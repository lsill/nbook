---
title: "虚拟内存"
date: 2023-11-28T17:24:48+08:00
draft: true
---

# 虚拟内存
一个系统中的进程是与其他进程共享CPU和主存资源的。然而，共享主存会形成一些特殊的挑战。
随着对CPU需求的增长，进程以某种合理的平滑方式慢了下来。但是如果太多的进程需要太多的内
存，那么它们中的一些就根本无法运行。当一个程序没有空间可用时，那就是它运气不好了。内存
还很容易被破坏。如果某个进程不小心写了另一个进程使用的内存，它就可能以某种完全和程序逻
辑无关的令人迷惑的方式失败。

为了更加有效地管理内存并且少出错，现代系统提供了一种对主存的抽象概念，叫做`虛拟内存(VM)`。
虚拟内存是硬件异常、硬件地址翻译、主存、磁盘文件和内核软件的完美交互，它为每个进程提供了一
个大的、一致的和私有的地址空间。通过一个很清晰的机制，虛拟内存提供了三个重要的能力:1)它将主
存看成是一个存储在磁盘上的地址空间的高速缓存，在主存中只保存活动区域，并根据需要在磁盘和主存
之间来回传送数据，通过这种方式，它高效地使用了主存。2)它为每个进程提供了一致的地址空间，从而
简化了内存管理。3)它保护了每个进程的地址空间不被其他进程破坏。

虛拟内存是计算机系统最重要的概念之一。它成功的一个主要原因就是因为它是沉默地、自动地工作的，
不需要应用程序员的任何干涉。既然虛拟内存在幕后工作得如此之好，为什么程序员还需要理解它呢?
有以下几个原因:
- 虛拟内存是核心的。虚拟内存遍及计算机系统的所有层面，在硬件异常、汇编器、链接器、加载器、
共享对象、文件和进程的设计中扮演着重要角色。理解虛拟内存将帮助你更好地理解系统通常是如何工作的。
- 虛拟内存是强大的。虛拟内存给子应用程序强大的能力，可以创建和销毁内存片(chunk)、将内存片映射
到磁盘文件的某个部分，以及与其他进程共享内存。比如，你知道可以通过读写内存位置读或者修改一个磁盘
文件的内容吗?或者可以加载一个文件的内容到内存中，而不需要进行任何显式地复制吗?理解虚拟内存将帮助
你利用它的强大功能在应用程序中添加动力。
- 虛拟内存是危险的。每次应用程序引用一个变量、间接引用一个指针，或者调用一个诸如malloc这样的动态
分配程序时，它就会和虚拟内存发生交互。如果虚拟内存使用不当，应用将遇到复杂危险的与内存有关的错误。
例如，一个带有错误指针的程序可以立即崩溃于“段错误”或者“保护错误”，它可能在崩溃之前还默默地运行了
几个小时，或者是最令人惊慌地，运行完成却产生不正确的结果。理解虛拟内存以及诸如malloc之类的管理
虚拟内存的分配程序，可以帮助你避免这些错误。

## 1. 物理和虚拟寻址
计算机系统的主存被组织成一个由M个连续的字节大小的单元组成的数组。每宇节都有一个唯一的
`物理地址(PhysicalAddress`, 第一个字节的地址为0，接下来的字节地址为1，再下一个为2，
依此类推。给定这种简单的结构，CPU访问内存的最自然的方式就是使用物理地址。把这种方式称
为物理寻址(physical addressing)

使用虚拟寻址，CPU通过生成一个虛拟地址(Virtual Address,VA)来访问主存，这个虛拟地址
在被送到内存之前先转换成适当的物理地址。将一个虚拟地址转换为物理地址的任务叫做地址翻译
(address translation)。就像异常处理一样，地址翻译需要CPU硬件和操作系统之间的紧密
合作。CPU芯片上叫做内存管理单元(Memory Management Unit,MMU)的专用硬件，利用存放
在主存中的查询表来动态翻译虚拟地址，该表的内容由操作系统管理。

## 2. 地址空间
地址空间(address space)是一个非负整数地址的有序集合:

{0,1,2,...}

如果地址空间中的整数是连续的，那么我们说它是一个`线性地址空间(linear address space)`
。为了简化讨论，我们总是假设使用的是线性地址空间。在一个带虚拟内存的系统中，CPU从一个有
N=2^n个地址的地址空间中生成虛拟地址，这个地址空间称为虚拟地址空间(virtual address space):

{0,1,2,....N-1}

一个地址空间的大小是由表示最大地址所需要的位数来描述的。例如，一个包含N=2^n个地址的虚拟地址
空间就叫做一个n位地址空间。现代系统通常支持32位或者64位虛拟地址空间。

一个系统还有一个`物理地址空间(physical address space)`，对应于系统中物理内存的M个字节:

{0, 1, 2...M-1}

M不要求是2的幂，但是为了简化讨论，我们假设M=2^m。

地址空间的概念是很重要的，因为它清楚地区分了数据对象(字节)和它们的属性(地址)。一旦认识到了这种
区别，那么我们就可以将其推广，允许每个数据对象有多个独立的地址，其中每个地址都选自一个不同的地址
空间。这就是虚拟内存的基本思想。主存中的每字节都有一个选自虚拟地址空间的虚拟地址和一个选自物理
地址空间的物理地址。

## 3. 虚拟内存作为缓存的工具
概念上而言，虛拟内存被组织为一个由存放在磁盘上的N个连续的字节大小的单元组成的数组。
每宇节都有一个唯一的虛拟地址，作为到数组的素引。磁盘上数组的内容被缓存在主存中。和
存储器层次结构中其他缓存一样，磁盘(较低层)上的数据被分割成块，这些块作为磁盘和主存
(较高层)之间的传输单元。VM系统通过将虚拟内存分割为称为虛拟页(Virtual Page,VP)的
大小固定的块来处理这个问题。每个虚拟页的大小为P=2^p字节。类似地，物理内存被分割为物
理页(Physical Page,PP)，大小也为P字节(物理页也被称为页帧(page frame))。

在任意时刻，虚拟页面的集合都分为三个不相交的子集:
- 未分配的:VM系统还未分配(或者创建)的页。未分配的块没有任何数据和它们相关联，因此也就不占用任何磁盘空间。
- 缓存的:当前已缓存在物理内存中的己分配页。
- 未缓存的:未缓存在物理内存中的已分配页。

### 1. DRAM 缓存的组织结构
在存储层次结构中，DRAM缓存的位置对它的组织结构有很大的影响。DRAM比SRAM要慢大约10倍，而磁盘
要比DRAM慢大约100 000多倍。因此，DRAM缓存中的不命中比起SRAM缓存中的不命中要昂贵得多，这是
因为DRAM缓存不命中要由磁盘来服务，而SRAM缓存不命中通常是由基于DRAM的主存来服务的。而且，从
磁盘的一个扇区读取第一个字节的时间开销比起读这个扇区中连续的字节要慢大约10 0000倍。归根到底，
DRAM缓存的组织结构完全是由巨大的不命中开销驱动的。

因为大的不命中处罚和访问第一个字节的开销，虛拟页往往很大，通常是4KB~2MB。由于大的不命中处罚，
DRAM缓存是全相联的，即任何虛拟页都可以放置在任何的物理页中。不命中时的替换策略也很重要，因为
替换错了虛拟页的处罚也非常之高。因此，与硬件对SRAM缓存相比，操作系统对DRAM缓存使用了更复杂
精密的替换算法。这些替换算法超出了我们的讨论范围)。最后，因为对磁盘的访问时间很长，DRAM缓存
总是使用写回，而不是直写。

### 2. 页表
同任何缓存一样，虚拟内存系统必须有某种方法来判定一个虚拟页是否缓存在DRAM中的某个地方。
如果是，系统还必须确定这个虛拟页存放在哪个物理页中。如果不命中，系统必须判断这个虛拟页
存放在磁盘的哪个位置，在物理内存中选择一个牺牲页，并将虚拟页从磁盘复制到DRAM中，替换这
个辆牲页。

这些功能是由软硬件联合提供的，包括操作系统软件、MMU(内存管理单元)中的地址翻译硬件和一个
存放在物理内存中叫做`页表(page table)`的数据结构，页表将虛拟页映射到物理页。每次地址
翻译硬件将一个虚拟地址转换为物理地址时，都会读取页表。操作系统负责维护页表的内容，以及在
磁盘与DRAM之间来回传送页。

页表就是一个`页表条目(Page Table Entry,PTE)`的数组。虛拟地址空间中的每个页在页表中
一个固定偏移量处都有一个PTE。

### 3. 页命中
### 4. 缺页
在虚拟内存的习惯说法中，DRAM缓存不命中称为缺页(page fault)。

虚拟内存是在20世纪60年代早期发明的，远在CPU-内存之间差距的加大引发产生SRAM缓存之前。
因此，虚拟内存系统使用了和SRAM缓存不同的术语，即使它们的许多概念是相似的。在虚拟内存
的习惯说法中，块被称为页。在磁盘和内存之间传送页的活动叫做`交换(swapping)`或者
`页面调度(paging)`。页从磁盘`换入`(或者`页面调入`)DRAM和从DRAM`换出`(或者`页面调出`)
磁盘。一直等待，直到最后时刻，也就是当有不命中发生时才换入页面的这种策略称为
`按需页面调度(demand paging)`。也可以采用其他的方法，例如尝试着预测不命中，在页面实际
被引用之前就换人页面。然而，所有现代系统都使用的是按需页面调度的方式。

### 5. 分配页面

### 6. 又是局部性救了我们
因为局部性，虚拟内存工作的相当好

尽管在整个运行过程中程序引用的不同页面的总数可能超出物理内存总的大小，但是局部性原则保证了
在任意时刻，程序将趋向于在一个较小的`活动页面(active page)`集合上工作，这个集合叫做
`工作集(working set)`或者`常驻集合(resident set)`。在初始开销，也就是将工作集页面调度
到内存中之后，接下来对这个工作集的引用将导致命中，而不会产生额外的磁盘流量。

只要我们的程序有好的时间局部性，虚拟内存系统就能工作得相当好。但是，当然不是所有的程序都能
展现良好的时间局部性。如果工作集的大小超出了物理内存的大小，那么程序将产生一种不幸的状态，
叫做`抖动(thrashing)`，这时页面将不断地换进换出。虽然虚拟内存通常是有效的，但是如果一个
程序性能慢得像爬一样，那么聪明的程序员会考虑是不是发生了抖动。

可以利用Linux的getrusage函数监测缺页的数量(以及许多其他的信息)

## 4. 虚拟内存作为内存管理的工具
按需页面调度和独立的虛拟地址空间的结合，对系统中内存的使用和管理造成了深远的影响。
特别地，VM简化了链接和加载、代码和数据共享，以及应用程序的内存分配。

- `简化链接`。独立的地址空间允许每个进程的内存映像使用相同的基本格式，而不管代码和数据实际
存放在物理内存的何处。
- `简化加载`。虚拟内存还使得容易向内存中加载可执行文件和共享对象文件。要把目标文件中.text
和.data节加载到一个新创建的进程中，Linux加载器为代码和数据段分配虚拟页，把它们标记为无效的
(即未被缓存的)，将页表条目指向目标文件中适当的位置。有趣的是，加载器从不从磁盘到内存实际复制
任何数据。在每个页初次被引用时，要么是CPU取指令时引用的，要么是一条正在执行的指令引用一个内存
位置时引用的，虚拟内存系统会按照需要自动地调人数据页。将一组连续的虚拟页映射到任意一个文件中
的任意位置的表示法称作`内存映射(memory mapping)`
- `简化共享`。独立地址空间为操作系统提供了一个管理用户进程和操作系统自身之间共享的一致机制。
一般而言，每个进程都有自己私有的代码、数据、堆以及栈区城，是不和其他进程共享的。在这种情况中，
操作系统创建页表，将相应的虚拟页映射到不连续的物理页面。然而，在一些情况中，还是需要进程来共
享代码和数据。例如，每个进程必须调用相同的操作系统内核代码，而每个C程序都会调用C标准库中的程
序，比如printf。操作系统通过将不同进程中适当的虚拟页面映射到相同的物理页面，从而安排多个进
程共享这部分代码的一个副本，而不是在每个进程中都包括单独的内核和C标准库的副本。
- `简化内存分配`。虛拟内存为向用户进程提供一个简单的分配额外内存的机制。当一个运行在用户进
程中的程序要求额外的堆空间时(如调用malloc的结果)，操作系统分配一个适当数宇(例如k)个连续的
虚拟内存页面，并且将它们映射到物理内存中任意位置的k个任意的物理页面。由于页表工作的方式，操
作系统没有必要分配k个连续的物理内存页面。页面可以随机地分散在物理内存中。

## 5. 虚拟内存作为内存保护的工具

## 6. 地址翻译
基本参数

| 符号    | 描述           |
|-------|--------------|
| N=2^n | 虚拟地址空间中的地址数量 |
| M=2^m | 物理地址空间中的地址数量 |
| P=2^p | 页的大小（字节）     |

虚拟地址（VA）的组成部分

| 符号   | 描述          |
|------|-------------|
| VPO  | 虚拟页面偏移量（字节） |
| VPN  | 虚拟页号        |
| TLBI | TLB索引       |
| TLBT | TLB标记       |

物理地址（PA）的组成部分

| 符号  | 描述          |
|-----|-------------|
| PPO | 物理页面偏移量(字节) |
| PPN | 物理页号        |
| CO  | 缓冲块内的字节偏移量  |
| CI  | 高速缓存索引      |
| CT  | 高速缓存标记      |

地址翻译是一个N元素的虚拟地址（VAS）中的元素和一个M元素的物理地址（PAS）中的元素之间的映射：

![MAP](https://raw.githubusercontent.com/lsill/gitLink/main/document/photo/note/MAP(VASandPAS).jpg)

图中展示了MMU如何利用页表来实现这种映射。CPU中的一个控制寄存器，`页表基址寄存器（Page Table 
Base Register, PTBR）`指向当前页表。n位的虚拟地址包含两个部分：一个p位的`虚拟页面偏移(Virtual
 Page Offset, VPO)`和一个(n-p)位的`虚拟页号（Virtual Page Number, VPN）`。MMU利用VPN来
选择适当的PTE。例如VPN0选择PTE0， VPN1选择PTE1，以此类推。将页表条目中`物理页号（Physical 
Page Number, PPN）`和虚拟地址中的VPO串联起来，就得到相应的物理地址。注意物理和虚拟页面都是P字节
的，所以`物理页面偏移（Physical Page Offset, PPO）`和VPO相同的。

当页面命中CPU硬件执行的操作：
- 第1步:处理器生成一个虛拟地址VA，并把它传送给MMU。
- 第2步:MMU生成PTE地址，并从高速缓存/主存请求得到它。
- 第3步:高速缓存/主存向MMU返回PTE。
- 第4步:MMU构造物理地址，并把它传送给高速缓存/主存。
- 第5步:高速缓存/主存返回所请求的数据字给处理器。

处理缺页要求硬件和操作系统内核协作完成:
- 第1步到第3步:和上面的第1步到第3步相同。
- 第4步:PTE中的有效位是零，所以MMU触发了一次异常，传递CPU中的控制到操作系统内核中的缺页异常处理程序。
- 第5步:缺页处理程序确定出物理内存中的酒牲页，如果这个页面己经被修改了，则把它换出到磁盘。
- 第6步:缺页处理程序页面调人新的页面，并更新内存中的PTE。
- 第7步:缺页处理程序返回到原来的进程，再次执行导致缺页的指令。CPU将引起缺页的虚拟地址重新发送给MMU。
因为虚拟页面现在缓存在物理内存中，所以就会命中，然后走上面的页面命中操作。

### 1. 结合高速缓存和虚拟内存
在任何既使用虚拟内存又使用SRAM高速缓存的系统中，都有应该使用虚拟地址还是使用物理地址来访问SRAM高速
缓存的问题。大多数系统是选择物理寻址的。使用物理寻址，多个进程同时在高速缓存中有存储块和共享来自相同
虚拟页面的块成为很简单的事情。而且，高速缓存无需处理保护问题，因为访问权限的检查是地址翻译过程的一部分。

### 2. 利用TLB加速地址翻译
每次CPU产生一个虚拟地址，MMU就必须查阅一个PTE，以便将虛拟地址翻译为物理地址。在最糟糕的情况下，
这会要求从内存多取一次数据，代价是几十到几百个周期。如果PTE碰巧缓存在L1中，那么开销就下降到1个
或2个周期。然而，许多系统都试图消除即使是这样的开销，它们在MMU中包括了一个关于PTE的小的缓存，
称为翻译后备缓冲器(Translation Lookaside Buffer,TLB)。

TLB是一个小的、虚拟寻址的缓存，其中每一行都保存着由单个PTE组成的块。TLB通常有高度的相联度。

用于组选择和行匹配的索引和标记字段是从虛拟地址中的虛拟页号中提取出来的。如果TLB有T=2^t个组，
那么TLB索引(TLBI是由VPN的t个最低位组成的，而TLB标记(TLBT)是由VPN中剩余的位组成的。

TLB命中时(通常情况)所包括的步骤。这里的关键点是，所有的地址翻译步骤都是在芯片上的MMU中执行
的，因此非常快。
- 第1步:CPU产生一个虚拟地址。
- 第2步和第3步:MMU从TLB中取出相应的PTE。 
- 第4步:MMU将这个虚拟地址翻译成一个物理地址，并且将它发送到高速缓存/主存。
- 第5步:高速缓存/主存将所请求的数据字返回给CPU。

当TLB不命中时，MMU必须从L1缓存中取出相应的PTE。新取出的PTE存放在TLB中，可能会覆盖一个已经存在的条目。

### 3. 多级页表

### 4. 综合：端到端的地址翻译
通过一个具体的端到端的地址翻译示例，来综合一下我们刚学过的这些内容，这个示例运行在有一个
TLB和L1 d-cache的小系统上。为了保证可管理性，我们做出如下假设:
- 内存是按字节寻址的。
- 内存访问是针对1字节的字的(不是4字节的字)。
- 虚拟地址是14位长的(n=14)。
- 物理地址是12位长的(m=12)。
- 页面大小是64字节(P=64)。
- TLB是四路组相联的，总共有16个条目。
- L1 d-cache是物理寻址、直接映射的，行大小为4宇节，而总共有16个组

因为页面大小P=64，所以页面位p等于6（2^6=64）；

所以虚拟地址和物理地址的低6位分别作为VPO和PPO；

所以虚拟地址高8位作为VPN，物理地址高6位作为PPN；

![MAP](https://raw.githubusercontent.com/lsill/gitLink/main/document/photo/note/addessdemo.jpg)

- TLB: TLB是利用VPN的位进行虚拟寻址的。因为TLB有4个组，所以VPN的低2位就作为组素引(TLBI)。
VPN中剩下的高6位作为标记(TLBT)，用来区别可能映射到同一个TLB组的不同的VPN。
- 页表。这个页表是一个单级设计，一共有2^8=256个页表条目(PTE)。然而，我们只对这些条目中的开头
16个感兴趣。为了方便，我们用索引它的VPN来标识每个PTE;但是要记住这些VPN并不是页表的一部分，也
不储存在内存中。另外，注意每个无效PTE的PPN都用一个破折号来表示，以加强一个概念:无论刚好这里存
储的是什么位值，都是没有任何意义的。
- 高速缓存。直接映射的缓存是通过物理地址中的字段来寻址的。因为每个块都是4字节，所以物理地址的
低2位作为块偏移(CO)。因为有16组，所以接下来的4位就用来表示组索引(CI)。剩下的6位作为标记(CT)。

当CPU执行一条读地址0x03d4初字节的加载指令时
![MAP](https://raw.githubusercontent.com/lsill/gitLink/main/document/photo/note/addressdemohit.jpg)
开始时，MMU从虛拟地址中抽取出VPN(OxOF)，并且检查TLB，看它是否因为前面的某个内存引用缓存了
PTE OxOF的一个副本。TLB从VPN中抽取出TLB素引(0x03)和TLB标记(Ox3)，组0x3的第二个条目中有
效匹配，所以命中，然后将缓存的PPN(0xOD)返回给MMU。

如果TLB不命中，那么MMU就需要从主存中取出相应的PTE。然而，在这种情况中，我们很幸运，TLB会命中。
现在，MMU有了形成物理地址所需要的所有东西。它通过将来自PTE的PPN(OxOD)和来自康拟地址的VPO(Ox14)
连接起来，这就形成了物理地址(0x354)。

接下米，MMU发送物理地址给缓存，缓存从物理地址中抽取出缓存偏移CO(ox0)、缓存组素引CICOx5)以及
缓存标记CT(OxOD)。
![MAP](https://raw.githubusercontent.com/lsill/gitLink/main/document/photo/note/addressdemonohit.jpg)
因为组0x5中的标记与CT相匹配，所以缓存检测到一个命中，读出在偏移量CO处的数据字节(0x36)，并将它返
回给MMU，随后MMU将它传递回CPU。

翻译过程的其他路径也是可能的。例如，如果TLB不命中，那么MMU必须从页表中的PTE中取出PPN。如果得到
的PTE是无效的，那么就产生一个缺页，内核必须调人合适的页面，重新运行这条加载指令。另一种可能性是
PTE是有效的，但是所需要的内存块在缓存中不命中。

## 7. 案例研究：Intel Core i7/Linux 内存系统
Corei7内存系统的重要部分:处理器封装(processor package)包括四个核、一个大的所有核共享的L3高速缓存，
以及一个DDR3内存控制器。每个核包含一个层次结构的TLB、一个层次结构的数据和指令高速缓存，以及一组快速的
点到点链路，这种链路基于QuickPath技术，是为了让一个核与其他核和外部I/O桥直接通信。TLB是虚拟寻址的，
是四路组相联的。L1、L2和L3高速缓存是物理寻址的，块大小为64字节。L1和L2是8路组相联的，而L3是16路组
相联的。页大小可以在启动时被配置为4KB或4MB。Linux使用的是4KB的页。

### 1. Core i7地址翻译
### 2. Linux 虚拟内存系统
![LVM](https://raw.githubusercontent.com/lsill/gitLink/main/document/photo/note/linuxvirtualmemory.jpg)
内核虚拟内存的其他区域包含每个进程都不相同的数据。比如说，页表、内核在进程的上下文中执行代码时
使用的栈，以及记录虚拟地址空间当前组织的各种数据结构。

#### 1. Linux虚拟内存区域
Linux将虛拟内存组织成一些`区域`(也叫做`段`)的集合。一个区域(area)就是已经存在着的
(已分配的)虛拟内存的连续片(chunk)，这些页是以某种方式相关联的。例如，代码段、数据段
、堆、共享库段，以及用户栈都是不同的区域。每个存在的虚拟页面都保存在某个区域中，而不
属于某个区域的虛拟页是不存在的，并且不能被进程引用。区域的概念很重要，因为它允许虚拟
地址空间有间隙。内核不用记录那些不存在的虚拟页，而这样的页也不占用内存、磁盘或者内核
本身中的任何额外资源。
![LVM](https://raw.githubusercontent.com/lsill/gitLink/main/document/photo/note/linuxmanagevirtualmemory.jpg)
内核为系统中的每个进程维护一个单独的任务结构(源代码中的task_struct)。任务结构中的元素
包含或者指向内核运行该进程所需要的所有信息(例如，PID、指向用户栈的指针、可执行目标文件的
名字，以及程序计数器)。

任务结构中的一个条目指向mm_struct，它描述了虚拟内存的当前状态。我们感兴趣的两个字段是
pgd和mmap，其中pgd指向第一级页表(页全局目录)的基址，而mmap指向一个vm_area_structs
(区城结构)的链表，其中每个vm_area_structs都描述了当前虛拟地址空间的一个区域。当内核
运行这个进程时，就将pgd存放在CR3控制寄存器中。

一个具体区域的区域结构包含下面的字段:
- vm_start:指向这个区域的起始处。
- vm_end:指向这个区域的结束处。
- vm_prot:描述这个区域内包含的所有页的读写许可权限。
- vm_flags:描述这个区域内的页面是与其他进程共享的，还是这个进程私有的(还描述了其他一些信息)。
- vm_next:指向链表中下一个区域结构。

#### 2. Linux缺页异常处理
假设MMU在试图翻译某个虚拟地址A时，触发了一个缺页。这个异常导致控制转移到内核的缺页处理程序，
处理程序随后就执行下面的步骤:
- 虚拟地址A是合法的吗?换句话说，A在某个区域结构定义的区域内吗?为了回答这个问题，缺页处理程序
搜素区域结构的链表，把A和每个区域结构中的vm_start和vm_end做比较。如果这个指令是不合法的，
那么缺页处理程序就触发一个段错误，从而终止这个进程。
因为一个进程可以创建任意数量的新虛拟内存区域(使用在下一节中描述的mmap函数)，所以顺序搜索区域
结构的链表花销可能会很大。因此在实际中，Linux使用某些我们没有显示出来的字段，Linux在链表中
构建了一棵树，并在这棵树上进行查找。
- 试图进行的内存访问是否合法?换句话说，进程是否有读、写或者执行这个区域内页面的权限?例如，
这个缺页是不是由一条试图对这个代码段里的只读页面进行写操作的存储指令造成的?这个缺页是不是
因为一个运行在用户模式中的进程试图从内核虛拟内存中读取字造成的?如果试图进行的访问是不合法
的，那么缺页处理程序会触发一个保护异常，从而终止这个进程。
- 此刻，内核知道了这个缺页是由于对合法的虚我地址进行合法的操作造成的。它是这样来处理这个缺
页的:选择一个牺牲页面，如果这个牺牲页面被修改过，那么就将它交换出去，换入新的页面并更新页表。
当缺页处理程序返回时，CPU重新启动引起缺页的指令，这条指令将再次发送A到MMU。这次，MMU就能正
常地翻译A，而不会再产生缺页中断了。

## 8. 内存映射
Linux通过将一个虚拟内存区域与一个磁盘上的`对象(object)`关联起来，以初始化这个虚拟内存区域
的内容，这个过程称为`内存映射(memory——mapping)`。虚拟内存区域可以映射到两种类型的对象中的一种:
- Linux文件系统中的普通文件:一个区域可以映射到一个普通磁盘文件的连续部分，例如一个可执行目标文件。
文件区(section)被分成页大小的片，每一片包含一个虚拟页面的初始内容。因为按需进行页面调度，所以这些
虚拟页面没有实际交换进入物理内存，直到CPU第一次引用到页面(即发射一个虚拟地址，落在地址空间这个页面
的范围之内)。如果区域比文件区要大，那么就用零来填充这个区域的余下部分。
- 匿名文件:一个区域也可以映射到一个匿名文件，匿名文件是由内核创建的，包含的全是二进制零。CPU第一次
引用这样一个区域内的虚拟页面时，内核就在物理内存中找到一个合适的牺牲页面，如果该页面被修改过，就将
这个页面换出来，用二进制零覆盖牺牲页面并更新页表，将这个页面标记为是驻留在内存中的。注意在磁盘和内存
之间并没有实际的数据传送。因为这个原因，映射到匿名文件的区域中的页面有时也叫做`请求二进制零的页
(demand-zero page)`。

无论在哪种情况中，一旦一个虚拟页面被初始化了，它就在一个由内核维护的专门的`交换文件(swap file)`
之间换来换去。交换文件也叫做`交换空间(swap space)`或者`交换区城(swap area)`。需要意识到的很
重要的一点是，在任何时刻，交换空间都限制着当前运行着的进程能够分配的虛拟页面的总数。

### 1. 在看共享对象
一个对象可以被映射到虛拟内存的一个区域，要么作为共享对象，要么作为私有对象。

如果一个进程将一个共享对象映射到它的虛拟地址空间的一个区域内，那么这个进程对这个区域的任何
写操作，对于那些也把这个共享对象映射到它们虚拟内存的其他进程而言，也是可见的。而且，这些变
化也会反映在磁盘上的原始对象中。

另一方面，对于一个映射到私有对象的区域做的改变，对手其他进程来说是不可见的，并且进程对这个
区域所做的任何写操作都不会反映在磁盘上的对象中。

一个映射到共享对象的虚拟内存区域叫做共享区域。类似地，也有私有区域

### 2. 在看看fork函数
当fork函数被`当前进程调`用时，内核为`新进程`创建各种数据结构，并分配给它一个唯一的PID。
为了给这个新进程创建虛拟内存，它创建了当前进程的mm_struct、区域结构和页表的原样副本。
它将两个进程中的每个页面都标记为只读，并将两个进程中的每个区域结构都标记为私有的写时复制。

当fork在新进程中返回时，新进程现在的虛拟内存刚好和调用fork时存在的虚拟内存相同。当这两
个进程中的任一个后来进行写操作时，写时复制机制就会创建新页面，因此，也就为每个进程保持了
私有地址空间的抽象概念。

### 3.在看看evecve函数
假设运行在当前进程中的程序执行了如下的exevce调用：

execve("a.out", NULL, NULL);

execve函数在当前进程中加载并运行包含在可执行目标文件a.out中的程序，用a.out程序有效地替代
了当前程序。加载并运行a.out需要以下几个步骤:
- 删除已存在的用户区域。删除当前进程虛拟地址的用户部分中的已存在的区域结构。
- 映射私有区域。为新程序的代码、数据、bss和栈区域创建新的区域结构。所有这些新的区城都是
私有的、写时复制的。代码和数据区域被映射为a.out文件中的.text和.data区。bss区域是请求
二进制零的，映射到匿名文件，其大小包含在a.out中。栈和堆区域也是请求二进制零的，初始长度
为零。
- 映射共享区域。如果a.out程序与共享对象(或目标)链接，比如标准C库libc.so，那么这些对象
都是动态链接到这个程序的，然后再映射到用户虚拟地址空间中的共享区域内。
- 设置程序计数器(PC)。execve做的最后一件事情就是设置当前进程上下文中的程序计数器，使之
指向代码区域的人口点。

下一次调度这个进程时，它将从这个人口点开始执行。Linux将根据需要换人代码和数据页面。

### 4. 使用mmap函数的用户级内存映射
Linux进程可以使用mmap函数来创建新的虛拟内存区域，并将对象映射到这些区域中
```
#include <unistd.h> 
#include <sys/mman.h>
void *mmap(void *start, size_t length, int prot, int flags, int fd, off_t offset);
// 返回:若成功时則为指向映射区城的指针，若出錯則为MAP_FAILED(一1)
```
mmap函数要求内核創建一个新的虚似内存区域，最好是从地址start开始的一个区域，并将文件描述符fd
指定的对象的一个连续的片(chunk)映射到这个新的区域。连续的对象片大小为length字节，从距文件
开始处偏移量为offset字节的地方开始。start地址仅仅是一个暗示，通常被定义为NULL。为了我们的
目的，我们总是假设起始地址为NULL。

参数prot包含描述新映射的虛拟内存区城的访问权限位(即在相应区城结构中的vm_prot位)。
- PROT_EXEC:这个区域内的页面由可以被CPU执行的指令组成。
- PROT_READ:这个区域内的页面可读。
- PROT_WRITE:这个区域内的页面可写。
- PROT_NONE:这个区域内的页面不能被访问。

参数flags由描述被映射对象类型的位组成。如果设置了MAP_ANON标记位，那么被映射的对象就是
一个匿名对象，而相应的虚拟页面是请求二进制零的。MAP_PRIVATE表示被映射的対象是一个私有的
、写時复制的対象，而MAP_SHARED表示是-个共享対象。例如

bufp = mmap(Null, size, PROP_READ, MAN_PRIVATE|MAP_ANON,0,0);

让内核创建一个新的包含size字节的只读、私有、请求二进制零的虚拟内存区域。如果週用成功，那么
bufp包含新区域的地址。

munmap函数删除虛拟内存的区域:
```
#include sunistd.h>
#include <sys/mman.h>
int munmap(void *start, size_t length);
// 返回:若成功則为0 ，若出錯則为一1.
```
munmap函数删除从虛拟地址start开始的，由接下来length字节组成的区域。接下来对已删除区域的引用
会导致段错误。

## 9. 动态内存分配
虽然可以使用低级的mmap和munmap函数来创建和删除虛拟内存的区域，但是C程序员还是会觉得当运行时
需要额外虚拟内存时，用动态内存分配器(dynamic memory allocator)更方便，也有更好的可移植性。

动态内存分配器维护这一个进程的虚拟内存区域，称为`堆(heap)`。系统之间细节不同，但是不失通用性，
假设堆是一个请求二进制零的区域，它紧接在未初始化的数据区域后开始，并向上生长（向更高的地址）。
对于每个进程，内核维护着一个变量brk(读作"break"),它指向堆的顶部。

分配器将堆视为一组不同大小的`块(block)`的集合来维护。每个块就是一个连续的虚拟内存片(chunk)，
要么是已分配的，要么是空闲的。己分配的块显式地供应用程序使用。空闲块可用来分配。空闲块保持空闲，
直到它显式地被应用所分配。一个已分配的块保持已分配状态，直到它被释放，这种释放要么是应用程序显
式执行的，要么是内存分配器自身隐式执行的。

分配器有两种基本风格。两种风格都要求应用显式地分配块。它们的不同之处在于由哪个实体来负责
- 显式分配器(explicit allocator)，要求应用显式地释放任何已分配的块。例如，C标准库提供
一种叫做malloc程序包的显式分配器。C程序通过调用malloc函数来分配一个块，并通过调用free
函数来释放一个块。c++中的new和delete操作符与C中的malloc和free相当。
- 隐式分配器(implicit allocator)，另一方面，要求分配器检测一个已分配块何时不再被程序
所使用，那么就释放这个块。隐式分配器也叫做`垃圾收集器(garbage collector)`，而自动释放未
使用的已分配的块的过程叫做`垃圾收集(garbage collection)`。例如，诸如Lisp、ML以及Java
之类的高级语言就依赖垃圾收集来释放已分配的块。

### 1. malloc函数和free函数
C标淮库提供了一个称为malloc程序包的显式分配器。程序通过调用malloc函数来从堆中分配块。
```c
#include <stdlib.h>
void *malloc (size_t size);
// 返回:若成功則为已分配块的指针，若出錯則为NULL
```
ma1loc函数返回一个指针，指向大小为至少size字节的内存块，这个块会为可能包含在这个块内
的任何数据对象类型做对齐。实际中，对齐依赖于编译代码在32位模式(gcc-m32)还是64位模式
(默认的)中运行。在32位模式中，malloc返回的块的地址总是8的倍数。在64位模式中，该地址
总是16的倍数。

如果malloc遇到问题(例如，程序要求的内存块比可用的虚拟内存还要大)，那么它就返回NULL，并设置
errno。malloc不初始化它返回的内存。那些想要己初始化的动态内存的应用程序可以使用calloc，
calloc是一个基于malloc的瘦包装两数，它将分配的内存初始化为零。想要改变一个以前已分配块的大小，
可以使用realloc函数。

动态内存分配器，例如malloc，可以通过使用mmap和munmap函数，显式地分配和释放堆内存，或者还可以
使用sbrk西数:
```c
#include sunistd.h>
void *sbrk(intptr_t incr);
// 返回:若成功则为旧的brk 指针，若出錯则为一1.
```
sbrk函数通过将内核的brk指针增加incr来扩展和收缩堆。如果成功，它就返回brk的旧值，否则，它就返回一1，
并将errno设置为ENOMEM。如果incr为零，那么sbrk就返回brk的当前值。用一个为负的incr来调用sbrk是合
法的，而且很巧妙，因为返回值(brk的旧值)指向距新堆顶向上abs(incr)字节处。

程序是通过调用free函数来释放已分配的堆块
```c
#include <std1ib.h>
void free(void *ptr);
// 返回:无
```
ptr参数必须指向一个从malloc、calloc或者realloc获得的已分配块的起始位置。如果不是，那么free的
行为就是未定义的。更糟的是，既然它什么都不返回，free就不会告诉应用出现了错误。

### 2. 为什么要使用动态内存分配
程序使用动态内存的最重要的原因是经常直到程序实际运行时，才知道某些数据结构的大小。

### 3. 分配器的要求和目标
显式分配器必须在一些相当严格的约束条件下工作:
- 处理任意请求序列。一个应用可以有任意的分配请求和释放请求序列，只要满足约束条件:
每个释放请求必须对应于一个当前已分配块，这个块是由一个以前的分配请求获得的。因此，
分配器不可以假设分配和释放请求的顺序。例如，分配器不能假设所有的分配请求都有相匹配
的释放请求，或者有相匹配的分配和空闲请求是嵌套的。
- 立即响应请求。分配器必须立即响应分配请求。因此，不允许分配器为了提高性能重新排列或者缓冲请求。
- 只使用堆。为了使分配器是可扩展的，分配器使用的任何非标量数据结构都必须保存在堆里。
- 对齐块(对齐要求)。分配器必须对齐块，使得它们可以保存任何类型的数据对象。
- 不修改已分配的块。分配器只能操作或者改变空闲块。特别是，一旦块被分配了，就不允许修改或者移动它了。
因此，诸如压缩已分配块这样的技术是不允许使用的。

在这些限制条件下，分配器的编写者试图实现吞吐率最大化和内存使用率最大化，而这两个性能目标
通常是相互冲突的。
- 目标1:`最大化吞吐率`。假定n个分配和释放请求的某种序列:R0,R1....Rn-1我们希望一个分配器的
吞吐率最大化，吞吐率定义为每个单位时间里完成的请求数。例如，如果一个分配器在1秒内完成500个分
配请求和500个释放请求，那么它的吞吐率就是每秒1000次操作。一般而言，我们可以通过使满足分配和
释放请求的平均时间最小化来使吞吐率最大化。正如我们会看到的，开发一个具有合理性能的分配器并
不困难，所谓合理性能是指一个分配请求的最糟运行时间与空闲块的数量成线性关系，而一个释放请求的运
行时间是个常数。
- 目标2:`最大化内存利用率`。天真的程序员经常不正确地假设虛拟内存是一个无限的资源。实际上，一
个系统中被所有进程分配的虚拟内存的全部数量是受磁盘上交换空问的数量限制的。好的程序员知道虚拟内
存是一个有限的空间，必须高效地使用。对于可能被要求分配和释放大块内存的动态内存分配器来说，尤其如此.

有很多方式来描述一个分配器使用堆的效率如何。在我们的经验中，最有用的标准是峰值利用率
(peak utilization)。像以前一样，我们给定n个分配和释放请求的某种顺序R0,R1,...,Rn-1
如果一个应用程序请求一个p字节的块，那么得到的已分配块的`有效载荷(payload)`是p字节。
在请求R完成之后，`聚集有效載荷(aggregate payload)`表示为P，为当前已分配的块的有效
载荷之和，而H(k)表示堆的当前的(单调非递减的)大小。
那么，k+1个请求的峰值利用率，表示为U，可以通过下式得到:

U(k) = max(i<=k)P(i) / H(k)

那么，分配器的目标就是在整个序列中使峰值利用率U(n-1)最大化。正如我们将要看到的，在最大
化吞吐率和最大化利用率之间是互相牵制的。特别是，以堆利用率为代价，很容易编写出吞吐率最
大化的分配器。分配器设计中一个有趣的挑战就是在两个目标之间找到一个适当的平衡。

### 4. 碎片
造成堆利用率很低的主要原因是一种称为`碎片(fragmentation)`的现象，当虽然有末使用的内存
但不能用来满足分配请求时，就发生这种现象。有两种形式的碎片:`内部碎片(internal fragmentation)`
和`外部碎片(external fragmentation)`。

`内部碎片`是在一个已分配块比有效载荷大时发生的。很多原因都可能造成这个问题。例如，一个分配器
的实现可能对已分配块强加一个最小的大小值，而这个大小要比某个请求的有效载荷大。

内部碎片的量化是简单明了的。它就是已分配块大小和它们的有效载荷大小之差的和。因此，在任意时刻，
内部碎片的数量只取决于以前请求的模式和分配器的实现方式。

`外部碎片`是当空闲内存合计起来足够满足一个分配请求，但是没有一个单独的空闲块足够大可以來处理
这个请求时发生的。

外部碎片比内部碎片的量化要困难得多，因为它不仅取决于以前请求的模式和分配器的实现方式，还取决于
将来请求的模式。例如，假设在k个请求之后，所有空闲块的大小都怡好是4个字。这个堆会有外部碎片吗?
答案取决于将来请求的模式。如果将来所有的分配请求都要求小于或者等于4个字的块，那么就不会有外部
碎片。另一方面，如果有一个或者多个请求要求比4个字大的块，那么这个堆就会有外部碎片。

因为外部碎片难以量化且不可能预测，所以分配器通常采用启发式策略来试图维持少量的大空闲块，而不是
维持大量的小空闲块。

### 5. 实现问题
可以想象出的最简单的分配器会把堆组织成一个大的字节数组，还有一个指针p，初始指向这个数组的第一个字节。
为了分配size个字节，malloc将p的当前值保存在栈里，将又增加size，并将p的旧值返回到调用函数。free只
是简单地返回到调用函数，而不做其他任何事情。

这个简单的分配器是设计中的一种极端情况。因为每个malloc和free只执行很少量的指令，吞吐率会极好。然而，
因为分配器从不重复使用任何块，内存利用率将极差。一个实际的分配器要在吞吐率和利用率之间把握好平衡，就
必须考虑以下几个问题:
- 空闲块组织:我们如何记录空闲块?
- 放置:我们如何选择一个合适的空闲块来放置一个新分配的块?
- 分割:在将一个新分配的块放置到某个空闲块之后，我们如何处理这个空闲块中的剩余部分?
- 合并:我们如何处理一个刚刚被释放的块?

### 6. 隐式空闲链表
任何实际的分配器都需要一些数据结构，允许它来区别块边界，以及区别已分配块和空闲块。
大多数分配器将这些信息嵌人块本身。如下：
![LVM](https://raw.githubusercontent.com/lsill/gitLink/main/document/photo/note/hidelisttable.jpg)
在这种情况中，一个块是由一个字的`头部`、`有效载荷`，以及可能的一些额外的填充组成的。头部
编码了这个块的大小(包括头部和所有的填充)，以及这个块是已分配的还是闲的。如果我们强加一个
双字的对齐约束条件，那么块大小就总是8的倍数，且块大小的最低3位,总是零。因此，我们只需要
内存大小的29个高位，释放剩余的3位来编码其他信息。在这种情况中，我们用其中的最低位(已分
配位)来指明这个块是已分配的还是空闲的。例如，假设我们有一个已分配的块，大小为24(0x18)字节。
那么它的头部将是

0x00000018 | 0x1 = 0x00000019

类似的，一个块大小为40(0x28)字节的空闲块有如下的头部

0x00000028 | 0x0 = 0x00000028

头部后面就是应用调用malloc时请求的有效载荷。有效载荷后面是一片不使用的填充块，其大小可以
是任意的。需要填充有很多原因。比如，填充可能是分配器策略的一部分，用来对付外部碎片。或者
也需要用它来满足对齐要求。

我们可以将堆组织为一个连续的已分配块和空闲块的序列，如图：
![LVM](https://raw.githubusercontent.com/lsill/gitLink/main/document/photo/note/hideliststruct.jpg)
我们称这种结构为`隐式空闲链表`，是因为空闲块是通过头部中的大小字段隐含地连接着的。分配器
可以通过遍历堆中所有的块，从而间接地遍历整个空闲块的集合。注意，我们需要某种特殊标记的结
束块，在这个示例中，就是一个设置了已分配位而大小为零的终止头部(terminating header)。

隐式空闲链表的优点是简单。显著的缺点是任何操作的开销，例如放置分配的块，要求对空闲链表进行
搜索，该搜素所需时间与堆中已分配块和空闲块的总数呈线性关系。很重要的一点就是意识到系统对齐
要求和分配器对块格式的选择会对分配器上的最小块大小有强制的要求。没有已分配块或者空闲块可以
比这个最小值还小。例妇，如果我们假设一个双字的对齐要求，那么每个块的大小都必须是双字(8字节)
的倍数。块格式就导致最小的块大小为两个字:一个字作头，另一个字维持对齐要求。即使应用只请求一
字节，分配器也仍然需要创建一个两宇的块。

### 7. 放置已分配的块
当一个应用请求一个k字节的块时，分配器搜索空闲链表，查找一个足够大可以放置所请求块的空闲块。
分配器执行这种搜素的方式是由`放置策略(placement policy)`确定的。一些常见的策略是
`首次适配(first fit)`、`下一次造配(next fit)`和`最佳适配(best fit)`。

`首次适配`从头开始搜索空闲链表，选择第一个合适的空闲块。`下一次适配`和首次适配很相似，只
不过不是从链表的起始处开始每次搜素，而是从上一次查询结束的地方开始。`最佳适配`检查每个空
闲块，选择适合所需请求大小的最小空闲块。

首次适配的优点是它趋向于將大的空闲块保留在链表的后面。缺点是它趋向于在靠近链表起始处留下小
空闲块的“碎片”，这就增加了对较大块的搜素时间。下一次适配是由DonaldKnuth作为首次适配的一
种代替品最早提出的，源于这样一个想法:如果我们上一次在某个空闲块里己经发现了一个匹配，那么
很可能下一次我们也能在这个剩余块中发现匹配。下一次适配比首次适配运行起来明显要快一些，尤其
是当链表的前面布满了许多小的碎片时。然而，一些研究表明，下一次适配的内存利用率要比首次适配
低得多。研究还表明最佳适配比首次适配和下一次适配的内存利用率都要高一些。然而，在简单空闲链
表组织结构中，比如隐式空闲链表中，使用最佳适配的缺点是它要求对堆进行彻底的搜索。

### 8. 分割空闲块
一旦分配器找到一个匹配的空闲块，它就必领做另一个策略决定，那就是分配这个空闲块中多少空间。
一个选择是用整个空闲块。虽然这种方式简单而快捷，但是主要的缺点就是它会造成内部碎片。如果放
置策略趋向于产生好的匹配，那么额外的内部碎片也是可以接受的。

然而，如果匹配不太好，那么分配器通常会选择将这个空闲块`分割`为两部分。第一部分变成分配块，
而剩下的变成一个新的空闲块。

### 9. 获取额外的堆内存
如果分配器不能为请求块找到合适的空闲块将发生什么呢?一个选择是通过合并那些在内存中物理上相邻
的空闲块来创建一些更大的空闲块。然而，如果这样还是不能生成一个足够大的块，或者如果空闲块己经
最大程度地合并了，那么分配器就会通过调用sbrk西数，向内核请求额外的堆内存。分配器将额外的内存
转化成一个大的空闲块，将这个块插人到空闲链表中，然后将被请求的块放置在这个新的空闲块中。

### 10. 合并空闲块
当分配器释放一个已分配块时，可能有其他空闲块与这个新释放的空闲块相邻。这些邻接的空闲块可能引起
一种现象，叫做`假碎片(fault fragmentation)`，就是有许多可用的空闲块被切割成为小的、无法使
用的空闲块。

为了解决假碎片问题，任何实际的分配器都必须合并相邻的空闲块，这个过程称为`合并(coalescing)`。
这就出现了一个重要的策略决定，那就是何时执行合并。分配器可以选择`立即合并(immediate coalescing)`
，也就是在每次一个块被释放时，就合并所有的相邻块。或者它也可以选择`推迟合并(deferred coalescing)`
，也就是等到某个稍晚的时候再合并空闲块。例如，分配器可以推迟合并，直到某个分配请求失败，然后扫描整个
堆，合并所有的空闲块。

立即合并很简单明了，可以在常数时间内执行完成，但是对于某些请求模式，这种方式会产生一种形式的抖动，
块会反复地合并，然后马上分割。

### 11. 带边界标记的合并
分配器是如何实现合并的?让我们称想要释放的块为`当前块`。那么，合并(内存中的)下一个空闲块很简单
而且高效。当前块的头部指向下一个块的头部，可以检查这个指针以判断下一个块是否是空闲的。如果是，
就将它的大小简单地加到当前块头部的大小上，这两个块在常数时间内被合并。

但是我们该如何合并前面的块呢?给定一个带头部的隐式空闲链表，唯一的选择将是搜索整个链表，记住
前面块的位置，直到我们到达当前块。使用隐式空闲链表，这意味着每次调用free需要的时间都与堆的
大小成线性关系。即使使用更复杂精细的空闲链表组织，搜索时间也不会是常数。

![LVM](https://raw.githubusercontent.com/lsill/gitLink/main/document/photo/note/boundarytag.jpg)
Knuth提出了一种聪明而通用的技术，叫做`边界标记(boundary tag)`，允许在常数时间内进行
对前面块的合并。这种思想，如上所示，是在每个块的结尾处添加一个脚部(footer，边界标记)，
其中脚部就是头部的一个副本。如果每个块包括这样一个脚部，那么分配器就可以通过检查它的脚部
，判断前面一个块的起始位置和状态，这个脚部总是在距当前块开始位置一个字的距离

考虑当分配器释放当前块时所有可能存在的情况：
- 前面的块和后面的块都是已分配的。
- 前面的块是己分配的，后面的块是空闲的。
- 前面的块是空闲的，而后面的块是已分配的。
- 前面的和后面的块都是空闲的。

四种情况合并如下:
![LVM](https://raw.githubusercontent.com/lsill/gitLink/main/document/photo/note/mergefour.jpg)
在情况1中，两个邻接的块都是已分配的，因此不可能进行合并。所以当前块的状态只是简单地从已分配变成空闲。
在情况2中，当前块与后面的块合并。用当前块和后面块的大小的和来更新当前块的头部和后面块的脚部。
在情况3中，前面的块和当前块合并。用两个块大小的和来更新前面块的头部和当前块的脚部。
在情况4中，要合并所有的三个块形成一个单独的空闲块，用三个块大小的和来更新前面块的头部和后面块的脚部。
在每种情况中，合并都是在常数时间内完成的。

边界标记的概念是简单优雅的，它对许多不同类型的分配器和空闲链表组织都是通用的。然而，它也存在
一个潜在的缺陷。它要求每个块都保持一个头部和一个脚部，在应用程序操作许多个小块时，会产生显著
的内存开销。例如，如果一个图形应用通过反复调用malloc和free来动态地创建和销毀图形节点，并且
每个图形节点都只要求两个内存字，那么头部和脚部将占用每个已分配块的一半的空间。

幸运的是，有一种非常聪明的边界标记的优化方法，能够使得在已分配块中不再需要脚部。回想一下，当
我们试图在内存中合并当前块以及前面的块和后面的块时，只有在前面的块是空闲时，才会需要用到它的
脚部。如果我们把前面块的已分配/空闲位存放在当前块中多出来的低位中，那么已分配的块就不需要脚部
了，这样我们就可以将这个多出来的空间用作有效载荷了。不过请注意，空闲块仍然需要脚部。

### 12. 综合：实现一个简单的分配器
基于隐式空闲链表，使用立即边界标记合并方式，从头至尾地讲述一个简单分配器的实现。最大的块大小
为2^32=4GB。代码是64位干净的，即代码能不加修改地运行在32位(gcc-m32)或64位(gcc-m64)的进程中。

#### 1. 通用分配器设计
![LVM](https://raw.githubusercontent.com/lsill/gitLink/main/document/photo/note/memlib_c.jpg)
mem_init函数将对于堆来说可用的虚拟内存模型化为一个大的、双字对齐的字节数组。
在mem_heap和mem_brk之间的字节表示已分配的虛拟内存。mem_brk之后的字节表示未分配的虛拟内存。
分配器通过调用mem_sbrk函数来请求额外的堆内存，这个函数和系统的sbrk函数的接口相同，而且语义
也相同，除了它会拒绝收缩堆的请求。

分配器包含在一个源文件中(mm.c)，用户可以编译和链接这个源文件到他们的应用之中。分配器输出三个
函数到应用程序:
```
extern int mm_init(void);
extern void* mm_malloc(size_t size);
extern void mm_free(void* ptr);
```
mm_init函数初始化分配器，如果成功就返回0，否则就返回-1。mm_mal1oc和mm_free函数与它们对应
的系统函数有相同的接口和语义。分配器使用如上所示的块格式。最小块的大小为16字节。空闲链表组织
成为一个隐式空闲链表，具有如上所示的恒定形式。

第一个字是一个双字边界对齐的不使用的填充字。填充后面紧跟着一个特殊的`序言块(prologue block)`
，这是一个8字节的已分配块，只由一个头部和一个脚部组成。序言块是在初始化时创建的，并且永不释放。
在序言块后紧跟的是零个或者多个由malloc或者free调用创建的普通块。堆总是以一个特殊的
`结尾块(epilogue block)`来结束，这个块是一个大小为零的己分配块，只由一个头部组成。
序言块和结尾块是一种消除合并时边界条件的技巧。分配器使用一个单独的私有(static)全局变量(heap_listp)，
它总是指向序言块。(作为一个小优化，我们可以让它指向下一个块，而不是这个序言块。)

#### 2. 操作空闲链表和基本常数和宏
![LVM](https://raw.githubusercontent.com/lsill/gitLink/main/document/photo/note/basefunandmacro.jpg)
如上展示了一些我们在分配器编码中将要使用的基本常数和宏。第2~4行定义了一些基本的大小常数:
字的大小(WSIZE)和双字的大小(DSIZE)，初始空闲块的大小和扩展堆时的默认大小(CHUNKSIZE)。

在空闲链表中操作头部和脚部可能是很麻烦的，因为它要求大量使用强制类型转换和指针运算。因此，
我们发现定义一小组宏来访问和遍历空闲链表是很有帮助的(第9~25行)。

PACK宏(第9行)将大小和已分配位结合起来并返回一个值，可以把它存放在头部或者脚部中。

GET宏(第12行)读取和返回参数p引用的宇。这里强制类型转换是至关重要的。参数p典型地是一个(viod*)指针
，不可以直接进行间接引用。类似地，PUT宏(第13行)将val存放在参数p指向的字中。

GET_SIZE和GET_ALLOC宏(第16~17行)从地址p处的头部或者脚部分别返回大小和已分配位。
剩下的宏是对块指针(block pointer，用bp表示)的操作，块指针指向第一个有效载荷字节。
给定一个块指针bp，HDRP和FTRP宏(第20~21行)分别返回指向这个块的头部和脚部的指针。
NEXT_BLKP和PREV_BLKP宏(第24~25行)分别返回指向后面的块和前面的块的块指针。

可以用多种方式来编辑宏，以操作空闲链表。比如，给定一个指向当前块的指针bp,我们可以
使用下面的代码行来确定内存中后面的块的大小:
```
size_t size= GET_SIZE(HDRP(NEXT_BLKP(bp)));
```

#### 3. 创建初始空闲链表
![LVM](https://raw.githubusercontent.com/lsill/gitLink/main/document/photo/note/createfreelink_mm.jpg)
在调用mm_malloc或者mm_free之前，应用必须通过调用mm_init函数来初始化堆见图9-44)。
mm_init函数从内存系统得到4个字，并将它们初始化，创建一个空的空闲链表(第4~10行)。
然后它调用extend_heap函数(图9-45)，这个函数将堆扩展CHUNKSIZE字节，并且创建初始
的空闲块。此刻，分配器已初始化了，并且准备好接受来自应用的分配和释放请求

extend_heap函数会在两种不同的环境中被调用:1)当堆被初始化时;2)当mm_malloc不能找到一
个合适的匹配块时。为了保持对齐，extend_heap将请求大小向上舍入为最接近的2字(8字节)的倍数，
然后向内存系统请求额外的堆空间(第7~9行)。

extend_heap函数的剩余部分(第12~17行)有点儿微妙。堆开始于一个双字对齐的边界，并且每次对
extend_heap的调用都返回一个块，该块的大小是双字的整数倍。因此，对mem_sbrk的每次调用都
返回一个双字对齐的内存片，紫跟在结尾块的头部后面。这个头部变成了新的空闲块的头部(第12行)，
并且这个片的最后一个字变成了新的结尾块的头部(第14行)。最后，在很可能出现的前一个堆以一个
空闲块结束的情况中，我们调用coalesce两数来合并两个空闲块，并返回指向合并后的块的块指针(第17行)。

#### 4. 释放和合并块
![LVM](https://raw.githubusercontent.com/lsill/gitLink/main/document/photo/note/mergeandfreeblock.jpg)
应用通过调用mm_free函数(图9-46)，来释放一个以前分配的块，这个函数释放所请求的块(bp)，
然后使用边界标记合并技术将之与邻接的空闲块合并起来。

coalesce函数中的代码是图9-40中勾画的四种情况的一种简单直接的实现。这里也有一个微妙
的方面。我们选择的空闲链表格式(它的序言块和结尾块总是标记为已分配)允许我们忽略潜在的
麻烦边界情况，也就是，请求块bp在堆的起始处或者是在堆的结尾处。如果没有这些特殊块，代
码将混乱得多，更加容易出错，并且更慢，因为我们将不得不在每次释放请求时，都去检查这些
并不常见的边界情况。

#### 5. 分配块
![LVM](https://raw.githubusercontent.com/lsill/gitLink/main/document/photo/note/mallocblock.jpg)
一个应用通过调用mm_malloc函数(见图9-47)来向内存请求大小为size字节的块。在检查完请求的
真假之后，分配器必须调整请求块的大小，从而为头部和脚部留有空间，并满足双字对齐的要求。
第12~13行强制了最小块大小是16字节:8字节用来满足对齐要求，而另外8个用来放头部和脚部。
对于超过8字节的请求(第15行)，一般的规则是加上开销字节，然后向上舍人到最接近的8的整数倍。

一旦分配器调整了请求的大小，它就会搜搜索空闲链表，寻找一个合适的空闲块(第18行)。如果有合适
的，那么分配器就放置这个请求块，并可选地分割出多余的部分(第19行)，然后返回新分配块的地址。

如果分配器不能够发现一个匹配的块，那么就用一个新的空闲块来扩展堆(第24~26行)，把请求块放置
在这个新的空闲块里，可选地分割这个块(第27行)，然后返回一个指针，指向这个新分配的块。

### 13. 显示空闲链表
隐式空闲链表为我们提供了一种介绍一些基本分配器概念的简单方法。然而，因为块分配与堆块的总数
呈线性关系，所以对于通用的分配器，隐式空闲链表是不适合的(尽管对于堆块数量预先就知道是很小
的特殊的分配器来说它是可以的)。

一种更好的方法是将空闲块组织为某种形式的显式数据结构。因为根据定义，程序不需要一个空闲块的
主体，所以实现这个数据结构的指针可以存放在这些空闲块的主体里面。例如，堆可以组织成一个双向
空闲链表，在每个空闲块中，都包含一个pred(前驱)和succ(后继)指针，如图9-48所示。
![LVM](https://raw.githubusercontent.com/lsill/gitLink/main/document/photo/note/showlistblock.jpg)
使用双向链表而不是隐式空闲链表，使首次适配的分配时间从块总数的线性时间减少到了空闲块数量的
线性时间。不过，释放一个块的时间可以是线性的，也可能是个常数，这取决于我们所选择的空闲链表
中块的排序策略。

一种方法是用`后进先出(LIFO)`的顺序维护链表，將新释放的块放置在链表的开始处。使用LIFO的顺序
和首次适配的放置策略，分配器会最先检查最近使用过的块。在这种情况下，释放一个块可以在常数时
间内完成。如果使用了边界标记，那么合并也可以在常数时间内完成。

另一种方法是按照`地址顺序`来维护链表，其中链表中每个块的地址都小于它后继的地址。在这种情况下，
释放一个块需要线性时间的搜索来定位合适的前驱。平衡点在于，按照地址排序的首次适配比LIFO排序的
首次适配有更高的内存利用率，接近最佳适配的利用率。

一般而言，显式链表的缺点是空闲块必须足够大，以包含所有需要的指针，以及头部和可能的脚部。这就
导致了更大的最小块大小，也潜在地提高了内部碎片的程度。

### 14. 分离的空闲链表
就像我们已经看到的，一个使用单向空闲块链表的分配器需要与空闲块数量呈线性关系的时问来分配块。
一种流行的减少分配时间的方法，通常称为`分离存储(segregated storage)`，就是维护多个空闲
链表，其中每个链表中的块有大致相等的大小。一般的思路是将所有可能的块大小分成一些等价类，也
叫做`大小类(size class)`。有很多种方式来定义大小类。例如，我们可以根据2的罪来划分块大小:
{1)，{2),{3,4),{5~8},....,{1025~2048},{2049~4096},{4097~∞}
或者我们可以将小的块分派到它们自己的大小类里，而将大块按照2的幂分类:
{1},{2}，{3},...，{1023}，{1024}，{1025~2048},{2049~4096},{4097~∞}

分配器维护着一个空闲链表数组，每个大小类一个空闲链表，按照大小的升序排列。当分配器需要一个大小
为n的块时，它就搜索相应的空闲链表。如果不能找到合适的块与之匹配，它就搜素下一个链表，以此类推。

有关动态内存分配的文献描述了几十种分离存储方法，主要的区别在于它们如何定义大小类，何时进行合并，
何时向操作系统请求额外的堆内存，是否允许分割，等等。为了使你大致了解有哪些可能性，我们会描述两
种基本的方法:`简单分离存储(simple segregated storage)`和`分离适配(segregated fit)`。

#### 1. 简单分离存储
使用简单分离存储，每个大小类的空闲链表包含大小相等的块，每个块的大小就是这个大小类中最大元素的大小。
例如，如果某个大小类定义为(17~32〉，那么这个类的空闲链表全由大小为32的块组成。

为了分配一个给定大小的块，我们检查相应的空闲链表。如果链表非空，我们简单地分配其中第一块的全部。
空闲块是不会分割以满足分配请求的。如果链表为空，分配器就向操作系统请求一个固定大小的额外内存
片(通常是页大小的整数倍)，将这个片分成大小相等的块，并将这些块链接起来形成新的空闲链表。要释
放一个块，分配器只要简单地将这个块插人到相应的空闲链表的前部。

这种简单的方法有许多优点。分配和释放块都是很快的常数时间操作。而且，每个片中都是大小相等的块，
不分割，不合并，这意味着每个块只有很少的内存开销。由于每个片只有大小相同的块，那么一个已分配
块的大小就可以从它的地址中推断出来。因为没有合并，所以已分配块的头部就不需要一个已分配/空闲
标记。因此已分配块不需要头部，同时因为没有合并，它们也不需要脚部。因为分配和释放操作都是在空
闲链表的起始处操作，所以链表只需要是单向的，而不用是双向的。关键点在于，在任何块中都需要的唯
一字段是每个空闲块中的一个字的succ指针，因此最小块大小就是一个字。

一个显著的缺点是，简单分离存储很容易造成内部和外部碎片。因为空闲块是不会被分割的，所以可能会
造成内部碎片。更糟的是，因为不会合并空闲块，所以某些引用模式会引起极多的外部碎片.

#### 2. 分离适配
使用这种方法，分配器维护着一个空闲链表的数组。每个空闲链表是和一个大小类相关联的，并且被组织成
某种类型的显式或隐式链表。每个链表包含潜在的大小不同的块，这些块的大小是大小类的成员。有许多种
不同的分离适配分配器。这里，我们描述了一种简单的版本。

为了分配一个块，必须确定请求的大小类，并且对适当的空闲链表做首次适配，查找一个合适的块。如果找
到了一个，那么就(可选地)分割它，并将剩余的部分插人到适当的空闲链表中。如果找不到合适的块，那么
就搜素下一个更大的大小类的空闲链表。如此重复，直到找到一个合适的块。如果空闲链表中没有合适的块，
那么就向操作系统请求额外的堆内存，从这个新的堆内存中分配出一个块，将剩余部分放置在适当的大小类
中。要释放一个块，我们执行合并，并将结果放置到相应的空闲链表中。

分离适配方法是一种常见的选择，C标准库中提供的GNN malloc包就是采用的这种方法，因为这种方法既快
速，对内存的使用也很有效率。搜索时间减少了，因为搜素被限制在堆的某个部分，而不是整个堆。内存利用
率得到了改善，因为有一个有趣的事实:对分离空闲链表的简单的首次适配搜素，其内存利用率近似于对整个
堆的最佳适配搜索的内存利用率。

#### 3. 伙伴系统
`伙件系统(buddy system)`是分离适配的一种特例，其中每个大小类都是2的幂。基本的思路是假设一个堆
的大小为2^m个字，我们为每个块大小2^k维护一个分离空闲链表，其中0<=k=<m。请求块大小向上舍人到最
接近的2的幂。最开始时，只有一个大小为2^m个字的空闲块。

为了分配一个大小为2^k的块，我们找到第一个可用的、大小为2^j的块，其中k≤j<=m。如果j=k，那么我们就
完成了。否则，我们递归地二分割这个块，直到j=k。当我们进行这样的分割时，每个剩下的半块(也叫做伙件)
被放置在相应的空闲链表中。要释放一个大小为2^k的块，我们继续合并空闲的伙伴。当遇到一个已分配的伙伴
时，我们就停止合并。

关于伙伴系统的一个关键事实是，给定地址和块的大小，很容易计算出它的伙伴的地址。例如，一个块，大小为
32字节，地址为:
xxx...x0000
它的伙伴的地址为
xxx...x10000
换句话说，一个块的地址和它的伙伴的地址只有一位不相同。

伙伴系统分配器的主要优点是它的快速搜素和快速合并。主要缺点是要求块大小为2的幂可能导致显著的内部碎片。
因此，伙伴系统分配器不适合通用目的的工作负载。然而，对于某些特定应用的工作负载，其中块大小预先知道
是2的幂，伙伴系统分配器就很有吸引力了。


## 10. 垃圾收集
`垃圾收集器(garbage collector)`是一种动态内存分配器，它自动释放程序不再需要的已分配块。
这些块被称为`垃圾(garbage)`(因此术语就称之为垃圾收集器)。自动回收堆存储的过程叫做
`垃圾收集(garbage collection)`。在一个支持垃圾收集的系统中，应用显式分配堆块，但是从不显
示地释放它们。在C程序的上下文中，应用调用malloc，但是从不调用free。反之，垃圾收集器定期识别
垃圾块，并相应地调用free，将这些块放回到空闲链表中。

垃圾收集可以追湖到John McCarthy在20世纪60年代早期在MIT开发的Lisp系统。它是诸如Java、ML、
Perl和Mathematica等现代语言系统的一个重要部分，而且它仍然是一个重要而活跃的研究领域。有关文
献描述了大量的垃圾收集方法，其数量令人吃惊。我们的讨论局限于McCarthy独创的
Mark&Sweep(标记&清除)算法，这个算法很有趣，因为它可以建立在己存在的malloc包的基础之上，
为C和C++程序提供垃圾收集。

### 1. 垃圾收集器的基本知识
### 2. Mark &Sweep 垃圾收集器
Mark&Sweep垃圾收集器由标记(mark)阶段和清除(sweep)阶段组成，标记阶段标记出根节点的所有可达
的和已分配的后继，而后面的清除阶段释放每个未被标记的已分配块。块头部中空闲的低位中的一位通常用
来表示这个块是否被标记了。

### 3. C程序的保守Mark&Sweep
Mark&Sweep对C程序的垃圾收集是一种合适的方法，因为它可以就地工作，而不需要移动任何块。然而，
C语言为isPtr函数的实现造成了一些有趣的挑战。

第一，C不会用任何类型信息来标记内存位置。因此，对isPtr没有一种明显的方式来判断它的输人参数p
是不是一个指针。第二，即使我们知道又是一个指针，对isPtr也没有明显的方式来判断p是否指向一个
已分配块的有效载荷中的某个位置。

对后一问题的解决方法是将己分配块集合维护成一棵平衡二叉树，这棵树保持着这样一个属性:左子树中的
所有块都放在较小的地址处，而右子树中的所有块都放在较大的地址处。这就要求每个已分配块的头部里
有两个附加字段(left和right)。每个字段指向某个已分配块的头部。isPtr(ptr p)函数用树来执行对
已分配块的二分查找。在每一步中，它依赖于块头部中的大小字段来判断又是否落在这个块的范围之内。

平衡树方法保证会标记所有从根节点可达的节点，从这个意义上来说它是正确的。这是一个必要的保证，
因为应用程序的用户当然不会喜欢把他们的已分配块过早地返回给空闲链表。然而，这种方法从某种意义
上而言又是保守的，因为它可能不正确地标记实际上不可达的块，因此它可能不会释放某些垃圾。虽然这
并不影响应用程序的正确性，但是这可能导致不必要的外部碎片。

C程序的Mark&Sweep收集器必须是保守的，其根本原因是C语言不会用类型信息来标记内存位置。因此，
像int或者float这样的标量可以伪装成指针。例妇，假设某个可达的已分配块在它的有效载荷中包含
一个int，其值碰巧对应于某个其他己分配块b的有效载荷中的一个地址。对收集器而言，是没有办法
推断出这个数据实际上是int而不是指针。因此，分配器必须保守地将块b标记为可达，尽管事实上它
可能是不可达的。

## 11. C程序中常见的与内存有关的错误

### 1. 间接引用坏指针
在进程的虛拟地址空间中有较大的洞，没有映射到任何有意义的数据。如果我们试图间接引用一个指向
这些洞的指针，那么操作系统就会以段异常中止程序。而且，虚拟内存的某些区域是只读的。试图写这
些区域将会以保护异常中止这个程序。

间接引用坏指针的一个常见示例是经典的scanf错误。假设我们想要使用scanf从stdin读一个整数到
一个变量。正确的方法是传递给scanf一个格式串和变量的地址:

scanf("%d",&val)

然而，对于C程序员初学者而言(对有经验者也是如此!)，很容易传递val的内容，而不是它的地址:

scanf("%d",val)

在这种情况下，scanf将把val的内容解释为一个地址，并试图将一个字写到这个位置。在最好的情况下
，程序立即以异常终止。在最糟糕的情况下，val的内容对应于虛拟内存的某个合法的读/写区域，于是
我们就覆盖了这块内存，这通常会在相当长的一段时间以后造成灾难性的、令人困惑的后果。

### 2. 读未初始化的内存
虽然bss内存位置(诸如末初始化的全局C变量)总是被加载器初始化为零，但是对于堆内存却并不是这样的。
一个常见的错误就是假设堆内存被初始化为零:
```c
/* return y = ax */
int* matvec(int **A, int *x, int n)
{
  int i,j;
  int *y = (int*)Malloc(n * sizeof(int));
  for (i = 0; i < n;i++)
    for (j = 0;j < n; j++)
      y[i] += A[i][j] * x[j];
  return y;
}
```
在这个示例中，程序员不正确地假设向量y被初始化为零。正确的实现方式是显式地将y[i]设置为零，或者使用calloc。

### 3. 允许栈缓冲区溢出
如果一个程序不检查输人串的大小就写人栈中的目标缓冲区，那么这个程序就会有缓冲区溢出错误
(buffer overflow bug)。例如，下面的函数就有缓冲区溢出错误，因为gets函数复制一个
任意长度的串到缓冲区。为了纠正这个错误，我们必须使用fgets两数，这个两数限制了输入串的大小:
```c
void bufoverflow()
{
  char buf[64];
  
  gets(buf); /* Here is the stack buffer overflow bug */
  return;
}
```

### 4. 假设指针和它们指向的对象是相同大小的
一种常见的错误是假设指向对象的指针和它们所指向的对象是相同大小的:
```c
/* Create an nux array */
int** makeArray1(int n, int m)
{
  int i;
  int** A = (int**)Malloc(n * sizeof(int));
  
  for (i = 0; i < n; i++)
    A[i] = (int*)Malloc(m*sizeof(iny));
  return A;
}

```
这里的目的是创建一个由n个指针组成的数组，每个指针都指向一个包含m个int的数组。
然而，因为程序员将sizeof(int*)写成了sizeof(int)，代码实际上创建的是一个int的数组。

这段代码只有在int和指向int的指针大小相同的机器上运行良好。但是，如果我们在像Corei7这样的机器
上运行这段代码，其中指针大于int，那么第7行和第8行的循环将写到超出A数组结尾的地方。因为这些字中
的一个很可能是已分配块的边界标记脚部，所以我们可能不会发现这个错误，直到在这个程序的后面很久释放
这个块时，此时，分配器中的合并代码会戏剧性地失败，而没有任何明显的原因。这是“在远处起作用(action 
at distance)”的一个阴险的示例，这类“在远处起作用”是与内存有关的编程错误的典型情况。

### 5. 造成错误错误
错位(off-by-one)错误是另一种很常见的造成覆盖错误的来源
```c
/* Create an nxm array */
int** makeArray2(int n, int m)
{
  int i;
  int** A = (int**)Malloc(n * sizeof(int*));
  
  for (i = 0; i <= n; i++) // 这里错误，数组越界 i<n是正确的
   A[i] = (int*)Malloc(m*sizeof(int));
  return A;
}
```

### 6. 引用指针，而不是它所指向的对象
如果不太注意C操作符的优先级和结合性，我们就会错误地操作指针，而不是指针所指向的对象。
比如，考虑下面的函数，其目的是删除一个有*size项的二叉堆里的第一项，然后对剩下的
*size-1项重新建堆:
```c
int* binheapDelete(int** binheap, int* size)
{
 int *packet = binheap[0];
 
 binheap[0] = binheap[*size -1];
 *size--; /* this should be (*size)-- */
 heapify(binheap, *size, 0);
 return (packet);
}
```
在第6行，目的是减少size指针指向的整数的值。然而，因为一元运算符--和*的优先级相同，从右向左结合，
所以第6行中的代码实际减少的是指针自己的值，而不是它所指向的整数的值。如果幸运地话，程序会立即失败;
但是更有可能发生的是，当程序在执行过程后很久才产生出一个不正确的结果时，我们只有一头的雾水。这里的原
则是当你对优先级和结合性有疑问的时候，就使用括号。比如，在第6行，我们可以使用表达式(*size)--，
清晰地表明我们的意图。

### 7. 误解指针运算
另一种常见的错误是忘记了指针的算术操作是以它们指向的对象的大小为单位来进行的，而这种大小单位并
不一定是字节。例如，下面两数的目的是扫描一个int的数组，并返回一个指针，指向val的首次出现：
```c
int* search(int* p, int val)
{
 while(*p && *p != val)
  p += sizeof(int); /* should be p++ */
 return p;
}
```
然而，因为每次循环时，第4行都把指针加了4(一个整数的字节数)，函数就不正确地扫描数组中每4个整数。

### 8. 引用不存在的变量
没有太多经验的C 程序员不理解栈的规则，有时会引用不再合法的本地变量，如下列所示:
```c
int *stackref () 
{
 int val;
 return &val;
}
```
这个函数返回一个指针(比如说是p)，指向栈里的一个局部变量，然后弹出它的栈帧。尽管又仍然指向一个合法
的内存地址，但是它已经不再指向一个合法的变量了。当以 后在程序中调用其他函数时，内存将重用它们的栈
帧。 再后来，如果程序分配某个值给 *p，那么它可能实际上正在修改另一个西数的栈帧中的一个条目，从而
潜在地带来灾难性的、令人困惑的后果。

### 9. 引用空闲堆块中的数据
一个相似的错误是引用己经被释放了的堆块中的数据。例如，考感下面的示例，这个示例在第6行分配了 
一个整数数组x，在第10行中先释放了块x，然后在第14行中又引用了它:
```c
int* heapref(int n, int m)
{
 int i;
 int *x, *y;
 
 x = (int*)Malloc(n*sizeof(int));
 
 // other calls to malloc and free go here
 
 free(x);
 
 y = (int*) Mallc(m*sizeof(int));
 for (i =0;i<m;i++)
  y[i] = x[i]++; // oops! x[i] is a word in a free block
 return y;
}
```
取决于在第6行和第10行发生的malloc和free的调用模式，当程序在第14行引用x[i]时，
数组x可能是某个其他己分配堆块的一部分了，因此其内容被重写了。和其他许多与内存有
关的错误一样，这个错误只会在程序执行的后面，当我们注意到y中的值被破坏了时才会显现出来。

### 10. 引起内存泄漏
内存泄漏是缓慢、隐性的杀手，当程序员不小心忘记释放已分配块，而在堆里创建了垃圾时，会发生
这种问题。例如，下面的函数分配了一个堆块x，然后不释放它就返回：
```c
void leak(int n)
{
 int *x = (int*)Malloc(n * sizeof(int));
 
 return; // x is geabage at this point
}
```
如果经常调用leak，那么渐渐地，堆里就会充满了垃圾，最糟糕的情况下，会占用整个虚拟地址空问。
对于像守护进程和服务器这样的程序来说，内存泄漏是特别严重的，根据定义这些程序是不会终止的。


## 12. 小结
虚拟内存是对主存的一个抽象。支持庭拟内存的处理器通过使用一种叫做虛拟寻址的间接形式来引用主存。
处理器产生一个虚拟地址，在被发送到主存之前，这个地址被翻译成一个物理地址。从虛拟地址空间到物理
地址空间的地址翻译要求硬件和软件紧密合作。专门的硬件通过使用页表来翻译虚找地址，而页表的内容是
由操作系统提供的。

虚拟内存提供三个重要的功能。第一，它在主存中自动缓存最近使用的存放磁盘上的虚拟地址空间的内容。
虚拟内存缓存中的块叫做页。对磁盘上页的引用会触发缺页，缺页将控制转移到操作系统中的一个缺页处理
程序。缺页处理程序将页面从磁盘复制到主存缓存，如果必要，将写回被驱逐的页。第二，虚拟内存简化了
内存管理，进而又简化了链接、在进程间共享数据、进程的内存分配以及程序加载。最后，虛拟内存通过在
每条页表条目中加人保护位，从而了简化了内存保护。

地址翻译的过程必须和系统中所有的硬件缓存的操作集成在一起。大多数页表条目位于L1高速绥存中，但是
一个称为TLB的页表条目的片上高速级存，通常会消除访问在L1上的页表条目的开销。

现代系统通过将虛拟内存片和磁盘上的文件片关联起来，来初始化虛拟内存片，这个过程称为内存映射。内存
映射为共享数据、创建新的进程以及加载程序提供了一种高效的机制。应用可以使用mmap函数来手工地创建和
删除虚拟地址空间的区域。然而，大多数程序依赖于动态内存分配器，例如malloc,它管理虚拟地址空间区域
内一个称为堆的区域。动态内存分配器是一个感觉像系统级程序的应用级程序，它直接操作内存，而无需类型
系统的很多帮助。分配器有两种类型。显式分配器要求应用显式地释放它们的内存块。隐式分配器(垃圾收集器)
自动释放任何未使用的和不可达的块。

对于C程序员来说，管理和使用虚拟内存是一件因难和容易出错的任务。常见的错误示例包括:间接引用坏指针，
读取未初始化的内存，允许栈缓冲区溢出，假设指针和它们指向的对象大小相同，引用指针而不是它所指向的对
象，误解指针运算，引用不存在的变量，以及引起内存泄漏。













