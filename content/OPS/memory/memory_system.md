---
title: "存储器层次结构"
date: 2023-11-22T14:08:48+08:00
draft: true
---

# 存储器层级结构
存储技术
- SRAM存储器
- DRAM存储器
- ROM存储器

## 1. 存储技术
### 1. 随机访问存储器
随机访问存储器(Random-Access Memory，RAM) 分为两类:静态的和动态的。静态 RAM( SRAM) 比动态RAM( DRAM) 更快，
但也贵得多。SRAM 用来作为高速缓存存储器，既可以在CPU 芯片上，也可以在片下。DRAM用来作为主存以及图形系统的帧缓冲
区。典型地，一个桌面系统的SRAM不会超过几兆字节，但是DRAM却有几百或几千兆字节。

#### 1. 静态RAM
SRAM将每个位存储在一个双稳态的(bi stable)存储器单元里。每个单元是用一个六晶体管电路来实现的。
这个电路有这样一个属性，它可以无限期地保持在两个不同的电压配置(configuration )或状态(state)
之一。其他任何状态都是不稳定的一一从不稳定状态开始，电路会迅速地转移到两个稳定状态中的一个。

由于SRAM存储器单元的双稳态特性，只要有电，它就会永远地保持它的值。即使有干扰(例如电子噪音)来扰乱电压，
当干扰消除时，电路就会饮复到稳定值。

#### 2. 动态RAM
DRAM将每个位存储为对一个电容的充电。这个电容非常小，通常只有大约30亳徽微法拉(femtofarad) --30 × 10^15法拉。不过，
回想一下法拉是一个非常大的计量单位。 DRAM存储器可以制造得非常密集--每个单元由一个电容和一个访问晶体管组成。但是，与
SRAM不同，DRAM存储器单元对干扰非常敏感。当电容的电压被扰乱之后，它就永远不会饮复了。暴露在光线下会导致电容电压改变。
实际上，数码照相机和摄像机中的传感器本质上就是DR AM 单元的阵列。


很多原因会导致漏电，使得DRAM单元在10 ~ 100毫秒时间内失去电荷。幸运的是，计算机运行的时钟周期是以纳秒来衡量的，所以相
对而言这个保持时间是比较长的。内存 系统必须周期性地通过读出，然后重写来刷新内存每一位。有些系统也使用纠错码，其中计算机
的字会被多编码几个位(例如64位的字可能用72位来编码)，这样一来 ，电路可以发现并纠正一个字中任何单个的错误位。

| RAM  | 每位晶体管数 | 相对访问时间 | 持续的？ | 敏感的？ | 相对花费  | 应用      |
|------|--------|--------|------|------|-------|---------|
| SRAM | 6      | 1*     | 是    | 否    | 1000* | 高速缓存存储器 |
| DRAM | 1      | 10*    | 否    | 是    | 1*    | 主存，帧缓冲区 |

#### 3. 传统的DRAM
DRAM芯片中的单元(位)被分成d个超单元(supercell)，每个超单元都由w个DRAM单元组成。一个d*w的DRAM总共存储了
dw位信息。超单元被组织成一个，r行c列的长方形阵列，这里rc=d。每个超单元有形如(i，j)的地址，这里i表示行，
而j表示列.

每个DRAM芯片被连接到某个称为内存控制器(memorycontroller )的电路，这个电路可以一次传送w位到每个DRAM芯片
或一次从每个DRAM芯片传出w位。为了读出超单元(i，j)的内容，内存控制器將行地址i 发送到DRAM，然后是列地址j。
DRAM把超单元(i，j)的内容发回给控制器作为响应。行地址i称为RAS(Row AccessStrobe, 行访问选通脉冲)请求。列
地址j称为CAS(Column AccessStrobe，列访问选通脉冲)请求。注意，RAS和CAS 清求共享相同的DRAM地址引脚。

电路设计者将DRAM组织成二维阵列而不是线性数组的一个原因是降低芯片上地址引脚的数量。例如，如果示例的128位DRAM
被组织成一个16个超单元的线性数组，地址为0~15，那么芯片会需要4个地址引脚而不是2个。二维阵列组织的缺点是必须分
两步发送地址，这增加了访问时间。

#### 4. 内存模块
DRAM芯片封装在内存模块(memory module)中，它插到主板的扩展槽上。Corei7系统使用的240个引脚的双列直插
内存模块(Dual Inline Memory Module,DIMM)，它以64位为块传送数据到内存控制器和从内存控制器传出数据。

#### 5. 增强的DRAM
- 快页模式DRAM(Fast Page Mode DRAM,FPMDRAM)：传统的DRAM将超单元的一整行复制到它的内部行缓冲区中，使用一个，然后丢弃剩余的。
FPMDRAM允许对同一行连续地访问可以直接从行缓冲区得到服务，从而改进了这一点。例如，要从一个传统的DRAM的行i中读4个超单元，内存
控制器必须发送4个RAS/CAS请求，即使是行地址i在每个情况中都是一样的。要从一个FPMDRAM的同一行中读取超单元，内存控制器发送第一
个RAS/CAS请求，后面跟三个CAS请求。初始的RAS/CAS请求将行i复制到行缓冲区，并返回CAS寻址的那个超单元。接下来三个超单元直接从
行缓冲区获得，因此返回得比初始的超单元更快。
- 扩展数据出DRAM(Extended Data OutDRAM,EDODRAM):FPMDRAM的一个增强的形式，它允许各个CAS信号在时间上靠得更紧密一点.
- 同步DRAM(Synchronous DRAM，SDRAM):就它们与内存控制器通信使用一组显示的控制信号来说，常规的、FPM和EDO DRAM都是异步的。
SDRAM用与驱动内存控制器相同的外部时钟信号的上升沿来代替许多这样的控制信号。我们不会深人讨论细节，最终效果就是SDRAM能够比那些
异步的存储器更快地输出它的超单元的内容。
- 双倍数据速率同步DRAM(Double Data-Rate Synchronous DRAM,DDRSDRAM)：DDR SDRAM是对SDRAM的一种增强，它通过使用两个时钟沿
作为控制信号，从而使DRAM的速度翻倍。不同类型的DDR SDRAM是用提高有效带宽的很小的预取缓冲区的大小来划分的:DDR(2位)、DDR2(4位)和DDR(8位)。
- 视频RAM(Video RAM,VRAM)：它用在图形系统的帧缓冲区中。VRAM的思想与FPMDRAM类似。两个主要区别是:
1)VRAM的输出是通过依次对内部缓冲区的整个内容进行移位得到的;
2)VRAM允许对内存并行地读和写。因此，系统可以在写下一次更新的新值(写)的同时，用帧缓冲区中的像素刷屏幕(读)。

#### 6. 非易失性存储器
如果断电，DRAM和SRAM 会丟失它们的信息，从这个意义上说，它们是易失的 (volatile)。

非易失性存储器(non volatile memory)即使是在关电后，仍然保存着它们的信息。现在有
很多种非易失性存储器。由于历史原因，虽然ROM中有的类型既可以读也可以写，但是它们整体
上都被称为只读存储器(Read-OnlyMemory,ROM)。ROM是以它们能够被重编程(写)的次数和
对它们进行重编程所用的机制来区分的。

可擦写可编程ROM(Erasable Programmable ROM,EPROM)有一个透明的石英窗又，允许光
到达存储单元。紫外线光照射过窗口，EPROM单元就被清除为0。对EPROM编程是通过使用一种
把1写入EPROM的特殊设备来完成的。EPROM能够被擦除和重编程的次数的数量级可以达到1000
次。电子可擦除PROM(Electrically ErasableP ROM,EEPROM)类似于EPROM，但是它不需
要一个物理上独立的编程设备，因此可以直接在印制电路卡上编程。EEPROM能够被编程的次数的
数量级可以达到10^5次。

闪存(flash memory)是一类非易失性存储器，基于EEPROM，它己经成为了一种重要的存储技术。
闪存无处不在，为大量的电子设备提供快速而持久的非易失性存储，包括数码相机、手机、音乐播放
器、PDA和笔记本、台式机和服务器计算机系统。(固态硬盘)

#### 7. 访问主存
数据流通过称为总线(bus)的共享电子电路在处理器和DRAM主存之间来来回回。
每次CPU和主存之间的数据传送都是通过一系列步骤来完成的，这些步骤称为**总线事务(bustransaction)**。
- 读事务(read transaction)从主存传送数据到CPU。
- 写事务(write transaction)从CPU传送数据到主存。

总线是一组并行的导线，能携带地址、数据和控制信号。取决于总线的设计，数据和地址信号可以共享同一组导线，
也可以使用不同的。同时，两个以上的设备也能共享同一总线。控制线携带的信号会同步事务，并标识出当前正在被
执行的事务的类型。例如，当前关注的这个事务是到主存的吗?还是到诸如磁盘控制器这样的其他I/O设备?这个事务
是读还是写?总线上的信息是地址还是数据项?

movq A, %rax 会发生什么（A是地址）:
这里，地址A的内容被加载到寄存器%rax中。CPU芯片上称为总线接又(bus interface)的电路在总线上发起读事务。
读事务是由三个步骤组成的。首先，CPU將地址A放到系统总线上。I/O桥将信号传递到内存总线。
接下来，主存感觉到内存总线上的地址信号，从内存总线读地址，从DRAM取出数据字，并将数据
写到内存总线。I/O桥将内存总线信号翻译成系统总线信号，然后沿着系统总线传递 。
最后，CPU感觉到系统总线上的数据，从总线上读数据，并将数据复制到寄存器%rax。

反过来movq %rax, A:奇存器%rax的内容被写到地址A，CPU发起写事务。同样，有三个基本步骤。
首先，CPU將地址放到系统总线上。内存从内存总线读出地址，并等待数据到达。接下来，CPU将%rax
中的数据字复制到系统总线。最后，主存从内存总线读出数据宇，并且将这些位存储到DRAM中。

### 2. 磁盘存储
磁盘是广为应用的保存大量数据的存储设备，存储数据的数量级可以达到几百到几千千兆字节，而基于RAM的存储器只能
有几百或几千兆字节。不过，从磁盘上读信息的时间为毫秒级，比从DRAM读慢了10万倍，比从SRAM读慢了100万倍。

#### 1. 磁盘构造
磁盘是由盘片(platter)构成的。每个盘片有两面或者称为表面(surface)，表面覆盖着磁性记录材料。
独片中央有一个可以旋转的主轴(spindle)，它使得盘片以固定的旋转速率(rotational rate)旋转，
通常是5400~15000转每分钟(Revolution Per Minute,RPM)。磁盘通常包含一个或多个这样的盘片，
并封装在一个密封的容器内。 

每个表面是由一组称为碰道(track)的同心圆组成的。每个磁道被划分为一
组扇区(sector)。每个扇区包含相等数量的数据位(通常是512字节)，这些数据编码在扇区上的磁性材料
中。扇区之间由一些间隙(gap)分隔开，这些间隙中不存储数据位。间隙存储用来标识扇区的格式化位。

磁盘是由一个或多个叠放在一起的盘片组成的，它们被封装在一个密封的包装里，整个装置通常被称为
磁盘驱动器(disk drive)，我们通常简称为磁盘(disk)。有时，我们会称磁盘为旋转磁盘(rotating disk)，
以使之区别于基于闪存的固态硬盘(SSD)，SSD是没有移动部分的。 磁盘制造商通常用术语柱面(cylinder)来描
述多个盘片驱动器的构造，这里，柱面是所有盘片表面上到主轴中心的距离相等的磁道的集合。
例如，如果一个驱动器有三个盘片和六个面，每个表面上的磁道的编号都是一致的，那么柱面k就是6个磁道k的集合。

#### 2. 磁盘容量
一个磁盘上可以记录的最大位数称为它的最大容量，或者简称为容量。磁盘容量是由以下技术因素决定的:
- 记录密度(recording density)(位/英寸):磁道一英寸的段中可以放人的位数。
- 磁道密度(track density)(道/英寸):从盘片中心出发半径上一英寸的段内可以有的磁道数。
- 面密度(arealdensity)(位/平方英寸):记录密度与磁道密度的乘积。

磁盘容量 = 字节数(每扇区） * 平均扇区数（(每磁道) * 磁道数(每表面) * 表面数(每盘片) * 盘片数(每磁盘)

#### 3. 磁盘操作
#### 4. 逻辑磁盘块

#### 5. 连接I/Os设备
虽然I/0总线比系统总线和内存总线慢，但是它可以容纳种类繁多的第三方I/0设备。

- 通用串行总线(Universal Serial Bus,USB)控制器是一个连接到USB总线的设备的中转机构，
USB总线是一个广泛使用的标准，连接各种外围I/0设备，包括键盘、鼠标、调制解调器、数码相机、
游戏操纵杆、打印机、外部磁盘驱动器和固态硬盘。USB3.0总线的最大带宽为625MB/s。USB3.1总线的最大带宽为1250MB/s。
- 图形卡(或造配器)包含硬件和软件逻辑，它们负责代表CPU在显示器上画像素。
- 主机总线适配器将一个或多个磁盘连接到I/O总线，使用的是一个特别的主机总线接口定义的通信协议。
两个最常用的这样的磁盘接又是SCSI(读作“scuzzy”)和SATA(读作“sat-uh”。SCSI磁盘通常比SATA
驱动器更快但是也更费。SCSI主机总线适配器(通常称为SCSI控制器)可以支持多个磁盘驱动器，与SATA
适配器不同，它只能支持一个驱动器。

#### 6. 访问磁盘

### 3. 固态硬盘
固态硬盘(Solid State Disk，SSD)是一种基于闪存的存储技术，在某些情况下是传统旋转磁盛的极有
吸引力的替代产品。SSD封装插到I/O总线上标准硬盘插槽(通常是USB或SATA)中，行为就和其他硬盘一样，
处理来自CPU的读写逻辑磁盘块的请求。一个SSD封装由一个或多个闪存芯片和闪存翻译层(flash translation layer)组成，
闪存芯片替代传统旋转磁盘中的机械驱动器，而闪存翻译层是一个硬件/固件设备，扮演与磁盘控制器相同的角色，
将对逻辑块的请求翻译成对底层物理设备的访问。

读SSD比写要快。随机读和写的性能差别是由底层闪存基本属性决定的。一个闪存由B个块的序列组成，每个块由P页组成。
通常，页的大小是512字节~4KB，块是由32~128页组成的，块的大小为16KB~512KB。数据是以页为单位读写的。只有在
一页所属的块整个被擦除之后，才能写这一页(通常是指该块中的所有位都被设置为1)。不过，一旦一个块被擦除了，块中
每一个页都可以不需要再进行擦除就写一次。在大约进行100000次重复写之后，块就会磨损坏。一旦一个块磨损坏之后，
就不能再使用了。

随机写很慢，有两个原因。首先，擦除块篇要相对较长的时间，1ms级的，比访问页所需时问要高一个数量级。
其次，如果写操作试图修改一个包含已经有数据(也就是不是全为1)的页力，那么这个块中所有带有用数据的页
都必须被复制到一个新(擦除过的)块，然后才能进行对页p的写。制造商已经在闪存翻译层中实现了复杂的逻辑，
试图抵消擦写块的高昂代价，最小化内部写的次数，但是随机写的性能不太可能和读一样好。

比起旋转磁盘，SSD有很多优点。它们由半导体存储器构成，没有移动的部件，因而随机访问时间比旋转磁盘要快，
能耗更低，同时也更结实。不过，也有一些缺点。首先，因为反复写之后，闪存块会磨损，所以SSD也容易磨损。
闪存翻译层中的平均磨损(wear leveling)逻辑试图通过将擦除平均分布在所有的块上来最大化每个块的寿命。

## 2. 局部性
一个编写良好的计算机程序常常具有良好的局部性(locality)。也就是，它们倾向于引用邻近于其他最近引用过
的数据项的数据项，或者最近引用过的数据项本身。这种倾向性，被称为局部性原理(principle of locality)，
是一个持久的概念，对硬件和软件系统的设计和性能都有着极大的影响。

局部性通常有两种不同的形式:时间局部性(temporal locality) 和空间局部性(spatial locality)。
在一个具有良好时间局部性的程序中，被引用过一次的内存位置很可能在不远的将来再被多次引用。 
在一个具有良好空间局部性的程序中，如果一个内存位置被引用了一次，那么程序很可能在不远的将来引用附近的一个内存位置。

**有良好局部性的程序比局部性差的程序运行得更快。**

在硬件层，局部性原理允许计算机设计者通过引人称为`高速缓存存储器`的小而快速的存储器来保存最近被引用
的指令和数据项，从而提高对主存的访问速度。在操作系统级，局部性原理允许系统使用主存作为虛拟地址空间
最近破引用块的高速绥存。类似地，操作系统用主存来缓存磁盘文件系统中最近被使用的磁盘块。局部性原理在
应用程序的设计中也扮演着重要的角色。

### 1. 对程序数据引用的局部性
顺序访问一个向量每个元素的两数，具有步长为1的引用模式(stride-1reference pattern)(相对于元素的大小)。
有时我们称步长为1的引用模式为顺序引用模式(sequential reference pattern)。一个连续向量中，每隔人个元
素进行访问，就称为步长为大的引用模式(stride-k reference pattern)。步长为1的引用模式是程序中空间局部
性常见和重要的来源。一般而言，随着步长的增加，空间局部性下降。

二维数组先循环行，在循环列（**行优先顺序**），比较符合局部空间性

### 2. 取指令的局部性
因为程序指令是存放在内存中的，CPU必须取出(读出)这些指令，所以我们也能够评价一个程序关于取指令的局部性。

代码区别于程序数据的一个重要属性是在运行时它是不能被修改的。当程序正在执行时，CPU只从内存中读出它的指令。CPU很少会重写或修改这些指令.

### 3. 局部性小结
- 重复引用相同变量的程序有良好的时间局部性
- 对于具有步长为么的引用模式的程序，生长越小，空间局部性越好。
具有步长为1的引用模式的程序有很好的空间局部性。在内存中以大步长跳来跳去的程序空间局部性会很差。
- 对于取指令来说，循环有好的时间和空间局部性。循环体越小，循环迭代次数越多，局部性越好。

## 3. 存储器层次结构
- 存储技术:不同存储技术的访问时间差异很大。速度较快的技术每字节的成本要比速度较慢的技术高，
而且容量较小。CPU和主存之间的速度差距在增大。
- 计算机软件:一个编写良好的程序倾向于展示出良好的局部性。

计算中一个喜人的巧合是，硬件和软件的这些基本属性互相补充得很完美。它们这种相互补充的性质使人想到一种
组织存储器系统的方法，称为存储器层次结构(memory hierarchy)，所有的现代计算机系统中都使用了这种方法

存储器结构：
表中从上往下，更大，更慢和每字节成本更低的存储设备
表中从下往上，更小，更快和每字节成本更高的存储设备

| 符号 | 名称                     | 作用                     |
|----|------------------------|------------------------|
| L0 | 寄存器                    | CPU寄存器保存着从高速缓存存储器取出的字  |
| L1 | L1高速缓存(SRAM)           | L1高速缓存保存着从L2高速缓存取出的缓存行 |
| L2 | L2高速缓存(SRAM)           | L2高速缓存保存着从L3高速缓存取出的缓存行 |
| L3 | L3高速缓存(SRAM)           | L2高速缓存保存着从主存高速缓存取出的缓存行 |
| L4 | 主存(DRAM)               | 主存保存着从本地磁盘取出的磁盘块       |
| L5 | 本地二级存储(本地磁盘)           | 本地磁盘保存着从远程网络服务器磁盘取出的文件 |
| L6 | 远程二级存储（分布式文件系统，web服务器） | --                     |

在最高层(L0)，是少量快速的CPU寄存器，CPU可以在一个时钟周期内访问它们。
接下来是一个或多个小型到中型的基于SRAM的高速缓存存储器，可以在几个CPU时钟周期内访间它们。
然后是一个大的基于DRAM的主存，可以在几十到几百个时钟周期内访问它们。
接下来是慢速但是容量很大的本地磁盘。
最后，有些系统甚至包括了一层附加的远程服务器上的磁盘，要通过网络来访问它们。

### 1. 存储器层次结构中的缓存
一般而言，高速缓存(cache，读作“cash”)是一个小而快速的存储设备，它作为存储
在更大、也更慢的设备中的数据对象的缓冲区域。使用高速缓存的过程称为缓存(caching.读作“cashing”)。
存储器层次结构的中心思想是，对于每个k，位于k层的更快更小的存储设备作为位于k十1层的更大更慢的存储设
备的缓存。换句话说，层次结构中的每一层都缓存来自较低一层的数据对象。

数据总是以块大小为传送单元(transfer unit)在第k层和第k+1层之间来回复制的。
虽然在层次结构中任何一对相邻的层次之间块大小是固定的，但是其他的层次对之间可以有不同的块大小。

L1和LO之间的传送通常使用的是1个字大小的块。L2和L1之间(以及L3和L2之间、L4和L3之间)的传送通常使用的是几十个字节的块。
而L5和L4之间的传送用的是大小为几百或几千字节的块。

#### 1. 缓存命中
当程序需要第k+1层的某个数据对象d时，它首先在当前存储在第k层的一个块中查找d。
如果d刚好缓存在第k层中，那么就是我们所说的缓存命中(cache hit)。
该程序直接从第k层读取d，根据存储器层次结构的性质，这要比从第k+1层读取d更快。
例如，一个有良好时间局部性的程序可以从块14中读出一个数据对象，得到一个对第k层的缓存命中。

#### 2. 缓存不命中
如果第k层中没有缓存数据对象d，那么就是我们所说的缓存不命中(cache miss)。
当发生缓存不命中时，第k层的缓存从第k+1层缓存中取出包含d的那个块，
如果第k层的缓存已经满了，可能就会覆盖现存的一个块。
覆盖一个现存的块的过程称为替换(replacing)或驱逐(evicting)这个块。
被驱逐的这个块有时也称为辆牲块(victim block)。
决定该替换哪个块是由缓存的替换策略(replace-ment policy)来控制的。
例如，一个具有**随机替换策略**的缓存会随机选择一个辆牲块。
一个具有最近**最少被使用(LRU)替换策略**的缓存会选择那个最后被访问的时间距现在最远的块。
在第k层缓存从第k+1层取出那个块之后，程序就能像前面一样从第k层读出d了


扩展：
LFU（最不频繁使用）：LFU策略根据数据项被访问的频率来确定淘汰哪些数据。
访问次数最少的数据项将被优先淘汰。LFU的核心思想是，访问频次较高的数据项可能在未来还会被多次访问，
因此应该保留在缓存中。为了实现LFU策略，可以使用最小堆或者哈希表等数据结构。

FIFO（First In First Out）：先进先出策略。根据数据项进入缓存的顺序来确定淘汰哪些数据。最先进入缓存的数据项将被优先淘汰。

过期时间（Expiration）：根据数据项的过期时间来确定淘汰哪些数据。过期的数据项将被优先淘汰。

#### 3. 缓存不命中的种类

#### 4. 缓存管理

### 2. 存储器层次结构概念小结
概括来说，基于缓存的存储器层次结构行之有效，是因为较慢的存储设备比较快的存储设备更便宜，还因为程序倾向于展示局部性:
- 利用时间局部性:由于时间局部性，同一数据对象可能会被多次使用。
一旦一个数据对象在第一次不命中时被复制到缓存中，我们就会期望后面对该目标有一系列的访问命中。
因为缓存比低一层的存储设备更快，对后面的命中的服务会比最开始的不命中快很多。
- 利用空间局部性:块通常包含有多个数据对象。由于空间局部性，我们会期望后面对该块中其他对象的访问能够补偿不命中后复制该块的花费。

| 类型     | 缓存什么     | 被缓存在何处     | 延迟（周期数）       | 由谁管理     |
|--------|----------|------------|---------------|----------|
| CPU寄存器 | 4字节或8字节字 | 芯片上的CPU寄存器 | 0             | 编译器      |
| TLB    | 地址翻译     | 芯片上的TLB    | 0             | 硬件MMU    |
| L1高速缓存 | 64字节块    | 芯片上的L1高速缓存 | 4             | 硬件       |
| L2高速缓存 | 64字节块    | 芯片上的L2高速缓存 | 10            | 硬件       |
| L3高速缓存 | 64字节块    | 芯片上的L3高速缓存 | 50            | 硬件       |
| 虚拟内存   | 4KB页     | 主存         | 200           | 硬件+os    |
| 缓存区缓存  | 部分文件     | 主存         | 200           | os       |
| 磁盘缓存   | 磁盘扇区     | 磁盘控制器      | 100 000       | 控制器固件    |
| 网络缓存   | 部分文件     | 本地磁盘       | 10 000 000    | NFS客户    |
| 浏览器缓存  | Web页     | 本地磁盘       | 10 000 000    | Web浏览器   |
| Web缓存  | Web页     | 远程服务器磁盘    | 1 000 000 000 | Web代理服务器 |

- TLB:翻译后备缓冲器(TranslationLookasideBuffer)
- MMU:内存管理单元(MemoryManagementUnit)
- 0S:操作系统(OperatingSystem)
- AFS:安德鲁文件系统(AndrewFileSystem)
- NFS:网络文件系统(NetworkFileSystem)

## 4. 高速缓存存储器
早期计算机系统的存储器层次结构只有三层:CPU寄存器、DRAM主存储器和磁盘存储。
不过，由于CPU和主存之间逐渐增大的差距，系统设计者被迫在CPU寄存器文件和主存
之间插人了一个小的SRAM高速缓存存储器，称为L1高速缓存(一级缓存)。
L1高速缓存的访问速度几乎和奇存器一样快，典型地是大约4个时钟周期。

随着CPU和主存之间的性能差距不断增大，系统设计者在L1高速缓存和主存之间又插入
了一个更大的高速缓存，称为L2高速缓存，可以在大约10个时钟周期内访问到它。有些
现代系统还包括有一个更大的高速缓存，称为L3高速缓存，在存储器层次结构中，它位
于L2高速缓存和主存之间，可以在大约50个周期内访问到它。虽然安排上有相当多的变
化，但是通用原则是一样的。

### 1. 通用的高速缓存存储器组织结构
地址A（m-1位）:(t位标记) + （s位组索引）+（b位块偏移）

当一条加载指令指示CPU从主存地址A中读一个字时，它将地址A发送到高速缓存。
如果高速缓存正保存着地址A处那个字的副本，它就立即将那个字发回给CPU。
高速缓存的结构使得它能通过简单地检查地址位，找到所请求的字，类似于使
用极其简单的哈希两数的哈希表。下面介绍它是如何工作的:
A中s个组索引位是一个到S个组的数组的素引。第一个组是组0，第二个组是组1，依此类推。
组素引位被解释为一个无符号整数，它告诉我们这个字必须存储在哪个组中。一旦我们知道了
这个字必须放在哪个组中，A中的t个标记位就告诉我们这个组中的哪一行包含这个字(如果有
的话)。当且仅当设置了有效位并且该行的标记位与地址A中的标记位相匹配时，组中的这一行
才包含这个字。一旦我们在由组索引标识的组中定位了由标号所标识的行，那么b个块偏移位给
出了在B个字节的数据块中的字偏移。

基本参数：

| 参数          | 描述         |
|-------------|------------|
| S=2^s       | 组数         |
| E           | 每个组的行数     |
| B=2^b       | 块大小(字节)    |
| m = log2(M) | （主存）物理地址位数 |

衍生出来的量

| 参数            | 描述                         |
|---------------|----------------------------|
| M=2^m         | 内存地址的最大数量                  |
| s=log2(S)     | 组索引位数量                     |
| b=log2(B)     | 块偏移位数量                     |
| t = m - (s+b) | 标记为数量                      |
| C=B*E*S       | 不包括像有效位和标记位这样开销的高速缓存大小（字节） |

### 2. 直接映射高速缓存
根据每个组的高速级存行数E，高速级存被分为不同的类。每个组只有一行(E==1)的高速缓存
称为直接映射高速缓存(direct-mapped cache)

高速缓存确定一个请求是否命中，然后抽取被请求的字的过程
- 组选择
- 行匹配
- 字抽取

1. 直接映射高速缓存中的组选择
在这一步中，高速缓存从w的地址中间抽取出、个组素引位。这些位被解释成一个对应于一个组号的无符号整数。
换句话来说，如果我们把高速缓存看成是一个关于组的一维数组，那么这些组素引位就是一个到这个数组的素引。
2. 直接映射高速缓存中的行匹配
在上一步中我们己经选择了某个组之，接下来的一步就要确定是否有字w的一个副本存储在组之包含的一个高速缓
存行中。在直接映射高速缓存中这很容易，而且很快，这是因为每个组只有一行。当且仅当设置了有效位，而且高
速缓存行中的标记与we的地址中的标记相匹配时，这一行中包含么的一个副本.
3. 直接映射高速缓存中的字选择
一旦命中，我们知道w就在这个块中的某个地方。最后一步确定所需要的字在块中是从哪里开始的。
4. 直接映射高速缓存中不命中的行替换
一般而言，如果组中都是有效高速绥存行了，那么必领要驱逐出一个现存的行。对于直接映射高速缓存来说，
每个组只包含有一行，替换策略非常简单:用新取出的行替换当前的行。
5. 综合：运行中的直接映射高速缓存
6. 直接映射高速缓存中的冲突不命中
冲突不命中在真实的程序中很常见，会导致令人困惑的性能问题。当程序访问大小为2的幂的数组时，直
接映射高速缓存中通常会发生冲突不命中。

### 3. 组相联高速缓存
直接映射高速级存中冲突不命中造成的问题源于每个组只有一行(或者，按照我们的术语来描述就是E=1)这个限制。
组相联高速缓存(set associative cache)放松了这条限制，所以每个组都保存有多于一个的高速级存行。
一个1<E<C/B的高速缓存通常称为卫路组相联高速缓存。

1. 组相联高速缓存中的组选择
它的组选择与直接映射高速缓存的组选择一样，组素引位标识组。
2.  组相联高速缓存中的行匹配和字选择
组相联高速缓存中的行匹配比直接映射高速缓存中的更复杂，因为它必须检查多个行的标记位和有效位，以确定所请
求的字是否在集合中。传统的内存是一个值的数组，以地址作为输人，并返回存储在那个地址的值。另一方面，相联
存储器是一个(key，value)对的数组，以key为输人，返回与输人的key相匹配的(key，value)对中的value值
。因此，我们可以把组相联高速缓存中的每个组都看成一个小的相联存储器，key是标记和有效位，而value就是块
的内容。
3. 组相联高速缓存中不命中时的行替换
如果CPU请求的字不在组的任何一行中，那么就是缓存不命中，高速缓存必须从内存中取出包含这个字的块。不过，一
旦高速缓存取出了这个块，该替换哪个行呢?当然，如果有一个空行，那它就是个很好的候选。但是如果该组中没有空行
，那么我们必须从中选择一个非空的行，希望CPU不会很快引用这个被替换的行。（替换策略：LFU,LRU）

### 4. 全相联高速缓存
全相联高速缓存(fully associative cache)是由一个包含所有高速缓存行的组(即E=C/B)组成的。

1. 全相联高速缓存中的组选择
全相联高速缓存中的组选择非常简单，因为只有一个组
2. 全相联高速缓存中的行匹配和字选择
全相联高速缓存中的行匹配和字选择与组相联高速缓存中的是一样的

因为高速缓存电路必须并行地搜素许多相匹配的标记，构造一个又大又快的相联高速 缓存很困难，而且很昂贵。
因此，全相联高速缓存只适合做小的高速缓存，例如虛拟内存系统中的翻译备用缓冲器(TLB)

### 5. 有关写的问题
写的情况要比读复杂一些。

- 直写：就是立即将w的高速缓存块写回到紧接着的低一层中。虽然简单，但是直写的缺点是每次写都会引起总线流量。
- 写回：尽可能地推迟更新，只有当替换算法要驱逐这个更新过的块时，才把它写到紧接着的低一层中。由于局部性，
写回能显著地减少总线流量，但是它的缺点是增加了复杂性。高速缓存必须为每个高速缓存行维护一个额外的修改位
(dirtybit)，表明这个高速缓存块是否被修改过。

处理写不命中：
写分配：加载相应的低一层中的块到高速缓存中，然后更新这个高速缓存块。写分配试图利用写的空间局部性，但是缺点
是每次不命中都会导致一个块从低一层传送到高速缓存。另一种方法，称为非写分配(not write-allocate)，避开高
速缓布，直接把这个字写到低一层中。直写高速缓存通常是非写分配的。写回高速缓存通常是写分配的。

### 6. 一个真实的高速缓存层次结构的解剖
实际上，高速缓存既保存数据，也保存指令。只保存指令的高速缓存称为i-cache。只保存程序数据的高速绥存称为d-cache。
既保存指令又包括数据的高速缓存称为统一的高速缓存(unified cache)。现代处理器包括独立的i-cache和d-cache。
这样做有很多原因。有两个独立的高速缓存，处理器能够同时读一个指令字和一个数据宇。i-cache通常是只读的，因此比较
简单。通常会针对不同的访问模式来优化这两个高速缓存，它们可以有不同的块大小，相联度和容量。使用不同的高速缓存
也确保了数据访问不会与指令访问形成冲突不命中，反过来也是一样，代价就是可能会引起容量不命中增加。

### 7. 高速缓存参数的性能影响
- 不命中率(miss rate)。在一个程序执行或程序的一部分执行期间，内存引用不命中的比率。它是这样计算的:不命中数量/引用数量。
- 命中率(hit rate)。命中的内存引用比率。它等于1-不命中率。
- 命中时间(hit time)。从高速缓存传送一个字到CPU所需的时间，包括组选择、行确认和宇选择的时间。
- 对于L1高速缓存来说，命中时间的数量级是几个时钟周期。
- 不命中处罚(miss penalty)。由于不命中所需要的额外的时间。L1不命中需要从12得到服务的处罚，
通常是数10个周期;从L3得到服务的处罚，50个周期;，从主存得到的服务的处罚，200个周期。

1. 高速缓存大小的影响
一方面，较大的高速缓存可能会提高命中率。另一方面，使大存储器运行得更快总是要难一些的。结果，较大的高速缓存可能会增加命中时间。
这解释了为什么L1高速缓存比L2高速缓存小，以及为什么L2高速缓存比L3高速缓存小
2. 块大小的影响
大的块有利有弊。一方面，较大的块能利用程序中可能存在的空间局部性，帮助提高命中率。不过，对于给定的
高速缓存大小，块越大就意味着高速缓存行数越少，这会损害时问局部性比空间局部性更好的程序中的命中率。
较大的块对不命中处罚也有负面影响，因为块越大，传送时间就越长。现代系统(如Core-i7)会折中使
高速缓存块包含64个字节。
3. 相联度的影响
这里的问题是参数E选择的影响，E是每个组中高速缓存行数。较高的相联度(也就是E的值较大)
的优点是降低了高速缓存由于冲突不命中出现抖动的可能性。不过，较高的相联度会造成较高的
成本。较高的相联度实现起来很昂贵，而且很难使之速度变快。每一行需要更多的标记位，每一行
需要额外的LRU状态位和额外的控制逻辑。较高的相联度会增加命中时间，因为复杂性增加了，
另外，还会增加不命中处罚，因为选择牺牲行的复杂性也增加了。
相联度的选择最终变成了命中时间和不命中处罚之间的折中。传统上，努力争取时钟頻率的高性能系统
会为L1高速缓存选择较低的相联度(这里的不命中处罚只是几个周期)，而在不命中处罚比较高的
较低层上使用比较小的相联度。例如，IntelCore-i7系统中，L1和L2高速缓存是8路组相联的，
而L3高速缓存是16路组相联的。
4. 写策略的影响
直写高速缓存比较容易实现，而且能使用独立于高速缓存的写缓冲区(write buffer)，用来更新内存。
此外，读不命中开销没这么大，因为它们不会触发内存写。
回高速缓存引起的传送比较少，它允许更多的到内存的带宽用于执行DMA的V/O设备。此外，越往层次结构
下面走，传送时间增加，减少传送的数量就变得更加重要。一般而言，高速缓存越往下层，越可能使用写回
而不是直写。

## 5. 编写高速缓存友好的代码
确保代码高速缓存友好的基本方法

-  让最常见的情况运行得快:程序通常把大部分时间都花在少量的核心函数上，而这些函数通常把大部分时间
都花在了少量循环上。所以要把注意力集中在核心函数里的循环上，而忽略其他部分。
- 尽量减 小每个循环内部的缓存不命中数量：在其他条件(例如加载和存储的总次数)相同的情况下，不命中率较低的循环运行得更快。

编写高速缓存友好的代码的重要问题:

- 对局部变量的反复引用是好的，因为编译器能够将它们缓存在寄存器文件中(时间局部性)。
- 步长为1的引用模式是好的，因为存储器层次结构中所有层次上的缓存都是将数据存储为连续的块(空间局部性)。


## 6. 综合：高速缓存对程序性能的影响
### 1. 存储器山
### 2. 重新排列循环以提高空间局部性
### 3. 在程序中利用局部性
- 将你的注意力集中在内循环上，大部分计算和内存访问都发生在这里。
- 通过按照数据对象存储在内存中的顺序、以步长为1的来读数据，从而使得你程序中的空间局部性最大。
- 一旦从存储器中读人了一个数据对象，就尽可能多地使用它，从而使得程序中的时间局部性最大





