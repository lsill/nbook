---
title: "cpu使用率100%处理"
date: 2023-05-16T16:28:48+08:00
draft: true
---

### CPU 使用率
在上一期我曾提到，Linux 作为一个多任务操作系统，将每个 CPU 的时间划分为很短的时间片，再通过调度器轮流分配给各个任务使用，因此造成多任务同时运行的错觉。
为了维护 CPU 时间，Linux 通过事先定义的节拍率（内核中表示为 HZ），触发时间中断，并使用全局变量 Jiffies 记录了开机以来的节拍数。每发生一次时间中断，Jiffies 的值就加 1。
节拍率 HZ 是内核的可配选项，可以设置为 100、250、1000 等。不同的系统可能设置不同数值，你可以通过查询 /boot/config 内核选项来查看它的配置值。比如在我的系统中，节拍率设置成了 250，也就是每秒钟触发 250 次时间中断。
```
root@eBpfTest:~# grep 'CONFIG_HZ' /boot/config-$(uname -r)
# CONFIG_HZ_PERIODIC is not set
# CONFIG_HZ_100 is not set
CONFIG_HZ_250=y
# CONFIG_HZ_300 is not set
# CONFIG_HZ_1000 is not set
CONFIG_HZ=250
```
同时，正因为节拍率 HZ 是内核选项，所以用户空间程序并不能直接访问。为了方便用户空间程序，内核还提供了一个用户空间节拍率 USER_HZ，它总是固定为 100，也就是 1/100 秒。这样，用户空间程序并不需要关心内核中 HZ 被设置成了多少，因为它看到的总是固定值 USER_HZ。
Linux 通过 /proc 虚拟文件系统，向用户空间提供了系统内部状态的信息，而 /proc/stat 提供的就是系统的 CPU 和任务统计信息。比方说，如果你只关注 CPU 的话，可以执行下面的命令：
```
root@eBpfTest:~# cat /proc/stat | grep ^cpu
cpu  1497959 34115 1228968 324641437 38118 0 5030 0 0 0
cpu0 749455 15863 617958 162301193 26518 0 2618 0 0 0
cpu1 748504 18252 611009 162340244 11600 0 2412 0 0 0
```
当然，这里每一列的顺序并不需要你背下来。你只要记住，有需要的时候，查询 man proc 就可以。不过，你要清楚 man proc 文档里每一列的涵义，它们都是 CPU 使用率相关的重要指标，你还会在很多其他的性能工具中看到它们。下面，我来依次解读一下。

- 1497959: user（通常缩写为 us），代表用户态 CPU 时间。注意，它不包括下面的 nice 时间，但包括了 guest 时间。
- 34115: nice（通常缩写为 ni），代表低优先级用户态 CPU 时间，也就是进程的 nice 值被调整为 1-19 之间时的 CPU 时间。这里注意，nice 可取值范围是 -20 到 19，数值越大，优先级反而越低。
- 1228968: system（通常缩写为 sys），代表内核态 CPU 时间。
- 324641437:idle（通常缩写为 id），代表空闲时间。注意，它不包括等待 I/O 的时间（iowait）。
- 38118: iowait（通常缩写为 wa），代表等待 I/O 的 CPU 时间。
- 0: irq（通常缩写为 hi），代表处理硬中断的 CPU 时间。
- 5030: softirq（通常缩写为 si），代表处理软中断的 CPU 时间。
- 0: steal（通常缩写为 st），代表当系统运行在虚拟机中的时候，被其他虚拟机占用的 CPU 时间。
- 0: guest（通常缩写为 guest），代表通过虚拟化运行其他操作系统的时间，也就是运行虚拟机的 CPU 时间。
- 0: guest_nice（通常缩写为 gnice），代表以低优先级运行虚拟机的时间。

而我们通常所说的 CPU 使用率，就是除了空闲时间外的其他时间占总 CPU 时间的百分比，用公式来表示就是：
**cpu使用率 = 1 - 空间时间/总cpu时间**
根据这个公式，我们就可以从 /proc/stat 中的数据，很容易地计算出 CPU 使用率。当然，也可以用每一个场景的 CPU 时间，除以总的 CPU 时间，计算出每个场景的 CPU 使用率。
不过先不要着急计算，你能说出，直接用 /proc/stat 的数据，算的是什么时间段的 CPU 使用率吗？
看到这里，你应该想起来了，这是开机以来的节拍数累加值，所以直接算出来的，是开机以来的平均 CPU 使用率，一般没啥参考价值。
事实上，为了计算 CPU 使用率，性能工具一般都会取间隔一段时间（比如 3 秒）的两次值，作差后，再计算出这段时间内的平均 CPU 使用率，即
**平均cpu使用率=1-(空间时间（new）- 空闲时间(old))/（总cpu时间（new）- 总CPU时间（old））**
这个公式，就是我们用各种性能工具所看到的 CPU 使用率的实际计算方法。
现在，我们知道了系统 CPU 使用率的计算方法，那进程的呢？跟系统的指标类似，Linux 也给每个进程提供了运行情况的统计信息，也就是 /proc/[pid]/stat。不过，这个文件包含的数据就比较丰富了，总共有 52 列的数据。
当然，不用担心，因为你并不需要掌握每一列的含义。还是那句话，需要的时候，查 man proc 就行。

回过头来看，是不是说要查看 CPU 使用率，就必须先读取 /proc/stat 和 /proc/[pid]/stat 这两个文件，然后再按照上面的公式计算出来呢？

当然不是，各种各样的性能分析工具已经帮我们计算好了。不过要注意的是，性能分析工具给出的都是间隔一段时间的平均 CPU 使用率，所以要注意间隔时间的设置，特别是用多个工具对比分析时，你一定要保证它们用的是相同的间隔时间。

### 怎么查看 CPU 使用率
知道了 CPU 使用率的含义后，我们再来看看要怎么查看 CPU 使用率。说到查看 CPU 使用率的工具，我猜你第一反应肯定是 top 和 ps。的确，top 和 ps 是最常用的性能分析工具：
- top 显示了系统总体的 CPU 和内存使用情况，以及各个进程的资源使用情况。
- ps 则只显示了每个进程的资源使用情况。
比如，top(默认每3秒刷新一次) 的输出格式为：
```
top - 17:48:47 up 19 days,  3:18,  3 users,  load average: 0.02, 0.02, 0.00
Tasks: 121 total,   1 running, 120 sleeping,   0 stopped,   0 zombie
%Cpu(s):  0.5 us,  0.5 sy,  0.0 ni, 98.8 id,  0.2 wa,  0.0 hi,  0.0 si,  0.0 st
MiB Mem :   3544.8 total,    245.9 free,    283.8 used,   3015.1 buff/cache
MiB Swap:      0.0 total,      0.0 free,      0.0 used.   2980.9 avail Mem 

    PID USER      PR  NI    VIRT    RES    SHR S  %CPU  %MEM     TIME+ COMMAND                                                                                                                                                            
   1712 root      10 -10  127900  37400  18512 S   1.0   1.0 315:38.66 AliYunDunMonito                                                                                                                                                    
   1702 root      10 -10   76408  13816  11300 S   0.3   0.4 183:46.09 AliYunDun                                                                                                                                                          
      1 root      20   0  182832  12176   8572 S   0.0   0.3   0:31.32 systemd                                                                                                                                                            
      2 root      20   0       0      0      0 S   0.0   0.0   0:00.23 kthreadd                                                                                                                                                           
      3 root       0 -20       0      0      0 I   0.0   0.0   0:00.00 rcu_gp                                                                                                                                                             
      4 root       0 -20       0      0      0 I   0.0   0.0   0:00.00 rcu_par_gp                                                                                                                                                         
      5 root       0 -20       0      0      0 I   0.0   0.0   0:00.00 slub_flushwq                                                                                                                                                       
      6 root       0 -20       0      0      0 I   0.0   0.0   0:00.00 netns                                                                                                                                                              
      8 root       0 -20       0      0      0 I   0.0   0.0   0:00.00 kworker/0:0H-events_highpri                                                                                                                                        
     10 root       0 -20       0      0      0 I   0.0   0.0   0:00.00 mm_percpu_wq                                                                                                                                                       
     11 root      20   0       0      0      0 S   0.0   0.0   0:00.00 rcu_tasks_rude_                                                                                                                                                    
     12 root      20   0       0      0      0 S   0.0   0.0   0:00.00 rcu_tasks_trace                                                                                                                                                    
     13 root      20   0       0      0      0 S   0.0   0.0   0:02.27 ksoftirqd/0                                                                                                                                                        
     14 root      20   0       0      0      0 I   0.0   0.0   6:07.60 rcu_sched                                                                                                                                                          
     15 root      rt   0       0      0      0 S   0.0   0.0   0:05.54 migration/0   
```
这个输出结果中，第三行 %Cpu 就是系统的 CPU 使用率，具体每一列的含义上一节都讲过，只是把 CPU 时间变换成了 CPU 使用率，我就不再重复讲了。不过需要注意，top 默认显示的是所有 CPU 的平均值，这个时候你只需要按下数字 1 ，就可以切换到每个 CPU 的使用率了。
继续往下看，空白行之后是进程的实时信息，每个进程都有一个 %CPU 列，表示进程的 CPU 使用率。它是用户态和内核态 CPU 使用率的总和，包括进程用户空间使用的 CPU、通过系统调用执行的内核空间 CPU 、以及在就绪队列等待运行的 CPU。在虚拟化环境中，它还包括了运行虚拟机占用的 CPU。
所以，到这里我们可以发现， top 并没有细分进程的用户态 CPU 和内核态 CPU。那要怎么查看每个进程的详细情况呢？你应该还记得上一节用到的 pidstat 吧，它正是一个专门分析每个进程 CPU 使用情况的工具。

比如，下面的 pidstat 命令，就间隔 1 秒展示了进程的 5 组 CPU 使用率，包括：
- 用户态 CPU 使用率 （%usr）；
- 内核态 CPU 使用率（%system）；
- 运行虚拟机 CPU 使用率（%guest）；
- 等待 CPU 使用率（%wait）；
- 以及总的 CPU 使用率（%CPU）。

最后的 Average 部分，还计算了 5 组数据的平均值
```
root@eBpfTest:~# pidstat 1 5
Linux 5.15.0-58-generic (eBpfTest)      05/16/2023      _x86_64_        (2 CPU)

05:59:59 PM   UID       PID    %usr %system  %guest   %wait    %CPU   CPU  Command
06:00:00 PM     0         1    1.00    0.00    0.00    0.00    1.00     0  systemd
06:00:00 PM     0        14    0.00    1.00    0.00    0.00    1.00     1  rcu_sched
06:00:00 PM     0      1712    3.00    0.00    0.00    6.00    3.00     0  AliYunDunMonito
06:00:00 PM     0     69687    1.00    0.00    0.00    0.00    1.00     1  systemd-journal
06:00:00 PM   107     69720    1.00    0.00    0.00    0.00    1.00     1  rsyslogd
06:00:00 PM     0    111439    0.00    1.00    0.00    0.00    1.00     1  kworker/1:3-events
06:00:00 PM     0    112483    0.00    1.00    0.00    0.00    1.00     0  pidstat

06:00:00 PM   UID       PID    %usr %system  %guest   %wait    %CPU   CPU  Command
06:00:01 PM   103       807    1.00    0.00    0.00    0.00    1.00     0  dbus-daemon
06:00:01 PM     0       839    0.00    1.00    0.00    0.00    1.00     0  systemd-logind
06:00:01 PM     0      1472    1.00    0.00    0.00    0.00    1.00     0  aliyun-service
06:00:01 PM     0      1702    1.00    1.00    0.00    0.00    2.00     1  AliYunDun
06:00:01 PM     0      1712    4.00    1.00    0.00    7.00    5.00     1  AliYunDunMonito
06:00:01 PM     0     69696    1.00    0.00    0.00    0.00    1.00     1  polkitd
06:00:01 PM     0    108081    0.00    1.00    0.00    0.00    1.00     1  sshd

06:00:01 PM   UID       PID    %usr %system  %guest   %wait    %CPU   CPU  Command
06:00:02 PM     0         1    1.00    0.00    0.00    0.00    1.00     0  systemd
06:00:02 PM   103       807    0.00    1.00    0.00    1.00    1.00     1  dbus-daemon
06:00:02 PM     0       839    1.00    0.00    0.00    0.00    1.00     0  systemd-logind
06:00:02 PM     0      1712    3.00    0.00    0.00    1.00    3.00     0  AliYunDunMonito
06:00:02 PM     0    112483    0.00    1.00    0.00    0.00    1.00     1  pidstat

06:00:02 PM   UID       PID    %usr %system  %guest   %wait    %CPU   CPU  Command
06:00:03 PM     0      1712    2.00    0.00    0.00    0.00    2.00     0  AliYunDunMonito

06:00:03 PM   UID       PID    %usr %system  %guest   %wait    %CPU   CPU  Command
06:00:04 PM     0      1702    1.00    0.00    0.00    0.00    1.00     1  AliYunDun
06:00:04 PM     0      1712    0.00    1.00    0.00    0.00    1.00     0  AliYunDunMonito
06:00:04 PM     0    112483    0.00    1.00    0.00    0.00    1.00     1  pidstat

Average:      UID       PID    %usr %system  %guest   %wait    %CPU   CPU  Command
Average:        0         1    0.40    0.00    0.00    0.20    0.40     -  systemd
Average:        0        14    0.00    0.20    0.00    0.00    0.20     -  rcu_sched
Average:      103       807    0.20    0.20    0.00    0.20    0.40     -  dbus-daemon
Average:        0       839    0.20    0.20    0.00    0.00    0.40     -  systemd-logind
Average:        0      1472    0.20    0.00    0.00    0.00    0.20     -  aliyun-service
Average:        0      1702    0.40    0.20    0.00    0.00    0.60     -  AliYunDun
Average:        0      1712    2.40    0.40    0.00    2.80    2.80     -  AliYunDunMonito
Average:        0     69687    0.20    0.00    0.00    0.20    0.20     -  systemd-journal
Average:        0     69696    0.20    0.00    0.00    0.00    0.20     -  polkitd
Average:      107     69720    0.20    0.00    0.00    0.00    0.20     -  rsyslogd
Average:        0    108081    0.00    0.20    0.00    0.00    0.20     -  sshd
Average:        0    111439    0.00    0.20    0.00    0.20    0.20     -  kworker/1:3-events
Average:        0    112483    0.00    0.60    0.00    0.00    0.60     -  pidstat
```

### CPU 使用率过高怎么办？
通过 `top`、`ps`、`pidstat` 等工具，你能够轻松找到 CPU 使用率较高（比如 100% ）的进程。接下来，你可能又想知道，占用 CPU 的到底是代码里的哪个函数呢？找到它，你才能更高效、更针对性地进行优化。
我猜你第一个想到的，应该是 GDB（The GNU Project Debugger）， 这个功能强大的程序调试利器。的确，GDB 在调试程序错误方面很强大。但是，我又要来“挑刺”了。请你记住，GDB 并不适合在性能分析的早期应用。
为什么呢？因为 GDB 调试程序的过程会中断程序运行，这在线上环境往往是不允许的。所以，GDB 只适合用在性能分析的后期，当你找到了出问题的大致函数后，线下再借助它来进一步调试函数内部的问题。
那么哪种工具适合在第一时间分析进程的 CPU 问题呢？我的推荐是 perf。perf 是 Linux 2.6.31 以后内置的性能分析工具。它以性能事件采样为基础，不仅可以分析系统的各种事件和内核性能，还可以用来分析指定应用程序的性能问题。
使用 perf 分析 CPU 性能问题，我来说两种最常见、也是我最喜欢的用法。
第一种常见用法是 perf top，类似于 top，它能够实时显示占用 CPU 时钟最多的函数或者指令，因此可以用来查找热点函数，使用界面如下所示：
```
Samples: 7K of event 'cpu-clock:pppH', 4000 Hz, Event count (approx.): 737141626 lost: 0/0 drop: 0/0
Overhead  Shared Object                                   Symbol
   7.42%  [kernel]                                        [k] finish_task_switch.isra.0
   5.76%  [kernel]                                        [k] update_blocked_averages
   3.03%  [kernel]                                        [k] __lock_text_start
   1.98%  perf                                            [.] rb_next
   1.84%  [kernel]                                        [k] __softirqentry_text_start
   1.79%  libc.so.6                                       [.] clock_nanosleep
   1.25%  [kernel]                                        [k] tick_nohz_idle_exit
   1.18%  [kernel]                                        [k] syscall_enter_from_user_mode
   1.04%  [kernel]                                        [k] __run_timers.part.0
   0.99%  [kernel]                                        [k] do_user_addr_fault
   0.90%  [kernel]                                        [k] kallsyms_expand_symbol.constprop.0
   0.87%  perf                                            [.] kallsyms__parse
   0.76%  python3.10                                      [.] _PyEval_EvalFrameDefault
   0.76%  [kernel]                                        [k] clear_page_erms
   0.70%  [kernel]                                        [k] __get_user_8
   0.68%  [kernel]                                        [k] vsnprintf
   0.67%  libc.so.6                                       [.] 0x00000000000a3d7d
   0.67%  perf                                            [.] d_print_comp_inner
   0.65%  perf                                            [.] deliver_event
   0.60%  perf                                            [.] evsel__parse_sample
   0.59%  [kernel]                                        [k] charge_memcg
   0.59%  libc.so.6                                       [.] pthread_mutex_lock
   0.58%  perf                                            [.] ordered_events__queue
   0.57%  [kernel]                                        [k] queue_work_on
   0.56%  perf                                            [.] map__process_kallsym_symbol
   0.55%  perf                                            [.] __symbols__insert
   0.53%  [kernel]                                        [k] format_decode
```
输出结果中，第一行包含三个数据，分别是采样数（Samples）、事件类型（event）和事件总数量（Event count）。比如这个例子中，perf 总共采集了 7K 个 CPU 时钟事件，而总事件数则为 737141626.
另外，采样数需要我们特别注意。如果采样数过少（比如只有十几个），那下面的排序和百分比就没什么实际参考价值了。
再往下看是一个表格式样的数据，每一行包含四列，分别是：
- 第一列 Overhead ，是该符号的性能事件在所有采样中的比例，用百分比来表示。
- 第二列 Shared ，是该函数或指令所在的动态共享对象（Dynamic Shared Object），如内核、进程名、动态链接库名、内核模块名等。
- 第三列 Object ，是动态共享对象的类型。比如 [.] 表示用户空间的可执行程序、或者动态链接库，而 [k] 则表示内核空间。
- 最后一列 Symbol 是符号名，也就是函数名。当函数名未知时，用十六进制的地址来表示。

还是以上面的输出为例，我们可以看到，占用 CPU 时钟最多的是 kernel的 finish_task_switch.isra.0，不过它的比例也只有 7.42%，说明系统并没有 CPU 性能问题。 perf top 的使用你应该很清楚了吧。

接着再来看第二种常见用法，也就是 perf record 和 perf report。 perf top 虽然实时展示了系统的性能信息，但它的缺点是并不保存数据，也就无法用于离线或者后续的分析。而 perf record 则提供了保存数据的功能，保存后的数据，需要你用 perf report 解析展示。
```
# ctrl c 终止采样
root@eBpfTest:~# perf record 
^C[ perf record: Woken up 19 times to write data ]
[ perf record: Captured and wrote 5.320 MB perf.data (93037 samples) ]
root@eBpfTest:~# perf report  # 展示类似于perf top的报告
```
在实际使用中，我们还经常为 perf top 和 perf record 加上 -g 参数，开启调用关系的采样，方便我们根据调用链来分析性能问题。

### 案例
下面我们就以 Nginx + PHP 的 Web 服务为例，来看看当你发现 CPU 使用率过高的问题后，要怎么使用 top 等工具找出异常的进程，又要怎么利用 perf 找出引发性能问题的函数。

#### 准备
- 机器配置：2 CPU，4GB 内存
- 预先安装 docker、sysstat、perf、ab 等工具，如 apt install docker.io sysstat linux-tools-common apache2-utils-

我先简单介绍一下这次新使用的工具 ab。ab（apache bench）是一个常用的 HTTP 服务性能测试工具，这里用来模拟 Ngnix 的客户端。由于 Nginx 和 PHP 的配置比较麻烦，我把它们打包成了两个 Docker 镜像，这样只需要运行两个容器，就可以得到模拟环境。注意，这个案例要用到两台虚拟机，如下图所示：
你可以看到，其中一台用作 Web 服务器，来模拟性能问题；另一台用作 Web 服务器的客户端，来给 Web 服务增加压力请求。使用两台虚拟机是为了相互隔离，避免“交叉感染”。
接下来，我们打开两个终端，分别 SSH 登录到两台机器上，并安装上面提到的工具。还是同样的“配方”。下面的所有命令，都默认假设以 root 用户运行，如果你是普通用户身份登陆系统，一定要先运行 sudo su root 命令切换到 root 用户。到这里，准备工作就完成了。
不过，操作之前，我还想再说一点。这次案例中 PHP 应用的核心逻辑比较简单，大部分人一眼就可以看出问题，但你要知道，实际生产环境中的源码就复杂多了。
所以，我希望你在按照步骤操作之前，先不要查看源码（避免先入为主），而是把它当成一个黑盒来分析。这样，你可以更好地理解整个解决思路，怎么从系统的资源使用问题出发，分析出瓶颈所在的应用、以及瓶颈在应用中的大概位置。
#### 操作和分析
接下来，我们正式进入操作环节。首先，在第一个终端执行下面的命令来运行 Nginx 和 PHP 应用：
```
$ docker run --name nginx -p 10000:80 -itd feisky/nginx
$ docker run --name phpfpm -itd --network container:nginx feisky/php-fpm
```
然后，在第二个终端使用 curl 访问 http://[VM1 的 IP]:10000，确认 Nginx 已正常启动。你应该可以看到 It works! 的响应
```
# 127.0.0.1是第一台虚拟机的IP地址
$ curl http://127.0.0.1:10000/
It works!
```
接着，我们来测试一下这个 Nginx 服务的性能。在第二个终端运行下面的 ab 命令：
```
root@eBpfTest:~# ab -c 10 -n 100 http://127.0.0.1:10000/
This is ApacheBench, Version 2.3 <$Revision: 1879490 $>
Copyright 1996 Adam Twiss, Zeus Technology Ltd, http://www.zeustech.net/
Licensed to The Apache Software Foundation, http://www.apache.org/

Benchmarking 127.0.0.1 (be patient).....done


Server Software:        nginx/1.15.4
Server Hostname:        127.0.0.1
Server Port:            10000

Document Path:          /
Document Length:        9 bytes

Concurrency Level:      10
Time taken for tests:   4.524 seconds
Complete requests:      100
Failed requests:        0
Total transferred:      17200 bytes
HTML transferred:       900 bytes
Requests per second:    22.10 [#/sec] (mean)
Time per request:       452.401 [ms] (mean)
Time per request:       45.240 [ms] (mean, across all concurrent requests)
Transfer rate:          3.71 [Kbytes/sec] received

Connection Times (ms)
              min  mean[+/-sd] median   max
Connect:        0    0   0.1      0       0
Processing:    90  432  75.4    437     568
Waiting:       90  432  75.4    437     567
Total:         90  432  75.4    438     568

Percentage of the requests served within a certain time (ms)
  50%    438
  66%    455
  75%    471
  80%    489
  90%    517
  95%    543
  98%    559
  99%    568
 100%    568 (longest request)
```
从 ab 的输出结果我们可以看到，Nginx 能承受的每秒平均请求数只有 22.10 。你一定在吐槽，这也太差了吧。那到底是哪里出了问题呢？我们用 top 和 pidstat 再来观察下。

这次，我们在第二个终端，将测试的请求总数增加到 10000。这样当你在第一个终端使用性能分析工具时， Nginx 的压力还是继续。继续在第二个终端，运行 ab 命令：
```
root@eBpfTest:~# ab -c -n 10000 http://127.0.0.1:10000/
```

接着，回到第一个终端运行 top 命令，并按下数字 1 ，切换到每个 CPU 的使用率：
```
top - 15:39:13 up 22 days,  1:08,  2 users,  load average: 2.87, 0.84, 0.33
Tasks: 135 total,   6 running, 129 sleeping,   0 stopped,   0 zombie
%Cpu0  : 97.7 us,  1.0 sy,  0.0 ni,  0.0 id,  0.0 wa,  0.0 hi,  1.3 si,  0.0 st
%Cpu1  : 97.7 us,  1.7 sy,  0.0 ni,  0.0 id,  0.0 wa,  0.0 hi,  0.7 si,  0.0 st
MiB Mem :   3544.8 total,    130.1 free,    365.6 used,   3049.1 buff/cache
MiB Swap:      0.0 total,      0.0 free,      0.0 used.   2880.2 avail Mem 

    PID USER      PR  NI    VIRT    RES    SHR S  %CPU  %MEM     TIME+ COMMAND                                                                                                                                                            
 132095 daemon    20   0  336700  15424   7744 R  39.5   0.4   0:19.32 php-fpm                                                                                                                                                            
 132148 daemon    20   0  336700  15360   7680 R  39.5   0.4   0:18.96 php-fpm                                                                                                                                                            
 132141 daemon    20   0  336700  15360   7680 R  38.9   0.4   0:19.48 php-fpm                                                                                                                                                            
 132098 daemon    20   0  336700  15424   7744 R  38.2   0.4   0:19.11 php-fpm                                                                                                                                                            
 132146 daemon    20   0  336700  15360   7680 R  37.9   0.4   0:18.82 php-fpm                                                                                                                                                            
 128691 root      20   0 1296016   4300   2496 S   1.0   0.1   0:00.72 docker-proxy                                                                                                                                                       
 128772 systemd+  20   0   33108   3804   2424 S   1.0   0.1   0:00.63 nginx                                                                                                                                                              
   1702 root      10 -10   76408  13836  11300 S   0.7   0.4 211:57.80 AliYunDun                                                                                                                                                          
   1712 root      10 -10  129236  38016  18756 S   0.7   1.0 364:15.34 AliYunDunMonito                                                                                                                                                    
     14 root      20   0       0      0      0 I   0.3   0.0   7:05.56 rcu_sched                                                                                                                                                          
 114617 root      20   0 1595264  74168  50136 S   0.3   2.0   0:42.21 dockerd                                                                                                                                                            
 128712 root      20   0  712212   9476   7492 S   0.3   0.3   0:00.38 containerd-shim                                                                                                                                                    
 131835 root      20   0       0      0      0 I   0.3   0.0   0:00.03 kworker/u4:1-events_power_efficient                                                                                                                                
 114617 root      20   0 1595264  74168  50136 S   0.3   2.0   0:42.20 dockerd                                                                                                                                                            
 130058 root      20   0  336316  47924  40520 S   0.3   1.3   0:00.17 php-fpm       
```
这里可以看到，系统中有几个 php-fpm 进程的 CPU 使用率加起来接近 200%；而每个 CPU 的用户使用率（us）也已经超过了 98%，接近饱和。这样，我们就可以确认，正是用户空间的 php-fpm 进程，导致 CPU 使用率骤升。

那再往下走，怎么知道是 php-fpm 的哪个函数导致了 CPU 使用率升高呢？我们来用 perf 分析一下。在第一个终端运行下面的 perf 命令：



### 一些问题解答
#### 1.为什么/proc要设计成文件系统类型？不能设计成内存数据库的方式呢？
1.统一性和一致性：将 /proc 设计为文件系统类型使得系统中的各种信息和状态都可以以文件的形式进行访问。这样，无论是进程信息、设备状态、内核参数还是其他系统信息，都可以通过相同的接口进行访问和操作，提供了统一的接口和一致性的访问方式。
2.可编程性和可扩展性：文件系统提供了丰富的文件操作接口，如读取、写入、修改、追加等，这使得对 /proc 中的数据进行编程和操作变得更加灵活和方便。通过文件系统接口，可以编写脚本、工具和程序来自动化配置、监控和管理系统。
3.可视化和易于理解：将系统信息和状态以文件的形式呈现，使得管理员和开发人员可以通过简单的文件读取操作来查看和理解系统的工作方式。这种可视化的方式使得调试、故障排除和性能优化等任务更加直观和可操作。
4.兼容性和跨平台性：文件系统是操作系统中的一项基本功能，几乎所有的操作系统都支持文件系统接口。通过将 /proc 设计为文件系统类型，可以使得在不同的操作系统和平台上都能够使用相同的方法来访问系统信息，提供了良好的兼容性和跨平台性。
尽管内存数据库在某些场景下可能具有更高的性能和效率，但文件系统在可编程性、可视化、兼容性等方面具有优势，并且已经成为了操作系统的核心组成部分。此外，将 /proc 设计为文件系统类型也是为了与现有工具、命令和工作流程的兼容性，使得管理员和开发人员可以继续使用他们熟悉的方式来管理和监控系统。

### 命令的总结
- grep 'CONFIG_HZ' /boot/config-$(uname -r) ： 查询linux内核cpu分片时间
- cat /proc/stat | grep ^cpu ： 查看系统的 CPU 和任务统计信息
- pidstat 1 5 : 间隔 1 秒展示了进程的 5 组 CPU 使用率
- perf top ：实时显示占用 CPU 时钟最多的函数或者指令
- perf record ： perf record 则提供了保存perf数据的功能
- perf report ： 解析perf record保存的数据
