---
title: "平均负载"
date: 2023-05-15T14:35:48+08:00
draft: true
---

### 1.定义
每次发现系统变慢时，我们通常做的第一件事，就是执行 top 或者 uptime 命令，来了解系统的负载情况。比如像下面这样，我在命令行里输入了 uptime 命令，系统也随即给出了结果。

```
$ uptime
02:34:03 up 2 days, 20:14,  1 user,  load average: 0.63, 0.83, 0.88
```
但我想问的是，你真的知道这里每列输出的含义吗？

我相信你对前面的几列比较熟悉，它们分别是当前时间、系统运行时间以及正在登录用户数。

02:34:03              // 当前时间
up 2 days, 20:14      // 系统运行时间
1 user                // 正在登录用户数
而最后三个数字呢，依次则是过去 1 分钟、5 分钟、15 分钟的平均负载（Load Average）。

简单来说，`平均负载`是指单位时间内，系统处于`可运行状态`和`不可中断状态`的平均进程数，也就是平均活跃进程数，它和 CPU 使用率并没有直接关系。
以简单理解为，平均负载其实就是平均活跃进程数。平均活跃进程数，直观上的理解就是单位时间内的活跃进程数，但它实际上是活跃进程数的指数衰减平均值。这个“指数衰减平均”的详细含义你不用计较，这只是系统的一种更快速的计算方式，你把它直接当成活跃进程数的平均值也没问题。

- 可运行状态的进程:是指正在使用 CPU 或者正在等待 CPU 的进程，也就是我们常用 ps 命令看到的，处于 R 状态（Running 或 Runnable）的进程。
- 不可中断状态的进程则是正处于内核态关键流程中的进程，并且这些流程是不可打断的，比如最常见的是等待硬件设备的 I/O 响应，也就是我们在 ps 命令中看到的 D 状态（Uninterruptible Sleep，也称为 Disk Sleep）的进程。
**不可中断状态实际上是系统对进程和硬件设备的一种保护机制。**

既然平均的是活跃进程数，那么最理想的，就是每个 CPU 上都刚好运行着一个进程，这样每个 CPU 都得到了充分利用。比如当平均负载为 2 时，意味着什么呢？
- 在只有 2 个 CPU 的系统上，意味着所有的 CPU 都刚好被完全占用。
- 在 4 个 CPU 的系统上，意味着 CPU 有 50% 的空闲。
- 而在只有 1 个 CPU 的系统中，则意味着有一半的进程竞争不到 CPU。

### 2.平均负载多少合理
我们知道，平均负载最理想的情况是等于 CPU 个数。所以在评判平均负载时，首先你要知道系统有几个 CPU，这可以通过 top 命令或者从文件 /proc/cpuinfo 中读取，比如：
```
root@eBpfTest:~# grep 'model name' /proc/cpuinfo | wc -l
2
```
有了 CPU 个数，我们就可以判断出，当平均负载比 CPU 个数还大的时候，系统已经出现了过载。
不过，且慢，新的问题又来了。我们在例子中可以看到，平均负载有三个数值，到底该参考哪一个呢？
实际上，都要看。三个不同时间间隔的平均值，其实给我们提供了，分析系统负载趋势的数据来源，让我们能更全面、更立体地理解目前的负载状况。
打个比方，就像初秋时北京的天气，如果只看中午的温度，你可能以为还在 7 月份的大夏天呢。但如果你结合了早上、中午、晚上三个时间点的温度来看，基本就可以全方位了解这一天的天气情况了。

同样的，前面说到的 CPU 的三个负载时间段也是这个道理。

- 如果 1 分钟、5 分钟、15 分钟的三个值基本相同，或者相差不大，那就说明系统负载很平稳。
- 但如果 1 分钟的值远小于 15 分钟的值，就说明系统最近 1 分钟的负载在减少，而过去 15 分钟内却有很大的负载。
- 反过来，如果 1 分钟的值远大于 15 分钟的值，就说明最近 1 分钟的负载在增加，这种增加有可能只是临时性的，也有可能还会持续增加下去，所以就需要持续观察。一旦 1 分钟的平均负载接近或超过了 CPU 的个数，就意味着系统正在发生过载的问题，这时就得分析调查是哪里导致的问题，并要想办法优化了。

这里我再举个例子，假设我们在一个单 CPU 系统上看到平均负载为 1.73，0.60，7.98，那么说明在过去 1 分钟内，系统有 73% 的超载，而在 15 分钟内，有 698% 的超载，从整体趋势来看，系统的负载在降低。
那么，在实际生产环境中，平均负载多高时，需要我们重点关注呢？
在我看来，当平均负载高于 CPU 数量 70% 的时候，你就应该分析排查负载高的问题了。一旦负载过高，就可能导致进程响应变慢，进而影响服务的正常功能。
但 70% 这个数字并不是绝对的，最推荐的方法，还是把系统的平均负载监控起来，然后根据更多的历史数据，判断负载的变化趋势。当发现负载有明显升高趋势时，比如说负载翻倍了，你再去做分析和调查。


### 3.平均负载与 CPU 使用率
现实工作中，我们经常容易把平均负载和 CPU 使用率混淆，所以在这里，我也做一个区分。

可能你会疑惑，既然平均负载代表的是活跃进程数，那平均负载高了，不就意味着 CPU 使用率高吗？

我们还是要回到平均负载的含义上来，平均负载是指单位时间内，处于可运行状态和不可中断状态的进程数。所以，它不仅包括了正在使用 CPU 的进程，还包括等待 CPU 和等待 I/O 的进程。
而 CPU 使用率，是单位时间内 CPU 繁忙情况的统计，跟平均负载并不一定完全对应。比如：
- CPU 密集型进程，使用大量 CPU 会导致平均负载升高，此时这两者是一致的；
- I/O 密集型进程，等待 I/O 也会导致平均负载升高，但 CPU 使用率不一定很高；
- 大量等待 CPU 的进程调度也会导致平均负载升高，此时的 CPU 使用率也会比较高。

### 4.平均负载案例分析
下面，我们以三个示例分别来看这三种情况，并用 iostat、mpstat、pidstat 等工具，找出平均负载升高的根源。


#### 1.准备
- 机器配置：2 CPU，4GB 内存。
- 预先安装 stress 和 sysstat 包，如 apt install stress sysstat。
`stress` 是一个 Linux 系统压力测试工具，这里我们用作异常进程模拟平均负载升高的场景。
而 `sysstat` 包含了常用的 Linux 性能工具，用来监控和分析系统的性能。我们的案例会用到这个包的两个命令 mpstat 和 pidstat。
- mpstat 是一个常用的多核 CPU 性能分析工具，用来实时查看每个 CPU 的性能指标，以及所有 CPU 的平均指标。
- pidstat 是一个常用的进程性能分析工具，用来实时查看进程的 CPU、内存、I/O 以及上下文切换等性能指标。

先用 uptime 命令，看一下测试前的平均负载情况：
```
root@eBpfTest:~# uptime
 15:22:52 up 18 days, 52 min,  3 users,  load average: 0.05, 0.02, 0.00
```

#### 场景一：CPU 密集型进程
首先，我们在第一个终端运行 stress 命令，模拟一个 CPU 使用率 100% 的场景：
```
$ stress --cpu 1 --timeout 600
```
终端输出：
```
stress: info: [98398] dispatching hogs: 1 cpu, 0 io, 0 vm, 0 hdd
```
接着，在第二个终端运行 uptime 查看平均负载的变化情况：
#-d 参数表示高亮显示变化的区域
```
$ watch -d uptime
...,  load average: 1.00, 0.75, 0.39
```
最后，在第三个终端运行 mpstat 查看 CPU 使用率的变化情况：
#-P ALL 表示监控所有 CPU，后面数字 5 表示间隔 5 秒后输出一组数据
```
root@eBpfTest:~# mpstat -P ALL 5
Linux 5.15.0-58-generic (eBpfTest)      05/15/2023      _x86_64_        (2 CPU)

03:25:17 PM  CPU    %usr   %nice    %sys %iowait    %irq   %soft  %steal  %guest  %gnice   %idle
03:25:22 PM  all   52.76    0.00    3.32    0.00    0.00    0.00    0.00    0.00    0.00   43.92
03:25:22 PM    0   96.20    0.00    1.40    0.00    0.00    0.00    0.00    0.00    0.00    2.40
03:25:22 PM    1    8.89    0.00    5.25    0.00    0.00    0.00    0.00    0.00    0.00   85.86

03:25:22 PM  CPU    %usr   %nice    %sys %iowait    %irq   %soft  %steal  %guest  %gnice   %idle
03:25:27 PM  all   50.55    0.00    0.60    0.00    0.00    0.00    0.00    0.00    0.00   48.84
03:25:27 PM    0   73.00    0.00    0.40    0.00    0.00    0.00    0.00    0.00    0.00   26.60
03:25:27 PM    1   27.88    0.00    0.81    0.00    0.00    0.00    0.00    0.00    0.00   71.31

03:25:27 PM  CPU    %usr   %nice    %sys %iowait    %irq   %soft  %steal  %guest  %gnice   %idle
03:25:32 PM  all   50.71    0.00    0.40    0.10    0.00    0.00    0.00    0.00    0.00   48.79
03:25:32 PM    0    1.83    0.00    0.81    0.20    0.00    0.00    0.00    0.00    0.00   97.16
03:25:32 PM    1   99.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    1.00
```
从终端二中可以看到，1 分钟的平均负载会慢慢增加到 1.00，而从终端三中还可以看到，正好有一个 CPU 的使用率为 100%，但它的 iowait 只有 0。这说明，平均负载的升高正是由于 CPU 使用率为 100% 。
那么，到底是哪个进程导致了 CPU 使用率为 100% 呢？你可以使用 pidstat 来查询：
```
root@eBpfTest:~# pidstat -u 5 1
Linux 5.15.0-58-generic (eBpfTest)      05/15/2023      _x86_64_        (2 CPU)

03:26:53 PM   UID       PID    %usr %system  %guest   %wait    %CPU   CPU  Command
03:26:58 PM     0         1    0.20    0.20    0.00    0.20    0.40     1  systemd
03:26:58 PM     0        14    0.00    0.20    0.00    0.20    0.20     1  rcu_sched
03:26:58 PM   103       807    0.40    0.20    0.00    0.80    0.60     1  dbus-daemon
03:26:58 PM     0       839    0.00    0.20    0.00    0.20    0.20     1  systemd-logind
03:26:58 PM     0      1670    0.00    0.20    0.00    0.00    0.20     1  assist_daemon
03:26:58 PM     0      1702    0.40    0.40    0.00    0.00    0.80     1  AliYunDun
03:26:58 PM     0      1712    1.80    1.00    0.00    3.80    2.80     1  AliYunDunMonito
03:26:58 PM     0     69687    0.20    0.00    0.00    0.20    0.20     1  systemd-journal
03:26:58 PM     0     97033    0.00    0.20    0.00    0.00    0.20     1  kworker/1:1-events
03:26:58 PM     0     98399   99.40    0.00    0.00    0.60   99.40     0  stress
03:26:58 PM     0     98767    0.20    0.00    0.00    0.00    0.20     1  mpstat
```
#### 场景二：I/O 密集型进程
首先还是运行 stress 命令，但这次模拟 I/O 压力，即不停地执行 sync：
```
$ stress -i 1 --timeout 600
```
还是在第二个终端运行 uptime 查看平均负载的变化情况：
```
$ watch -d uptime
...,  load average: 1.00, 0.58, 0.37
```
然后，第三个终端运行 mpstat 查看 CPU 使用率的变化情况：
```
root@eBpfTest:~# mpstat -P ALL 5
Linux 5.15.0-58-generic (eBpfTest)      05/15/2023      _x86_64_        (2 CPU)

03:43:17 PM  CPU    %usr   %nice    %sys %iowait    %irq   %soft  %steal  %guest  %gnice   %idle
03:43:22 PM  all    8.19    0.00   20.64   30.32    0.00    2.66    0.00    0.00    0.00   38.19
03:43:22 PM    0    2.52    0.00   29.98   49.27    0.00    0.21    0.00    0.00    0.00   18.03
03:43:22 PM    1   14.04    0.00   11.02   10.80    0.00    5.18    0.00    0.00    0.00   58.96
```
从这里可以看到，1 分钟的平均负载会慢慢增加到 1.00，其中一个 CPU 的系统 CPU 使用率升高到了 29.98，而 iowait 高达 49.27%。这说明，平均负载的升高是由于 iowait 的升高。

那么到底是哪个进程，导致 iowait 这么高呢？我们还是用 pidstat 来查询：
```
root@eBpfTest:~# pidstat -u 5 1
Linux 5.15.0-58-generic (eBpfTest)      05/15/2023      _x86_64_        (2 CPU)

03:44:03 PM   UID       PID    %usr %system  %guest   %wait    %CPU   CPU  Command
03:44:08 PM     0         1    0.00    0.20    0.00    0.00    0.20     0  systemd
03:44:08 PM     0        90    0.00    4.00    0.00    0.20    4.00     0  kworker/0:1H-kblockd
03:44:08 PM     0       105    0.00    1.20    0.00    0.20    1.20     1  kworker/1:1H-kblockd
03:44:08 PM     0       306    0.00    0.20    0.00    0.00    0.20     1  jbd2/vda3-8
03:44:08 PM   103       807    0.40    0.00    0.00    0.40    0.40     1  dbus-daemon
03:44:08 PM     0       839    0.20    0.00    0.00    0.20    0.20     0  systemd-logind
03:44:08 PM     0      1472    0.00    0.20    0.00    0.00    0.20     1  aliyun-service
03:44:08 PM     0      1702    0.40    0.20    0.00    0.00    0.60     0  AliYunDun
03:44:08 PM     0      1712    1.80    0.80    0.00    1.20    2.60     1  AliYunDunMonito
03:44:08 PM     0     69696    0.20    0.00    0.00    0.00    0.20     0  polkitd
03:44:08 PM     0     95320    0.00    0.20    0.00    0.00    0.20     0  kworker/u4:0-events_power_efficient
03:44:08 PM     0     97033    0.00    0.20    0.00    0.00    0.20     1  kworker/1:1-events
03:44:08 PM     0     99643    1.00   31.00    0.00    6.40   32.00     0  stress
03:44:08 PM     0     99774    0.20    0.20    0.00    0.00    0.40     1  watch
03:44:08 PM     0    100986    0.20    0.00    0.00    0.00    0.20     0  sshd
```
可以发现，还是 stress 进程导致的。

#### 场景三：大量进程的场景
当系统中运行进程超出 CPU 运行能力时，就会出现等待 CPU 的进程。

比如，我们还是使用 stress，但这次模拟的是 8 个进程：
```
$ stress -c 8 --timeout 600
```
wathc uptime一下
由于系统只有 2 个 CPU，明显比 8 个进程要少得多，因而，系统的 CPU 处于严重过载状态，平均负载高达 7.95：
```
Every 2.0s: uptime                                                                                                                                                                                      eBpfTest: Mon May 15 15:58:48 2023

 15:58:48 up 18 days,  1:28,  4 users,  load average: 7.95, 5.06, 2.37
```

pidstatus看一下进程情况
```
root@eBpfTest:~# pidstat -u 5 1
Linux 5.15.0-58-generic (eBpfTest)      05/15/2023      _x86_64_        (2 CPU)

03:56:17 PM   UID       PID    %usr %system  %guest   %wait    %CPU   CPU  Command
03:56:22 PM   103       807    0.20    0.00    0.00    0.40    0.20     0  dbus-daemon
03:56:22 PM     0       839    0.00    0.20    0.00    0.20    0.20     0  systemd-logind
03:56:22 PM     0      1270    0.20    0.20    0.00    0.00    0.40     0  AliYunDunUpdate
03:56:22 PM     0      1472    0.20    0.00    0.00    0.00    0.20     0  aliyun-service
03:56:22 PM     0      1702    0.60    0.20    0.00    0.00    0.80     1  AliYunDun
03:56:22 PM     0      1712    1.39    0.40    0.00    1.79    1.79     1  AliYunDunMonito
03:56:22 PM     0     69687    0.00    0.20    0.00    0.00    0.20     0  systemd-journal
03:56:22 PM     0     69696    0.00    0.20    0.00    0.00    0.20     0  polkitd
03:56:22 PM     0     69708    0.20    0.00    0.00    0.00    0.20     0  tuned
03:56:22 PM     0    101494   24.50    0.00    0.00   75.10   24.50     1  stress
03:56:22 PM     0    101495   23.31    0.00    0.00   76.29   23.31     0  stress
03:56:22 PM     0    101496   23.11    0.00    0.00   76.49   23.11     1  stress
03:56:22 PM     0    101497   22.91    0.00    0.00   76.49   22.91     1  stress
03:56:22 PM     0    101498   23.31    0.00    0.00   76.29   23.31     0  stress
03:56:22 PM     0    101499   24.50    0.00    0.00   75.50   24.50     0  stress
03:56:22 PM     0    101500   23.51    0.00    0.00   76.10   23.51     0  stress
03:56:22 PM     0    101501   24.50    0.00    0.00   75.10   24.50     1  stress
03:56:22 PM     0    101872    0.20    0.00    0.00    0.00    0.20     0  watch
```
可以看出，8 个进程在争抢 2 个 CPU，每个进程等待 CPU 的时间（也就是代码块中的 %wait 列）高达 75%。这些超出 CPU 计算能力的进程，最终导致 CPU 过载。

### 小结
分析完这三个案例，归纳一下平均负载的理解。

平均负载提供了一个快速查看系统整体性能的手段，反映了整体的负载情况。但只看平均负载本身，我们并不能直接发现，到底是哪里出现了瓶颈。所以，在理解平均负载时，也要注意：
- 平均负载高有可能是 CPU 密集型进程导致的；
- 平均负载高并不一定代表 CPU 使用率高，还有可能是 I/O 更繁忙了；
- 当发现负载高的时候，你可以使用 mpstat、pidstat 等工具，辅助分析负载的来源。

### 命令总结

- uptime ： 查看平均负载情况
- stress --cpu 1 --timeout 600 ： 模拟一个 CPU（cpu1） 使用率 100% 的场景
- stress -i 1 --timeout 600 : 模拟 I/O 压力，即不停地执行 sync
- stress -c 8 --timeout 600 : 模拟的是 8 个进程
- watch -d uptime ：（watch 命令可以定期执行命令，并显示输出结果。它用于监视系统中运行的进程或其他任何命令的输出）定期输出平均负载情况 -d 参数表示高亮显示变化的区域
- mpstat -P ALL 5 ： 查看 CPU 使用率的变化情况，-P ALL 表示监控所有 CPU，后面数字 5 表示间隔 5 秒后输出一组数据
- pidstat -u 5 1 ：每隔 5 秒显示一次进程的 CPU 使用情况，共显示 1 次（pidstat一个 Linux 命令行工具，用于监控进程的 CPU 使用情况、内存占用情况等）

- %usr: 用户空间进程占用CPU时间的百分比
- %nice: 优先级较高的进程占用CPU时间的百分比
- %sys: 内核空间进程占用CPU时间的百分比
- %iowait: CPU等待I/O操作完成的时间的百分比
- %irq: 处理硬件中断所占用的CPU时间的百分比
- %soft: 内核产生的软件中断占用CPU时间的百分比
- %steal: 被其他虚拟机（VM）偷取的CPU时间的百分比
- %guest: 运行虚拟机（VM）时虚拟CPU占用实际CPU时间的百分比
- %gnice: 优先级较高的nice进程占用CPU时间的百分比
- %idle: 空闲CPU时间的百分比

