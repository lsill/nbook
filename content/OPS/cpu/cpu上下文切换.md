---
title: "cpu上下文切换"
date: 2023-05-15T17:18:48+08:00
draft: true
---

### cpu上下文定义
进程在竞争 CPU 的时候并没有真正运行，为什么还会导致系统的负载升高呢？看到今天的主题，你应该已经猜到了，CPU 上下文切换就是罪魁祸首。

Linux 是一个多任务操作系统，它支持远大于 CPU 数量的任务同时运行。当然，这些任务实际上并不是真的在同时运行，而是因为系统在很短的时间内，将 CPU 轮流分配给它们，造成多任务同时运行的错觉。

而在每个任务运行前，CPU 都需要知道任务从哪里加载、又从哪里开始运行，也就是说，需要系统事先帮它设置好 CPU 寄存器和程序计数器（Program Counter，PC）。

`CPU 寄存器`，是 CPU 内置的容量小、但速度极快的内存。而`程序计数器`，则是用来存储 CPU 正在执行的指令位置、或者即将执行的下一条指令位置。它们都是 CPU 在运行任何任务前，必须的依赖环境，因此也被叫做 `CPU 上下文`。

知道了什么是 CPU 上下文，我想你也很容易理解 CPU 上下文切换。
CPU 上下文切换: 就是先把前一个任务的 CPU 上下文（也就是 CPU 寄存器和程序计数器）保存起来，然后加载新任务的上下文到这些寄存器和程序计数器，最后再跳转到程序计数器所指的新位置，运行新任务。

而这些保存下来的上下文，会存储在系统内核中，并在任务重新调度执行时再次加载进来。这样就能保证任务原来的状态不受影响，让任务看起来还是连续运行。
我猜肯定会有人说，CPU 上下文切换无非就是更新了 CPU 寄存器的值嘛，但这些寄存器，本身就是为了快速运行任务而设计的，为什么会影响系统的 CPU 性能呢？
在回答这个问题前，不知道你有没有想过，操作系统管理的这些“任务”到底是什么呢？
也许你会说，任务就是进程，或者说任务就是线程。
是的，进程和线程正是最常见的任务。但是除此之外，还有没有其他的任务呢？不要忘了，硬件通过触发信号，会导致中断处理程序的调用，也是一种常见的任务。

所以，根据任务的不同，CPU 的上下文切换就可以分为几个不同的场景，也就是`进程上下文切换`、`线程上下文切换`以及`中断上下文切换`。

### 进程上下文切换
Linux 按照特权等级，把进程的运行空间分为内核空间和用户空间，分别对应着下图中， CPU 特权等级的 Ring 0 和 Ring 3。

- 内核空间（Ring 0）具有最高权限，可以直接访问所有资源；
- 用户空间（Ring 3）只能访问受限资源，不能直接访问内存等硬件设备，必须通过系统调用陷入到内核中，才能访问这些特权资源。

换个角度看，也就是说，进程既可以在用户空间运行，又可以在内核空间中运行。进程在用户空间运行时，被称为进程的用户态，而陷入内核空间的时候，被称为进程的内核态。
从用户态到内核态的转变，需要通过系统调用来完成。比如，当我们查看文件内容时，就需要多次系统调用来完成：首先调用 open() 打开文件，然后调用 read() 读取文件内容，并调用 write() 将内容写到标准输出，最后再调用 close() 关闭文件。那么，系统调用的过程有没有发生 CPU 上下文的切换呢？答案自然是肯定的。

CPU 寄存器里原来用户态的指令位置，需要先保存起来。接着，为了执行内核态代码，CPU 寄存器需要更新为内核态指令的新位置。最后才是跳转到内核态运行内核任务。而系统调用结束后，CPU 寄存器需要恢复原来保存的用户态，然后再切换到用户空间，继续运行进程。
所以，一次系统调用的过程，其实是发生了两次 CPU 上下文切换。不过，需要注意的是，系统调用过程中，并不会涉及到虚拟内存等进程用户态的资源，也不会切换进程。这跟我们通常所说的进程上下文切换是不一样的：
- 进程上下文切换，是指从一个进程切换到另一个进程运行。
- 而系统调用过程中一直是同一个进程在运行。

所以，系统调用过程通常称为`特权模式切换`，而不是上下文切换。但实际上，系统调用过程中，CPU 的上下文切换还是无法避免的。

那么，进程上下文切换跟系统调用又有什么区别呢？
首先，你需要知道，进程是由内核来管理和调度的，进程的切换只能发生在内核态。所以，进程的上下文不仅包括了虚拟内存、栈、全局变量等用户空间的资源，还包括了内核堆栈、寄存器等内核空间的状态。
因此，进程的上下文切换就比系统调用时多了一步：在保存当前进程的内核状态和 CPU 寄存器之前，需要先把该进程的虚拟内存、栈等保存下来；而加载了下一进程的内核态后，还需要刷新进程的虚拟内存和用户栈。
如下图所示，保存上下文和恢复上下文的过程并不是“免费”的，需要内核在 CPU 上运行才能完成。

根据 Tsuna 的测试报告，每次上下文切换都需要几十纳秒到数微秒的 CPU 时间。这个时间还是相当可观的，特别是在进程上下文切换次数较多的情况下，很容易导致 CPU 将大量时间耗费在寄存器、内核栈以及虚拟内存等资源的保存和恢复上，进而大大缩短了真正运行进程的时间。这也正是上一节中我们所讲的，导致平均负载升高的一个重要因素。

另外，我们知道， Linux 通过 TLB（Translation Lookaside Buffer）来管理虚拟内存到物理内存的映射关系。当虚拟内存更新后，TLB 也需要刷新，内存的访问也会随之变慢。特别是在多处理器系统上，缓存是被多个处理器共享的，刷新缓存不仅会影响当前处理器的进程，还会影响共享缓存的其他处理器的进程。

知道了进程上下文切换潜在的性能问题后，我们再来看，究竟什么时候会切换进程上下文。

显然，进程切换时才需要切换上下文，换句话说，只有在进程调度的时候，才需要切换上下文。Linux 为每个 CPU 都维护了一个就绪队列，将活跃进程（即正在运行和正在等待 CPU 的进程）按照优先级和等待 CPU 的时间排序，然后选择最需要 CPU 的进程，也就是优先级最高和等待 CPU 时间最长的进程来运行。

那么，进程在什么时候才会被调度到 CPU 上运行呢？

最容易想到的一个时机，就是进程执行完终止了，它之前使用的 CPU 会释放出来，这个时候再从就绪队列里，拿一个新的进程过来运行。其实还有很多其他场景，也会触发进程调度，在这里我给你逐个梳理下。
- 进程执行完终止了，它之前使用的 CPU 会释放出来，这个时候再从就绪队列里，拿一个新的进程过来运行。
- 为了保证所有进程可以得到公平调度，CPU 时间被划分为一段段的时间片，这些时间片再被轮流分配给各个进程。这样，当某个进程的时间片耗尽了，就会被系统挂起，切换到其它正在等待 CPU 的进程运行。
- 进程在系统资源不足（比如内存不足）时，要等到资源满足后才可以运行，这个时候进程也会被挂起，并由系统调度其他进程运行。
- 当进程通过睡眠函数 sleep 这样的方法将自己主动挂起时，自然也会重新调度。
- 当有优先级更高的进程运行时，为了保证高优先级进程的运行，当前进程会被挂起，由高优先级进程来运行。
- 发生硬件中断时，CPU 上的进程会被中断挂起，转而执行内核中的中断服务程序。

### 线程上下文切换
线程与进程最大的区别在于，线程是调度的基本单位，而进程则是资源拥有的基本单位。说白了，所谓内核中的任务调度，实际上的调度对象是线程；而进程只是给线程提供了虚拟内存、全局变量等资源。所以，对于线程和进程，我们可以这么理解：
- 当进程只有一个线程时，可以认为进程就等于线程。
- 当进程拥有多个线程时，这些线程会共享相同的虚拟内存和全局变量等资源。这些资源在上下文切换时是不需要修改的。
- 另外，线程也有自己的私有数据，比如栈和寄存器等，这些在上下文切换时也是需要保存的。

这么一来，线程的上下文切换其实就可以分为两种情况：
第一种， 前后两个线程属于不同进程。此时，因为资源不共享，所以切换过程就跟进程上下文切换是一样。
第二种，前后两个线程属于同一个进程。此时，因为虚拟内存是共享的，所以在切换时，虚拟内存这些资源就保持不动，只需要切换线程的私有数据、寄存器等不共享的数据。
到这里你应该也发现了，虽然同为上下文切换，但同进程内的线程切换，要比多进程间的切换消耗更少的资源，而这，也正是多线程代替多进程的一个优势。

### 中断上下文切换
除了前面两种上下文切换，还有一个场景也会切换 CPU 上下文，那就是中断。
为了快速响应硬件的事件，中断处理会打断进程的正常调度和执行，转而调用中断处理程序，响应设备事件。而在打断其他进程时，就需要将进程当前的状态保存下来，这样在中断结束后，进程仍然可以从原来的状态恢复运行。
跟进程上下文不同，中断上下文切换并不涉及到进程的用户态。所以，即便中断过程打断了一个正处在用户态的进程，也不需要保存和恢复这个进程的虚拟内存、全局变量等用户态资源。中断上下文，其实只包括内核态中断服务程序执行所必需的状态，包括 CPU 寄存器、内核堆栈、硬件中断参数等。
对同一个 CPU 来说，中断处理比进程拥有更高的优先级，所以中断上下文切换并不会与进程上下文切换同时发生。同样道理，由于中断会打断正常进程的调度和执行，所以大部分中断处理程序都短小精悍，以便尽可能快的执行结束。
另外，跟进程上下文切换一样，中断上下文切换也需要消耗 CPU，切换次数过多也会耗费大量的 CPU，甚至严重降低系统的整体性能。所以，当你发现中断次数过多时，就需要注意去排查它是否会给你的系统带来严重的性能问题。

### 怎么查看系统的上下文切换情况
通过前面学习我们知道，过多的上下文切换，会把 CPU 时间消耗在寄存器、内核栈以及虚拟内存等数据的保存和恢复上，缩短进程真正运行的时间，成了系统性能大幅下降的一个元凶。
既然上下文切换对系统性能影响那么大，你肯定迫不及待想知道，到底要怎么查看上下文切换呢？
在这里，我们可以使用 vmstat 这个工具，来查询系统的上下文切换情况。vmstat 是一个常用的系统性能分析工具，主要用来分析系统的内存使用情况，也常用来分析 CPU 上下文切换和中断的次数。比如，下面就是一个 vmstat 的使用示例：
```
root@eBpfTest:~# vmstat 5
procs -----------memory---------- ---swap-- -----io---- -system-- ------cpu-----
 r  b   swpd   free   buff  cache   si   so    bi    bo   in   cs us sy id wa st
 0  0      0 237944 179608 2895936    0    0     0     4   11    1  0  0 99  0  0
 0  0      0 237944 179608 2895936    0    0     0     2  704 1310  1  0 99  0  0
 0  0      0 237944 179608 2895936    0    0     0     0  708 1338  0  0 99  0  0
 0  0      0 237944 179608 2895936    0    0     0     0  737 1379  0  0 99  0  0
 0  0      0 237944 179608 2895936    0    0     0     0  702 1329  1  0 99  0  0
```
我们一起来看这个结果，你可以先试着自己解读每列的含义。
在这里，我重点强调下，需要特别关注的四列内容：
- cs（context switch）是每秒上下文切换的次数。
- in（interrupt）则是每秒中断的次数。
- r（Running or Runnable）是就绪队列的长度，也就是正在运行和等待 CPU 的进程数。
- b（Blocked）则是处于不可中断睡眠状态的进程数。
  
可以看到，这个例子中的上下文切换次数 cs 是 33 次，而系统中断次数 in 则是 25 次，而就绪队列长度 r 和不可中断状态进程数 b 都是 0。vmstat 只给出了系统总体的上下文切换情况，
要想查看每个进程的详细情况，就需要使用我们前面提到过的 pidstat 了。给它加上 -w 选项，你就可以查看每个进程上下文切换的情况了。
```
root@eBpfTest:~# pidstat -w 5
Linux 5.15.0-58-generic (eBpfTest)      05/15/2023      _x86_64_        (2 CPU)

06:10:47 PM   UID       PID   cswch/s nvcswch/s  Command
06:10:52 PM     0         1     17.96      0.00  systemd
06:10:52 PM     0         2      0.20      0.00  kthreadd
06:10:52 PM     0        13      1.80      0.00  ksoftirqd/0
06:10:52 PM     0        14     46.71      0.00  rcu_sched
06:10:52 PM     0        15      1.00      0.00  migration/0
06:10:52 PM     0        21      1.40      0.00  migration/1
06:10:52 PM     0        22      2.59      0.00  ksoftirqd/1
06:10:52 PM     0        32      2.00      0.00  kcompactd0
06:10:52 PM     0        90      0.20      0.00  kworker/0:1H-kblockd
06:10:52 PM   103       807     34.13     10.38  dbus-daemon
06:10:52 PM     0       839     17.96      1.00  systemd-logind
06:10:52 PM     0      1270      0.20      0.00  AliYunDunUpdate
06:10:52 PM     0      1702     11.78      0.00  AliYunDun
06:10:52 PM     0      1712     30.54      0.00  AliYunDunMonito
06:10:52 PM     0     69687      5.39      2.00  systemd-journal
06:10:52 PM     0     69689      3.99      0.00  packagekitd
06:10:52 PM     0     69692      3.39      0.00  udisksd
06:10:52 PM     0     69694      1.00      0.00  multipathd
06:10:52 PM     0     69696      6.19      0.00  polkitd
06:10:52 PM     0     69702      8.78      0.00  ModemManager
06:10:52 PM     0     69709      2.40      0.20  sshd
06:10:52 PM     0     98000      3.79      0.00  kworker/u4:2-events_unbound
06:10:52 PM     0    101570     10.58      0.00  kworker/0:2-events
06:10:52 PM     0    102686      4.99      0.00  kworker/u4:0-events_power_efficient
06:10:52 PM     0    102896     22.55      0.00  kworker/1:2-events
06:10:52 PM     0    103005      0.40      0.00  kworker/0:0-cgroup_destroy
06:10:52 PM     0    103520      0.20      0.00  pidstat
06:10:52 PM     0    103619      0.80      0.00  kworker/0:1-events
```
这个结果中有两列内容是我们的重点关注对象。一个是 cswch ，表示每秒自愿上下文切换（voluntary context switches）的次数，另一个则是 nvcswch ，表示每秒非自愿上下文切换（non voluntary context switches）的次数。
这两个概念你一定要牢牢记住，因为它们意味着不同的性能问题：
- 所谓`自愿上下文切换，是指进程无法获取所需资源，导致的上下文切换。`比如说， I/O、内存等系统资源不足时，就会发生自愿上下文切换。
- `而非自愿上下文切换，则是指进程由于时间片已到等原因，被系统强制调度，进而发生的上下文切换`。比如说，大量进程都在争抢 CPU 时，就容易发生非自愿上下文切换。

#### 案例分析
知道了怎么查看这些指标，另一个问题又来了，上下文切换频率是多少次才算正常呢？别急着要答案，同样的，我们先来看一个上下文切换的案例。通过案例实战演练，你自己就可以分析并找出这个标准了。

##### 准备
- 机器配置：2 CPU，4GB 内存预先安装 
- sysbench 和 sysstat 包，如 apt install sysbench sysstat

安装完成后，你可以先用 vmstat 看一下空闲系统的上下文切换次数：
```
root@eBpfTest:~# vmstat 1 1
procs -----------memory---------- ---swap-- -----io---- -system-- ------cpu-----
 r  b   swpd   free   buff  cache   si   so    bi    bo   in   cs us sy id wa st
 0  0      0 249408 179620 2897292    0    0     0     4   11    2  0  0 99  0  0
```
这里你可以看到，现在的上下文切换次数 cs 是 2，而中断次数 in 是 11，r 和 b 都是 0。因为这会儿并没有运行其他任务，所以它们就是空闲系统的上下文切换次数

##### 操作和分析
首先，在第一个终端里运行 sysbench ，模拟系统多线程调度的瓶颈：
```
root@eBpfTest:~# sysbench --threads=10 --max-time=300 threads run
```
接着，在第二个终端运行 vmstat ，观察上下文切换情况：
```
root@eBpfTest:~# vmstat 1
procs -----------memory---------- ---swap-- -----io---- -system-- ------cpu-----
 r  b   swpd   free   buff  cache   si   so    bi    bo   in   cs us sy id wa st
 7  0      0 242116 179620 2901100    0    0     0     4   12   11  0  0 99  0  0
 6  0      0 242148 179620 2901180    0    0     0     0 18694 836013 34 64  2  0  0
 6  0      0 239404 179620 2901180    0    0     0     0 22208 718685 31 65  5  0  0
 6  0      0 239404 179620 2901120    0    0     0     0 24485 767119 31 63  6  0  0
 6  0      0 239404 179620 2901088    0    0     0     0 24897 791221 34 64  2  0  0
 8  0      0 239404 179620 2901088    0    0     0     0 27075 855396 33 65  2  0  0
 6  0      0 239404 179620 2901088    0    0     0    40 23997 854396 31 68  1  0  0
 8  0      0 239404 179620 2901088    0    0     0     0 21142 926109 29 70  1  0  0
 8  0      0 239404 179620 2901088    0    0     0     0 26030 840192 29 70  2  0  0
 7  0      0 239404 179620 2901088    0    0     0     0 26336 795731 28 70  2  0  0
 6  0      0 239404 179620 2901088    0    0     0     0 29919 854905 28 70  2  0  0
 9  0      0 239404 179620 2901088    0    0     0    44 34344 863628 30 68  2  0  0
 7  0      0 239404 179620 2901088    0    0     0     0 30964 855336 30 69  1  0  0
 8  0      0 239404 179620 2901088    0    0     0     0 28967 857704 27 72  1  0  0
 9  0      0 239404 179620 2901088    0    0     0     0 32009 834886 31 68  1  0  0
 7  0      0 239404 179620 2901088    0    0     0     0 23863 908069 31 68  2  0  0
```
你应该可以发现，cs 列的上下文切换次数从之前的 2 骤然上升到了 85 万。同时，注意观察其他几个指标：
- r 列：就绪队列的长度已经到了 9，远远超过了系统 CPU 的个数 2，所以肯定会有大量的 CPU 竞争。
- us（user）和 sy（system）列：这两列的 CPU 使用率加起来上升到了 99%，其中系统 CPU 使用率，也就是 sy 列高达 70%，说明 CPU 主要是被内核占用了。
- in 列：中断次数也上升到了 2 万左右，说明中断处理也是个潜在的问题。

综合这几个指标，我们可以知道，系统的就绪队列过长，也就是正在运行和等待 CPU 的进程数过多，导致了大量的上下文切换，而上下文切换又导致了系统 CPU 的占用率升高。
那么到底是什么进程导致了这些问题呢？我们继续分析，在第三个终端再用 pidstat 来看一下， CPU 和进程上下文切换的情况：

```
root@eBpfTest:~# pidstat -w -u 1
Linux 5.15.0-58-generic (eBpfTest)      05/15/2023      _x86_64_        (2 CPU)

06:37:18 PM   UID       PID    %usr %system  %guest   %wait    %CPU   CPU  Command
06:37:19 PM     0        14    0.00    0.97    0.00    0.00    0.97     0  rcu_sched
06:37:19 PM   103       807    0.97    0.97    0.00    0.00    1.94     1  dbus-daemon
06:37:19 PM     0      1702    0.00    0.97    0.00    0.00    0.97     0  AliYunDun
06:37:19 PM     0      1712    2.91    0.00    0.00    0.00    2.91     0  AliYunDunMonito
06:37:19 PM     0    104899   52.43  102.91    0.00    0.00  155.34     1  sysbench

06:37:18 PM   UID       PID   cswch/s nvcswch/s  Command
06:37:19 PM     0         1     30.10      0.00  systemd
06:37:19 PM     0         2      0.97      0.00  kthreadd
06:37:19 PM     0        13     18.45      0.00  ksoftirqd/0
06:37:19 PM     0        14    100.97      0.00  rcu_sched
06:37:19 PM     0        21      2.91      0.00  migration/1
06:37:19 PM     0        22      1.94      0.00  ksoftirqd/1
06:37:19 PM     0        32      1.94      0.00  kcompactd0
06:37:19 PM     0       105      2.91      0.00  kworker/1:1H-kblockd
06:37:19 PM     0       306      2.91      0.00  jbd2/vda3-8
06:37:19 PM   103       807     57.28     17.48  dbus-daemon
06:37:19 PM     0       839     29.13      1.94  systemd-logind
06:37:19 PM     0      1270      0.97      0.00  AliYunDunUpdate
06:37:19 PM     0      1472     12.62      0.00  aliyun-service
06:37:19 PM     0      1702     12.62      0.97  AliYunDun
06:37:19 PM     0      1712     31.07      0.00  AliYunDunMonito
06:37:19 PM     0     69687      9.71      3.88  systemd-journal
06:37:19 PM     0     69689     23.30      0.00  packagekitd
06:37:19 PM     0     69692     17.48      0.00  udisksd
06:37:19 PM     0     69694      1.94      0.00  multipathd
06:37:19 PM     0     69696      9.71      0.00  polkitd
06:37:19 PM     0     69702     23.30      0.00  ModemManager
06:37:19 PM     0     69709      3.88      0.00  sshd
06:37:19 PM     0     98000     10.68      0.00  kworker/u4:2-events_power_efficient
06:37:19 PM     0    101570     32.04      0.00  kworker/0:2-events
06:37:19 PM     0    103816     13.59      0.00  kworker/1:0-mm_percpu_wq
06:37:19 PM     0    104650      1.94      0.00  kworker/0:0-cgroup_destroy
06:37:19 PM     0    105268      0.97      1.94  pidstat
06:37:19 PM     0    105324      2.91      0.00  kworker/0:1-events
```
从 pidstat 的输出你可以发现，CPU 使用率的升高果然是 sysbench 导致的，它的 CPU 使用率已经达到了 102.91 %（其实就是百分百，多核cpu计算会出现误差）。但上下文切换则是来自其他进程，包括非自愿上下文切换频率最高的 dbus-daemon ，以及自愿上下文切换频率最高的内核线程 rcu_sched。

不过，细心的你肯定也发现了一个怪异的事儿：pidstat 输出的上下文切换次数，加起来也就几百，比 vmstat 的 139 万明显小了太多。这是怎么回事呢？难道是工具本身出了错吗？
别着急，在怀疑工具之前，我们再来回想一下，前面讲到的几种上下文切换场景。其中有一点提到， Linux 调度的基本单位实际上是线程，而我们的场景 sysbench 模拟的也是线程的调度问题，那么，是不是 pidstat 忽略了线程的数据呢？
通过运行 man pidstat ，你会发现，pidstat 默认显示进程的指标数据，加上 -t 参数后，才会输出线程的指标。
所以，我们可以在第三个终端里， Ctrl+C 停止刚才的 pidstat 命令，再加上 -t 参数，重试一下看看：

```
Average:        0         -    108625    517.75     43.96  |__sshd
Average:        0    108842    108843  15116.31  69912.07  (sysbench)__sysbench
Average:        0         -    108844  15430.54  61551.89  |__sysbench
Average:        0         -    108845  15946.31  66835.68  |__sysbench
Average:        0         -    108846  14037.30  67618.02  |__sysbench
Average:        0         -    108847  14441.35  67523.42  |__sysbench
Average:        0         -    108848  14791.26  67476.13  |__sysbench
Average:        0         -    108849  15284.41  65701.89  |__sysbench
Average:        0         -    108850  14879.01  65927.03  |__sysbench
Average:        0         -    108851  14285.41  66129.28  |__sysbench
Average:        0         -    108852  14233.42  68215.59  |__sysbench
Average:        0    109000         -      0.99   1204.32  pidstat
Average:        0         -    109000      0.99   1204.32  |__pidstat
```
现在你就能看到了，虽然 sysbench 进程（也就是主线程）的上下文切换次数看起来并不多，但它的子线程的上下文切换次数却有很多。看来，上下文切换罪魁祸首，还是过多的 sysbench 线程。
我们已经找到了上下文切换次数增多的根源，那是不是到这儿就可以结束了呢？
当然不是。不知道你还记不记得，前面在观察系统指标时，除了上下文切换频率骤然升高，还有一个指标也有很大的变化。是的，正是中断次数。中断次数也上升到了 1 万，但到底是什么类型的中断上升了，现在还不清楚。我们接下来继续抽丝剥茧找源头。
既然是中断，我们都知道，它只发生在内核态，而 pidstat 只是一个进程的性能分析工具，并不提供任何关于中断的详细信息，怎样才能知道中断发生的类型呢？

没错，那就是从 /proc/interrupts 这个只读文件中读取。/proc 实际上是 Linux 的一个虚拟文件系统，用于内核空间与用户空间之间的通信。/proc/interrupts 就是这种通信机制的一部分，提供了一个只读的中断使用情况。

我们还是在第三个终端里， Ctrl+C 停止刚才的 pidstat 命令，然后运行下面的命令，观察中断的变化情况
```
           CPU0       CPU1
  1:          9          0   IO-APIC   1-edge      i8042
  4:       1365          0   IO-APIC   4-edge      ttyS0
  6:          0          3   IO-APIC   6-edge      floppy
  8:          0          0   IO-APIC   8-edge      rtc0
  9:          0          0   IO-APIC   9-fasteoi   acpi
 10:          0          0   IO-APIC  10-fasteoi   virtio3
 11:         20          0   IO-APIC  11-fasteoi   uhci_hcd:usb1
 12:          0         15   IO-APIC  12-edge      i8042
 14:          0          0   IO-APIC  14-edge      ata_piix
 15:          0          0   IO-APIC  15-edge      ata_piix
 24:          0          0   PCI-MSI 49152-edge      virtio0-config
 25:          0         27   PCI-MSI 49153-edge      virtio0-virtqueues
 26:          0          0   PCI-MSI 65536-edge      virtio1-config
 27:          0    7367197   PCI-MSI 65537-edge      virtio1-req.0
 28:          0          0   PCI-MSI 81920-edge      virtio2-config
 29:    1084663          1   PCI-MSI 81921-edge      virtio2-input.0
 30:          1    1082871   PCI-MSI 81922-edge      virtio2-output.0
NMI:          0          0   Non-maskable interrupts
LOC:  528272872  519753267   Local timer interrupts
SPU:          0          0   Spurious interrupts
PMI:          0          0   Performance monitoring interrupts
IWI:      88706      90593   IRQ work interrupts
RTR:          0          0   APIC ICR read retries
RES:    7159797    6875523   Rescheduling interrupts
CAL:   53425083   52673804   Function call interrupts
TLB:       9908      10203   TLB shootdowns
TRM:          0          0   Thermal event interrupts
THR:          0          0   Threshold APIC interrupts
DFR:          0          0   Deferred Error APIC interrupts
MCE:          0          0   Machine check exceptions
MCP:       5286       5286   Machine check polls
ERR:          0
MIS:          0
PIN:          0          0   Posted-interrupt notification event
NPI:          0          0   Nested posted-interrupt event
PIW:          0          0   Posted-interrupt wakeup event
```
观察一段时间，你可以发现，变化速度最快的是重调度中断（RES），这个中断类型表示，唤醒空闲状态的 CPU 来调度新的任务运行。这是多处理器系统（SMP）中，调度器用来分散任务到不同 CPU 的机制，通常也被称为处理器间中断（Inter-Processor Interrupts，IPI）。(观察了一点时间，的确是RES终端变化最快)

所以，这里的中断升高还是因为过多任务的调度问题，跟前面上下文切换次数的分析结果是一致的。
通过这个案例，你应该也发现了多工具、多方面指标对比观测的好处。如果最开始时，我们只用了 pidstat 观测，这些很严重的上下文切换线程，压根儿就发现不了了。
现在再回到最初的问题，每秒上下文切换多少次才算正常呢？

**这个数值其实取决于系统本身的 CPU 性能**。在我看来，如果系统的上下文切换次数比较稳定，那么从数百到一万以内，都应该算是正常的。但当上下文切换次数超过一万次，或者切换次数出现数量级的增长时，就很可能已经出现了性能问题。

这时，你还需要根据上下文切换的类型，再做具体分析。比方说：
- 自愿上下文切换变多了，说明进程都在等待资源，有可能发生了 I/O 等其他问题；
- 非自愿上下文切换变多了，说明进程都在被强制调度，也就是都在争抢 CPU，说明 CPU 的确成了瓶颈；
- 中断次数变多了，说明 CPU 被中断处理程序占用，还需要通过查看 /proc/interrupts 文件来分析具体的中断类型。

### 命令总结
- vmstat 5 ： 隔5秒输出1组系统性能数据
- pidstat -w 5 查看每个进程的详细情况
- pidstat -wt 1 显示输出线程的上下文切换指标
- sysbench --threads=10 --max-time=300 threads run : 模拟多线程调度
- watch -d cat /proc/interrupts 观察中断信号变化

#### vmstat 命令输出的系统统计信息
- r：正在运行的进程数。
- b：处于非中断等待状态的进程数。
- swpd：虚拟内存使用的大小（单位 KB）。
- free：空闲的物理内存大小（单位 KB）。
- buff：用于缓存块设备的内存大小（单位 KB）。
- cache：用于缓存文件系统的内存大小（单位 KB）。
- si：从磁盘读入虚拟内存的数据量（单位 KB/s）。
- so：写回磁盘的虚拟内存数据量（单位 KB/s）。
- bi：从块设备读取的数据量（单位 KB/s）。
- bo：向块设备写入的数据量（单位 KB/s）。
- in：每秒中断数，包括时钟中断。
- cs：每秒上下文切换数。
- us：用户进程消耗 CPU 时间的百分比。
- sy：内核进程消耗 CPU 时间的百分比。
- id：空闲 CPU 时间的百分比。
- wa：等待 I/O 操作完成消耗 CPU 时间的百分比。
- st：虚拟化环境中的时间百分比，表示操作系统等待虚拟机层处理的时间。

#### 中断一些意思
NMI（Non-Maskable Interrupts）：非可屏蔽中断，一种高优先级的中断，无法被屏蔽或忽略。通常由硬件问题或系统故障引发，用于处理严重的错误情况。
LOC（Local Timer Interrupts）：本地定时器中断，用于处理系统的定时器事件，时间管理和调度。
SPU（SPU Interrupts）：SPU（Synergistic Processing Unit）中断，用于处理特定类型的协处理器中断，通常与 Cell Broadband Engine 架构相关。
PMI（Performance Monitoring Interrupts）：性能监测中断，用于处理与性能监测相关的事件和数据收集。
IWI（IRQ work interrupts）：IRQ 工作中断，用于处理需要延迟执行的低优先级中断。
RTR（Redirected Timer Interrupts）：重定向的定时器中断，通常与虚拟化环境相关。
RES（Rescheduling Interrupts）：重新调度中断，用于系统重新调度任务和处理器切换。
CAL（Function Call Trampolines）：用于执行函数调用跳转的中断。
TLB（TLB shootdowns）：用于处理与地址转换缓冲（TLB）相关的操作。
TRM（Thermal event interrupts）：热事件中断，用于处理与温度监测和热管理相关的事件。
THR（Threshold APIC interrupts）：门限 APIC 中断，与局部和全局 APIC 相关。
DFR（Deferred Error Interrupts）：延迟错误中断，用于处理硬件错误。
MCE（Machine Check Exception）：机器检查异常，用于处理硬件故障和错误。
MCP（Machine Check Polling）：机器检查轮询，与机器检查异常处理相关。
ERR（Error Interrupts）：错误中断，用于处理硬件错误或异常情况。
MIS（Miscellaneous Interrupts）：其他中断类型，没有特定的分类。
PIN（Pin-based interrupts）：基于引脚的中断，用于处理外部设备的中断请求。
NPI（Non-PCI Interrupts）：非 PCI 中断，与非 PCI 总线设备相关。
PIW（Post Interrupt Work）：用于处理中断后的工作。