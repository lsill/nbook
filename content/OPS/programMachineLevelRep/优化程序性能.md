---
title: "优化程序性能"
date: 2023-11-16T15:35:48+08:00
draft: true
---

### 1. 优化编译器的能力和局限
现代编译器运用复杂精细的算法来确定一个程序中计算的是什么值，以及它们是被如何使用的。然后利用一些机会来简化
表达式，在几个不同的地方使用同一个计算，以及降低一个给定的计算必须被执行的次数。大多数编译器，包括GCC，想用户
提供了一些对他们使用优化的控制

优化级别：
GCC "-Og"是让GCC使用一组基本的优化，以选项"-O1""或更高（入“-O2”,"-O3"）调用GCC会让它使用更大量优化。
这样做可以进一步 提高程序的性能，但是也可能增加程序的规模，也可能使标准的调试工具更难对程序进行调试。
我们的表述，虽然对于大多数使用GCC的软件项目来说，优化级别-02 己经成为了被接受的标准，
但是还是主要考虑以优化级别-O1编译出的代码。我们特意限制了优化级别，以展示写C语言函数的不同方法如何
影响编译器产生代码的效率。我们会发现可以写出的C代码，即使用-O1选项编译得到的性能，也比用可能的最
高的优化等级编译一个 更原始的版本得到的性能好。


编译器必须很小心地对程序只使用安全的优化，也就是说对于程序可能遇到的所有可能的情况，在C语言标准提供的保证之下，
优化后得到的程序和末优化的版本有一样的行为。限制编译器只进行安全的优化，消除了造成不希望的运行时行为的一些可能
的原因，但是这也意味着程序员必须花费更大的力气写出编译器能够将之较换成有效机器代码的程序。为了理解决定一种程序
转换是否安全的难度,看看下面这两个过程：


妨碍优化的因素
- 两个指针可能指向同一个内存位置的情况称为**内存别名使用**。在只执行安全的优化中，编译器必须假设不同指针可能会指向
内存中同一个位置。
- 函数调用。编译器会假设最糟的情况，并保持所有的函数调用不变。
（包含函数调用的代码可以用内联函数替换的过程进行优化，将函数调用替换为函数体，这样转换既减少了函数调用的开销，也允许对展开的
的代码进一步优化）。

在各种编译器中，就优化能力来说，GCC被认为是胜任的，但是并不是特别突出。
它完成基本的优化，但是它不会对程序进行更加“有进取心的” 编译器所做的那种激进变换。
因此，使用GCC的程序员必须花费更多的精力，以一种简化编译器生成高效代码的 任务的方式来编写程序。

#### 2. 表示程序性能
引人度量标准每元素的周期数(Cycles Per Element, CPE)，作为一种表示程序性能并指导改进代码的方法。
CPE这种度量标准帮助在更细节的级别上理解迭代程序的循环性能。这样的度量标准对执行重复计算的程序来说
是很适当的，例如处理图像中 的像素，或是计算矩阵乘积中的元素。

处理器活动的顺序是由时钟控制的，时钟提供了某个频率的规律信号，通常用 千兆赫兹(GHz)，即十亿周期每秒来表示。
例如，当表明一个系统有“4GHz” 处理器，这表示处理器时钟运行频 率为每秒 4× 10^9 个周期。
每个时钟周期的时间是时钟频率的倒数。通常 是以纳秒(nanosecond，1纳秒等于10-^9秒)或
皮秒(picosecond，1皮秒等于10^12秒)为单位的。例如，一个4GHz的时钟其周期为0.25纳秒，或者250皮秒。
从程序员的角度来 看，用时钟周期来表示度量标准要比用纳秒或皮秒来表示有帮助得多。
用时钟周期来表示，度量值表示的是执行了多少条指令，而不是时钟运行得有多快。


#### 3. 程序示例
宏定义方便切换乘法和除法的测试

```c
#define IDENT 0
#define OP +
```

```c
#define IDENT 1
#define OP *
```

计算向量元素的乘积
```c
void combine1(vec_ptr v, data_t *dest)
{
    long i;
    *dest = IDENT;
    for (i = 0; i < vec_length(v);i++)
    {
        data_t val;
        get_vec_element(v, i, &val);
        *dest = *dest OP val;
    }
}
```

#### 4. 消除循环的低效率
因为函数调用，编译器不会去优化，所以需要程序员自己优化。
例如：
```c++
void lower1(char* s)
{
    long i;
    for (i = 0; i < strlen(s);i++)
    {
        if (s[i] >= 'A' && s[i] <= 'Z')
            s[i] -= ('A'-'a');
    }
}

void lower2(char* s)
{
    long i;
    long len = strlen(s);
    for (i = 0; i < len;i++)
    {
        if (s[i] >= 'A' && s[i] <= 'Z')
            s[i] -= ('A'-'a');
    }
}

size_t strlen(const char* s)
{
    long length = 0;
    while(*s != '\0')
    {
        s++;
        length++;
    }
    return length;
}
```

lower1和lower2能看得出的性能差距，因为是函数调用，所以编译器不会去尝试优化。

优化combine2，将冗余的函数提取出来
```c
void combine2(vec_ptr v, data_t *dest)
{
    long i;
    long length = vec_length(v);
    
    *dest = IDENT;
    for (i = 0; i < length;i++)
    {
        data_t val;
        get_vec_element(v, i, &val);
        *dest = *dest OP val;
    }
}
```

#### 5. 减少过程调用
过程调用会带来开销，而且妨碍大多数形式的程序优化。


对于每个向量引用，这个函数get_vec_element要把向量索引i与循环边界作比较，很明显会造成低效率。在处理任意
数组访问时，边界检查可能是很有用的特性，但是对combine2的简单分析表明，所有的引用都是合法的。

作为替代，增加一个函数get_vec_start,这个函数返回数组的起始地址：
```c
data_t *get_vec_start(vec_ptr v)
{
    return ->data;
}
```
```c
void combine3(vec_ptr v, data_t *dest)
{
    long i;
    long length = vec_length(v);
    data_t *data = get_vec_start(v);
    
    *dest = IDENT;
    for (i = 0; i < length;i++)
    {
        data_t val;
        *dest = *dest OP data[i];
    }
}
```
性能没有明显的提升，事实上整数求和的性能还略有下降。内循环的其他操作形成了瓶颈，限制性能超过调用get_vec_element.
#### 6. 消除不必要的内存引用
涉及到从内存中读取的时候，可以设置一个临时变量，等逻辑结束写会到内存中。在循环中更加能优化性能。
combine3的代码将合并运算计算的值积累在指针dest指令的位置。
```
// inner loop of combine3, data_t = double, OP = *
// dest in %rbx, data+i in %rdx, data+length in %rax
.L17        // loop:
    vmovsd (%rbx), %xmm0            // read product from dest
    vmulsd (%rdx), %xmm0, %xmm0     // multiply product by data[i]
    vmovsd %xmm0, (%rbx)            // store product at dest
    addq $8, %rdx                   // increment data+i
    cmpq    %rax, %rdx              // compare to data+length
    jne .L17                        // if !=, goto loop
```
可以看到每次迭代时，累积变量dest的数值都要从内存读出再写人到内存。这样的读写很浪费，因为每次迭代开始时从dest读出的值就是上次选代最后写人的值。

消除这种不必要的内存读写：
```
// inner loop of combine4, data_t = double, OP = *
// acc in %xmm0, data+i in %rdx, data+length in %rax
.L25:                           // loop:
    vmulsd (%rax), %xmm0, %xmm0     // multiply acc by data[i]
    addq    %8, %rax                // increment data+i
    cmpq %rax, %rdx                 // compare to data+length
    jne .L25                        // if !=, goto loop
```
```c
void combine4(vec_ptr v, data_t *dest)
{
    long i;
    long length = vec_length(v);
    data_t *data = get_vec_start(v);
    data_t acc = IDENT
    
    for (i = 0; i < length;i++)
    {
        acc = acc OP data[i];
    }
    *dest = acc;
}
```
把结果的积累放在临时变量中，将累计值存放在局部变量acc中，消除了每次循环迭代中从内从读取并将更新至写会的需求。



#### 7. 理解现代处理器
在实际的处理器中，是同时对多条指令求值的，这个现象称为**指令级并行**。

- 当一系列操作必须按照严格顺序执行时，就会遇到**延迟界限**，因为在下一条指令开始之前，这条指令必须结束。
当代码中的数据相关限制处理器利用指令并行的能力时，延迟界限能够限制程序性能。
- **吞吐量界限**刻画了处理器功能单元的原始计算能力，这个界限是程序性能的终极限制。

算术运算性能表示
- 延迟：表示完成运算所需要的时间
- 发射时间：表示两个连续的同类型运算之间需要的最小时钟周期
- 容量：表示能够执行该运算的功能单元的数量

表达发射时间的一种更常见的方法是指明这个功能单元的最大**吞吐量**，吞吐量= C/I(容量/发射时间)

对于形成循环的代码片段，可以将访问到寄存器分位4类:
- 只读：这些寄存器只用作源值，可以作为数据，也可以用来计算内存地址，但在循环中它们是不会被修改的。
- 只写：这些寄存器作为输出传送操作的为敌。
- 局部：这些寄存器在循环内部被修改和使用，迭代与迭代之间不相干。在这个循环中，条件码寄存器就是例子：cmp操作会修改它们，然后jne操作会使用它们。
- 循环：对于循环来说，这些寄存器既作为源值，又作为目的，一次迭代中产恒的值会在另一次迭代中用到。



#### 8. 循环展开
通过增加每次迭代计算的元素的数量，减少循环的迭代次数。

循环展开能够从两个方面改进程序的性能：
- 它减少了不直接有助于程序结果的操作数量
- 提供了一些方法，可以进一步变化代码，减少整个计算中关键路径上的操作数量

```c
void combine5(vec_ptr v, data_t *dest)
{
    long i;
    long length = vec_length(v);
    long limit = length - 1;
    data_t *data = get_vec_start(v);
    data_t acc = IDENT
    
    for (i = 0; i < limit;i+=2)
    {
        acc = (acc OP data[i]) OP data[i+1];
    }
    for (;i<length;i++) 
    {
        acc = acc OP data[i]
    }
    *dest = acc;
}
```
加法得到了性能提升，相对于计算向量和所需要加法的数量，降低循环开销的数量，此时整数加法的一个周期延迟成为了
限制性能的因素。

#### 9. 提高并行性
程序的性能是受运算单元的延迟限制的。执行加法和乘法的功能单元是完全流水线化的，
这意味着它们可以每个时钟周期开始一个新操作，并且有些操作可以被多个功能单元执行。
硬件具有以更高速率执行乘法和加法的潜力，但是代码不能利用这种能力，即使是使用循环展开也不能，
这是因为我们将累积值放在一个单独的变量 acc 中。在前面的计算完成之前，都不能计算acc的新值。
虽然计算acc新值的功能单元能够每个时钟周期开始一个新的操作，但是它只会每山个周期开始一条新操作，
这里L是合并操作的延迟。现在我们要考察打破这种顺序相关，得到比延迟界限更好性能的方法。

1. 多个累计变量
对于一个可结合和可交换的合并运算来说，比如说整数加法或乘法，可以通过将一组合并运算分割成两个或更多的部分，并在最后合并结果来提高性能。
```c
void combine6(vec_ptr v, data_t *dest)
{
    long i;
    long length = vec_length(v);
    long limit = length - 1;
    data_t *data = get_vec_start(v);
    data_t acc0 = IDENT
    data_t acc1 = IDENT
    
    for (i = 0; i < limit;i+=2)
    {
        acc0 = acc0 OP data[i];
        acc1 = acc1 OP data[i+1]
    }
    for (;i<length;i++) 
    {
        acc0 = acc0 OP data[i]
    }
    *dest = acc0 * acc1;
}
```
性能得到提升，整数乘、浮点加浮点乘改进了约2被，整数加法也有所提升。打破了延迟界限设下的限制。处理器不在需要延迟
下一个加法或乘法操作以待前一个操作完成。

#### 2. 重新结合变换
通过修改combine5内循环元素合并方式
```
acc = (acc OP data[i]) op data[i+1];
```
修改为
```
acc = acc OP (data[i] op data[i+1]);
```

```c
void combine7(vec_ptr v, data_t *dest)
{
    long i;
    long length = vec_length(v);
    long limit = length - 1;
    data_t *data = get_vec_start(v);
    data_t acc = IDENT
    
    for (i = 0; i < limit;i+=2)
    {
        acc = acc OP (data[i] OP data[i+1]);
    }
    for (;i<length;i++) 
    {
        acc = acc OP data[i]
    }
    *dest = acc;
}
```

整数加的性能几乎与combine5性能相同，但整数乘，浮点数加浮点数乘则与使用并行积累变量的版本combine6相同。
突破了延迟界限造成的限制。

重新结合变能减少计算中关键路径上操作的数量，通过更好的利用功能单元流水线的能力得到更好的性能。
大多数编译器不会尝试对浮点运算做重新结合，因为这些运算不保证是可结合的。

#### 11. 一些限制因素
1. 寄存器溢出
并行度力P超过了可用的寄存器数量，那么编译器会诉诸溢出(spilling)，将某些临时值存放到内存中，通常是在 运行时堆栈上分配空间。

2. 分支预测和预测错误处罚
通用原则：
- 不要过分关心可预测的分支
```
void combine4b(vec_ptr v, data_t *dest)
{
    long i;
    long length = vec_length(v);
    data_t acc = IDENT
    
    for (i = 0; i < length;i++)
    {
        if (i >= 0 && i < v->len) 
        {
            acc = acc OP v->data[i];
        }
    }
    *dest = acc;
}
// 对整数加法来说，会慢一点,但对其他三种情况来说，性能是一样的，这些情況受限于它们各自的合并操作的延迟。处理器能够预测这些分支的结果，所以这些求值
// 都不会形成对程序执行关键路径的指令的取值和处理产生太大的影响。
```
- 书写适合用条件传送实现的代码

分支预测只对有规律的模式可行。程序中的许多测试是完全不可预测的，依赖于数据的任意特性，例如一个数是负数还是正数。对于这些测试，分 支预测逻辑会处理得很糟糕。
对于本质上无法预测的情况，如果编译器能够产生使用条件数据传送而不是使用条件 控制转移的代码，可以极大地提高程序的性能。
这不是C语言程序员可以直接控制的，但是有些表达条件行为的方法能够更直接地被翻译成条件传送，而不是其他操作。

例：交换两个元素
// 可预测数据CPE约为2.5~3.5
```c
void minmax1(long a[], long b[], long n)
{
    long i;
    for (i = 0; i < n; i++)
    {
        if (a[i] > b[i])
        {
            long t = a[i];
            a[i] = b[i];
            b[i] = t;
        }
    }
}
// CPE 大约13.5
```
用功能式风格实现这个函数
```c
void minmax1(long a[], long b[], long n)
{
    long i;
    for (i = 0; i < n; i++)
    {
        long min = a[i] < b[i] ? a[i]:b[i];
        long max = a[i] < b[i] ? b[i]:a[i];
        a[i] = min;
        b[i] = max;
    }
}
```
这个函数的测试表明无论数据是任意的还是可预测的，CPE大约为4.0（使用了条件传送）

不是所有的条件行为都能用条件数据传送来实现，所以无可避 免地在某些情况中，
程序员不能避免写出会导致条件分支的代码，而对于这些条件分支，
处理器用分支预测可能会处理得很糟糕。但是，程序员方面用一点点聪明，
有时就能使代码更容易被翻译成条件数据传送。这需要一些试验，写出两数的不同版本，
然后检查产生的汇编代码，并测试性能。

#### 12. 理解内存性能
所有的现代处理器都包含一个或多个高速缓存(cache)存储器，以对这样少 量的存储器提供快速的访问。

现代处理器有专门的功能单元来执行加载和存储操作，这些单元有 内部的缓冲区来保存末完成的内存操作请求集合。

1. 加载的性能
加载链表长度可以看做是**加载内存的延迟CPE为4.0**（加载内存能在完全流水线化的模式中工作）
```c
typedef struct ELE 
{
    struct ELE* next;
    long data;
}list_ele, *list_ptr;

long listen_len(list_ptr ls)
{
    long len = 0;
    while(ls)
    {
        len++;
        ls = ls->next;
    }
    return len;
}
```

```
// Inner loop of list_len
// ls in %rdi, len in %rdx
.L3:
    addq $1, %rax   // increment len
    movq (%rdi), %rdi   // ls = ls->next
    testq %rdi, %rdi    // test ls
    jne .L3             // if nonnull, goto loop
```

2. 存储的性能
（存储也能在完全流水线化的模式中工作，每个周期开始一条新的存储）。存储的CPE等于1.00。

与其他操作不同，存储操作并不影响任何寄存器值。因此，就其本性来说，一系列存储操作不会产生数据相关。只有加载操作
会受存储操作结果的影响，因为只有加载才做能够从由存储操作写的那个位置读回值。

例：
```c
void write_read(long* src, long* dst, long n)
{
    long cnt = n;
    long val = 0;
    while (cnt)
    {
        *dst = val;
        val = (*src) + 1;
        cnt--;
    }
}
```
- 示例A:write_read(&a[0], &a[1],3):从src读出的结果不受对dest的写的影响，CPE等于1.3
- 示例B:write_read(&a[0],&a[0],3)：参数src和dest的指针都指向数组元素a[0]的指针，指针引用*src的每次
加载都会得到指针引用*dest的前次执行存储的值。因而，一系列不断增加的值被存储在这个位置。性能测试CPE为6.0

一个内存读的结果依赖于一个最近的内存写，称之为**读/写相关**。

write_read内循环汇编：
```
// Inner loop of write_read
// src in %rdi, dst in %rsi, val in %rax
.L3:
    movq %rax, (%rsi)   // write val to dst
    movq (%rdi), %rax   // t = *src
    addq $1, %rax       // val = t + 1
    subq $1, %rdx       // cnt--
    jne .L3             // if != 0, goto loop
```

示例A，有不同的源和目的地址，加载和存储操作可以独立进行，因此唯一的关键路径是减少变量cnt形成的，这是的CP等于1.0.
示例B，源地址和目的地址相同,s_data和load指令之间的数据相关使得关键路径的形成包括了存储、加载和增加数据，顺序执行这三个操作
一共需要7个时钟。

#### 13. 应用：性能提高技术
优化程序性能级基本策略：
1. 高级设计：为遇到的问题选择适当的算法和数据结构。要特别警觉，避免使用那些会渐进地产生糟糕性能的算法或编码技术。
2. 基本编码原则：避免限制优化的因素，这样编辑器就能产生高效的代码。
- 消除连续的函数调用：在可能时，将计算移到循环外。考虑有选择的妥协程序的模块性以获得更大的效率。
- 消除不必要的内存引用，引入临时变量来保存中间结果。只有在最后的值计算出来时，才将结果存放到数组或全局变量中。
3. 低级优化：结构化代码以利用硬件功能
- 展开循环，降低开销，并且使得进一步的优化成为可能。
- 通过使用例入多个累计变量和重新结合等技术，找到方法提高指令级并行。
- 用功能性的风格重写条件操作，使得编译采用条件数据传送。

要警惕，在为了提高效率重写程序时避免引人错误。在引人新变量、改变循环边界和使得代码整体上更复杂时，
很容易犯错误。一项有用的技术是在优化函数时，用检查代码来测试的数的每个版本，以确保在这个过程没有引
入错误。检查代码对函数的新版本实施一系列的测试，确保它们产生与原来一样的结果。对于高度优化的代码，
这组测试情况必领变得更加广泛，因为要考虑的情况也更多。例如，使用循环展开的检查代码需要测试许多不同
的循环界限，保证它能够处理最终单步迭代所需要的所有不同的可能的数字。

#### 14. 确认和消除性能瓶颈
如何使用代码剖析程序，这是在程序执行时收集性能数据的分析工具。系统优化的通用原则，称为Amdahl定律。

##### 1. 程序剖析（Profiling）
程序剖析(profiling) 运行程序的一个版本，其中插人了工具代码，以确定程序的各个部分需要多少时间。
这对于确认程序中我们需要集中注意力优化的部分是很有用的。剖析的一个有力之处在于可以在现实的基准数
揚(benchmark data)上运行实际程序的同时，进行剖析。

Unix 系统提供了一个剖析程序GPROF。这个程序产生两种形式的信息。首先，它确定程序中每个函数花费了
多少CPU时间。其次，它计算每个函数被调用的次数，以执行调用的函数来分类。这两种形式的信息都非常有
用。这些计时给出了不同函数在确定整体 运行时问中的相对重要性。调用信息使得我们能理解程序的动态行为。

用GPROF进行剖析需要了个步骤，就像C程序prog.c ,所示，它运行时命令行参数为file.txt:
1. 程序必须为剖析而编译和链接。使用GCC( 以及其他C编译器)，就是在命令行上简单地包括运行时标志“- pg”。
确保编译器不通过内联替换来尝试执行任何优化是很重要的， 否则就可能无法正确刻画两数调用。我们使用优化标
志- Og，以保证能正确跟踪西数调用。

linux>gcc -Og -pg prog.c -o prog
2. 然后程序像往常一样执行:

linux>./prog file.ext

它运行得会比正常时稍微慢一点(大约慢2倍)，不过除此之外唯一的区别就是它产生了一个文件gmon.out 。

3. 调用GPROF 来分析gmon. out 中的数据。

linux>gprof prog


剖析报告的第一部分列出子执行各个函数花费的时间，按照降序排列。剖析报告的第二部分是函数（例如递归）的调用历史。

GPROF 有些属性值得注意:
- 计时不是很准确。它的计时基于一个简单的间隔计数(interval counting)机制，编译过的程序为每个两数维护
一个计数器，记录花费在执行该西数上的时问。操作系统使得每隔某个规则的时间间隔ρ，程序被中断一次。ρ的典型值
的范围为1.0~ 10. 0 毫秒。当中断发生时，它会确定程序正在执行什么函数，并将该函数的计数器值增加ρ。当然，
也可能这个函数只是刚开始执行，而很快就会完成，却赋给它从上次中断以来整个的执行花费。在两次中断之间也可能
运行其他某个程序，却因此根本没有计算花费。 对于运行时间较长的程序，这种机制工作得相当好。从统计上来说，
应该根据花费在执行函数 上的相对时间来计算每个两数的花费。不过，对于那些运行时间少于1秒的程序来说，得到的
统计数宇只能看成是粗略的估计值。
- 假设没有执行内联替换，则调用信息相当可靠。编译过的程序为每对调用者和被调 用者维护一个计数器。每次调用一
个过程时，就会对适当的计数器加1。
- 默认情况下，不会显示对库函数的计时。相反，库函数的时间都被计算到调用它们的函数的时间中

##### 2. 使用剖析程序来指导优化








